{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1ea19d-f512-428b-a504-5ed1328e345d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import argparse\n",
    "import numpy as np\n",
    "import math\n",
    "from einops import rearrange\n",
    "import time\n",
    "import random\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "import webdataset as wds\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "\n",
    "from accelerate import Accelerator, DeepSpeedPlugin\n",
    "\n",
    "# tf32 data type is faster than standard float32\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "# custom functions #\n",
    "import utils\n",
    "\n",
    "global_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19a3ab0-e67c-4962-876c-007281a9ab02",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Multi-GPU config ###\n",
    "local_rank = os.getenv('RANK')\n",
    "if local_rank is None: \n",
    "    local_rank = 0\n",
    "else:\n",
    "    local_rank = int(local_rank)\n",
    "print(\"LOCAL RANK \", local_rank)  \n",
    "\n",
    "num_devices = torch.cuda.device_count()\n",
    "if num_devices==0: num_devices = 1\n",
    "\n",
    "accelerator = Accelerator(split_batches=False)\n",
    "\n",
    "### UNCOMMENT BELOW STUFF TO USE DEEPSPEED (also comment out the immediately above \"accelerator = \" line) ###\n",
    "\n",
    "# if num_devices <= 1 and utils.is_interactive():\n",
    "#     # can emulate a distributed environment for deepspeed to work in jupyter notebook\n",
    "#     os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "#     os.environ[\"MASTER_PORT\"] = str(np.random.randint(10000)+9000)\n",
    "#     os.environ[\"RANK\"] = \"0\"\n",
    "#     os.environ[\"LOCAL_RANK\"] = \"0\"\n",
    "#     os.environ[\"WORLD_SIZE\"] = \"1\"\n",
    "#     os.environ[\"GLOBAL_BATCH_SIZE\"] = str(global_batch_size) # set this to your batch size!\n",
    "#     global_batch_size = os.environ[\"GLOBAL_BATCH_SIZE\"]\n",
    "\n",
    "# # alter the deepspeed config according to your global and local batch size\n",
    "# if local_rank == 0:\n",
    "#     with open('deepspeed_config_stage2.json', 'r') as file:\n",
    "#         config = json.load(file)\n",
    "#     config['train_batch_size'] = int(os.environ[\"GLOBAL_BATCH_SIZE\"])\n",
    "#     config['train_micro_batch_size_per_gpu'] = int(os.environ[\"GLOBAL_BATCH_SIZE\"]) // num_devices\n",
    "#     with open('deepspeed_config_stage2.json', 'w') as file:\n",
    "#         json.dump(config, file)\n",
    "# else:\n",
    "#     # give some time for the local_rank=0 gpu to prep new deepspeed config file\n",
    "#     time.sleep(10)\n",
    "# deepspeed_plugin = DeepSpeedPlugin(\"deepspeed_config_stage2.json\")\n",
    "# accelerator = Accelerator(split_batches=False, deepspeed_plugin=deepspeed_plugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58820d2f-5864-4776-bbf8-a01ba559c693",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PID of this process =\",os.getpid())\n",
    "device = accelerator.device\n",
    "print(\"device:\",device)\n",
    "num_workers = num_devices\n",
    "print(accelerator.state)\n",
    "world_size = accelerator.state.num_processes\n",
    "distributed = not accelerator.state.distributed_type == 'NO'\n",
    "print(\"distributed =\",distributed, \"num_devices =\", num_devices, \"local rank =\", local_rank, \"world size =\", world_size)\n",
    "print = accelerator.print # only print if local_rank=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54a8b71-75c8-48b8-a829-fe49bdb4851a",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa112fda-ed74-4b2f-b586-4b46cb62ba8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = int(global_batch_size / num_devices)\n",
    "epochs = 800\n",
    "save_ckpt_freq = 50\n",
    "model_name = \"pretrain_videomae_base_patch16_224\"\n",
    "decoder_depth = 4\n",
    "mask_type = \"tube\"\n",
    "mask_ratio = .75 #ratio of the visual tokens/patches need be masked\n",
    "input_size = [65,78,65]\n",
    "drop_path = 0.0\n",
    "normlize_target = True\n",
    "\n",
    "lr = 1.5e-4\n",
    "warmup_lr = 1e-6\n",
    "min_lr = 1e-5\n",
    "warmup_epochs = 40\n",
    "warmup_steps = -1\n",
    "\n",
    "use_checkpoint = False\n",
    "resume = \"\"\n",
    "auto_resume = False\n",
    "start_epoch = 0\n",
    "\n",
    "color_jitter = 0.0\n",
    "train_interpolation = \"bicubic\"\n",
    "data_urls = \"/scratch/openneuro-0-100-ps13-f8-r1-bspline-shuffled/func-{000000..000577}.tar\"\n",
    "data_location = \"aws\"\n",
    "data_resample = True\n",
    "data_seed = 42\n",
    "data_buffer_size = 100 #buffer size for shuffling the datasets\n",
    "data_batch_per_epoch = 1000\n",
    "max_num_patches = 196*4\n",
    "num_frames = 8\n",
    "tubelet_size = 2\n",
    "sampling_rate = 1\n",
    "output_dir = \"\"\n",
    "log_dir = None\n",
    "seed = 0\n",
    "\n",
    "device = \"cuda\"\n",
    "num_workers = 1\n",
    "pin_mem = True\n",
    "world_size = 1\n",
    "local_rank = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954aa23a-c27c-40b5-82e1-08f5e20e52ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "model = timm.create_model(\n",
    "        model_name,\n",
    "        pretrained=False,\n",
    "        drop_path_rate=drop_path,\n",
    "        drop_block_rate=None,\n",
    "        decoder_depth=decoder_depth,\n",
    "        use_checkpoint=use_checkpoint\n",
    "    )\n",
    "\n",
    "patch_size = model.encoder.patch_embed.patch_size\n",
    "print(\"Patch size\", patch_size)\n",
    "\n",
    "window_size = (num_frames // tubelet_size, input_size[0] // \n",
    "               patch_size[0], input_size[1] // patch_size[1], input_size[2] // patch_size[2])\n",
    "print(\"Window size\", window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6719efa-6990-44a3-b37c-cdf19d85e693",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4821d2-9085-4cb3-b403-ce324b8acb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from masking_generator import TubeMaskingGenerator, AgnosticMaskingGenerator\n",
    "class DataAugmentationForVideoMAE():\n",
    "    def __init__(self, args):\n",
    "        # TODO: add augmentation for fMRI\n",
    "        self.transform = transforms.Compose([\n",
    "            # tio.CropOrPad((65, 78, 65)),\n",
    "            # tio.RandomFlip(axes=('LR',)),\n",
    "            # tio.RandomAffine(scales=(0.9, 1.1), degrees=10, isotropic=False, default_pad_value='otsu'),\n",
    "            # tio.RandomAffine(scales=(0.9, 1.1)),\n",
    "            # tio.RandomNoise(std=(0, 0.1)),\n",
    "            # tio.RandomBlur(std=(0, 0.1)),\n",
    "            # tio.RandomBiasField(coefficients=(0, 0.1)),\n",
    "            ])\n",
    "        self.patchify = Patchify(patch_size, tubelet_size, max_num_patches)\n",
    "        if mask_type == 'tube':\n",
    "            self.masked_position_generator = TubeMaskingGenerator(\n",
    "                window_size, mask_ratio, max_num_patches\n",
    "            )\n",
    "        elif mask_type == 'random':\n",
    "            self.masked_position_generator = AgnosticMaskingGenerator(\n",
    "                window_size, mask_ratio, max_num_patches\n",
    "            )\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        key, func = sample\n",
    "        process_data = self.transform(func)\n",
    "        paded, mask, token_shape = self.patchify(process_data)\n",
    "        return paded, token_shape, mask, self.masked_position_generator(token_shape)\n",
    "\n",
    "    def __repr__(self):\n",
    "        repr = \"(DataAugmentationForVideoMAE,\\n\"\n",
    "        repr += \"  transform = %s,\\n\" % str(self.transform)\n",
    "        repr += \"  Masked position generator = %s,\\n\" % str(self.masked_position_generator)\n",
    "        repr += \")\"\n",
    "        return repr\n",
    "transform = DataAugmentationForVideoMAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2438ac18-2a7e-41d2-80b1-58f635a8ec97",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = f\"pipe:aws s3 cp {data_urls} -\"\n",
    "print(urls)\n",
    "\n",
    "dataset_train = wds.WebDataset(urls, resampled=data_resample).decode(\"torch\")\\\n",
    "    .to_tuple(\"__key__\", \"func.npy\")\\\n",
    "    .shuffle(data_buffer_size, initial=data_buffer_size, rng=random.Random(data_seed))\\\n",
    "    .map(transform)\\\n",
    "    .batched(batch_size, partial=False)\\\n",
    "    .with_epoch(data_batch_per_epoch)\n",
    "print(\"Data Aug = %s\" % str(transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2351880b-67f3-4efa-a484-da808118a860",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
