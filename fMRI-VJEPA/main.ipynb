{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e6af0bb-19b2-472a-bd32-cd10bd997132",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e7a60b5f-c5db-46f5-8569-e10ac40fb8a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reached\n",
      "reached1\n",
      "reached2\n",
      "reached3\n",
      "reached4\n",
      "reached5\n",
      "Number of available CUDA devices: 1\n",
      "LOCAL RANK=0\n",
      "NUM GPUS=1\n",
      "NODE=0\n",
      "GLOBAL RANK=0\n",
      "WORLD_SIZE=1\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "PID of this process = 170885\n",
      "device = cuda distributed = False num_devices = 1 local rank = 0 world size = 1 data_type = torch.float16\n"
     ]
    }
   ],
   "source": [
    "# Import packages and setup gpu configuration.\n",
    "# This code block shouldnt need to be adjusted!\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import math\n",
    "import gc\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "import time\n",
    "import random\n",
    "import h5py\n",
    "import webdataset as wds\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import utils\n",
    "from models import *\n",
    "import nibabel as nib\n",
    "from nilearn import plotting\n",
    "import schedulers\n",
    "\n",
    "# tf32 data type is faster than standard float32\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "print(\"reached5\")\n",
    "### Multi-GPU config ###\n",
    "device_count = torch.cuda.device_count()\n",
    "print(f\"Number of available CUDA devices: {device_count}\")\n",
    "\n",
    "local_rank = os.getenv('LOCAL_RANK')\n",
    "if local_rank is None: \n",
    "    local_rank = 0\n",
    "else:\n",
    "    local_rank = int(local_rank)\n",
    "print(f\"LOCAL RANK={local_rank}\")\n",
    "\n",
    "num_devices = os.getenv('NUM_GPUS')\n",
    "if num_devices is None: \n",
    "    num_devices = 1\n",
    "else:\n",
    "    num_devices = int(num_devices)\n",
    "print(f\"NUM GPUS={num_devices}\")\n",
    "distributed = True if num_devices>1 else False\n",
    "if distributed: assert device_count==num_devices\n",
    "\n",
    "node = os.getenv('SLURM_NODEID')\n",
    "if node is None:\n",
    "    node = 0\n",
    "else:\n",
    "    node = int(node)\n",
    "print(f\"NODE={node}\")\n",
    "\n",
    "global_rank = os.getenv('RANK')\n",
    "if global_rank is None:\n",
    "    global_rank = 0\n",
    "else:\n",
    "    global_rank = int(global_rank)\n",
    "print(f\"GLOBAL RANK={global_rank}\")\n",
    "\n",
    "world_size = os.getenv('WORLD_SIZE')\n",
    "if world_size is None: \n",
    "    world_size = 1\n",
    "else:\n",
    "    world_size = int(world_size)\n",
    "print(f\"WORLD_SIZE={world_size}\")\n",
    "\n",
    "if utils.is_interactive():\n",
    "    # Following allows you to change functions in models.py or utils.py and \n",
    "    # have this notebook automatically update with your revisions\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    from tqdm.notebook import tqdm\n",
    "else:\n",
    "    from tqdm import tqdm\n",
    "\n",
    "# Load parameters from yaml config\n",
    "config = yaml.load(open('config.yaml', 'r'), Loader=yaml.FullLoader)\n",
    "\n",
    "# create global variables from the config\n",
    "for attribute_name in config.keys():\n",
    "    globals()[attribute_name] = config[f'{attribute_name}']\n",
    "\n",
    "data_type = torch.float16 # change depending on your mixed_precision\n",
    "# batch_size = global_batch_size // num_devices\n",
    "global_batch_size = batch_size * num_devices\n",
    "\n",
    "# FSDP Setup\n",
    "if distributed:\n",
    "    import torch.distributed as dist\n",
    "    import torch.multiprocessing as mp\n",
    "    from torch.distributed.fsdp import FullyShardedDataParallel as FSDP\n",
    "    from torch.distributed.fsdp.api import BackwardPrefetch, CPUOffload, ShardingStrategy\n",
    "    import functools\n",
    "    from torch.distributed.fsdp.wrap import size_based_auto_wrap_policy\n",
    "    print(\"starting init_process_group...\")\n",
    "    dist.init_process_group(\"nccl\", rank=global_rank, world_size=world_size)\n",
    "    print(f\"setting device to cuda:{local_rank}\")\n",
    "    try:\n",
    "        torch.cuda.set_device(local_rank)\n",
    "        device = torch.cuda.current_device() #torch.device('cuda',local_rank)\n",
    "        print(f\"\\nSuccessfully set cuda:{local_rank} | global_rank{global_rank} | node{node}\")\n",
    "    except Exception as error:        \n",
    "        print(f\"\\nFAILED TO SET DEVICE cuda:{local_rank} | global_rank{global_rank} | node{node}\")\n",
    "        print(\"An exception occurred:\", error)\n",
    "    dist.barrier()\n",
    "    print(\"passed barrier\\n\")\n",
    "else:\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "print(\"PID of this process =\",os.getpid())\n",
    "print(\"device =\", device, \"distributed =\",distributed, \"num_devices =\", num_devices, \"local rank =\", local_rank, \"world size =\", world_size, \"data_type =\", data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f3de5a1c-ee37-4e61-9ce6-6e2fae1dc7ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'long_run_batch=2', 'use_cls_token': False, 'use_contrastive_loss': False, 'constrastive_loss_weight': 1.0, 'batch_size': 2, 'num_workers': 1, 'num_epochs': 300, 'seed': 42, 'warmup': 40, 'start_lr': 0.0002, 'lr': 0.000625, 'final_lr': 1e-06, 'num_samples_per_epoch': 1024, 'ema': [0.998, 1.0], 'ipe_scale': 1.25, 'reg_coeff': 0.0, 'ckpt_saving': True, 'ckpt_interval': 5, 'resume_from_ckpt': False, 'wandb_log': True, 'x_encoder_start_masking_ratio': 0.85, 'x_encoder_end_masking_ratio': 0.85, 'y_encoder_mask_ratio': 0.85, 'patch_size': 8, 'frame_patch_size': 1, 'use_rope_emb': False, 'masking_strategy': 'MNI', 'depth': 12, 'heads': 12, 'dim': 512, 'mlp_dim': 1536, 'num_heads': 6, 'embed_dim': 384, 'dim_head': 64, 'image_size': [88, 104, 72], 'num_frames': 4, 'train_urls': ['/scratch/gpfs/ks9249/nsdfoundation/wds/{000005..000099}.tar'], 'test_urls': '/scratch/gpfs/ks9249/nsdfoundation/wds/{000000..000004}.tar', 'is_s3': False}\n",
      "outdir /scratch/gpfs/ks9249/fMRI-foundation-model/ckpts/long_run_batch=2\n",
      "global_batch_size 2\n",
      "use_cls_token False\n",
      "num_patches 5148\n",
      "num_encoder_patches 772\n",
      "num_decoder_patches 772\n"
     ]
    }
   ],
   "source": [
    "print(config)\n",
    "\n",
    "# seed all random functions\n",
    "utils.seed_everything(seed)\n",
    "\n",
    "outdir = os.path.abspath(f'../ckpts/{model_name}')\n",
    "print(\"outdir\", outdir)\n",
    "\n",
    "if use_contrastive_loss:\n",
    "    global_batch_size = global_batch_size // 2 # contrastive loss doubles the batch size with the same samples and different masks\n",
    "print(\"global_batch_size\", global_batch_size)\n",
    "\n",
    "use_cls_token = True if use_contrastive_loss else use_cls_token\n",
    "print(\"use_cls_token\", use_cls_token)\n",
    "\n",
    "num_patches = int(\n",
    "    (image_size[0] / patch_size)\n",
    "    * (image_size[1] / patch_size)\n",
    "    * (image_size[2] / patch_size)\n",
    "    * num_frames\n",
    ")\n",
    "num_patches_per_timepoint = num_patches // num_frames\n",
    "num_encoder_patches = int(num_patches_per_timepoint * (1 - x_encoder_start_masking_ratio) * num_frames)\n",
    "num_decoder_patches = int(num_patches_per_timepoint * (1 - y_encoder_mask_ratio) * num_frames)\n",
    "print(\"num_patches\", num_patches)\n",
    "print(\"num_encoder_patches\", num_encoder_patches)\n",
    "print(\"num_decoder_patches\", num_decoder_patches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee5be68-d850-42e9-a693-b78f22a1d19b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test to Check Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0915c828-19d2-49a5-b7bc-b170fcfaecd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_encoder\n",
      "param counts:\n",
      "21,275,904 total\n",
      "21,275,904 trainable\n",
      "21275904\n",
      "y_encoder\n",
      "param counts:\n",
      "21,275,904 total\n",
      "21,275,904 trainable\n",
      "21275904\n",
      "predictor\n",
      "param counts:\n",
      "21,275,904 total\n",
      "21,275,904 trainable\n",
      "21275904\n"
     ]
    }
   ],
   "source": [
    "image_depth, image_height, image_width = image_size\n",
    "image_patch_size=(patch_size,patch_size,patch_size)\n",
    "patch_depth, patch_height, patch_width = image_patch_size\n",
    "x_encoder = Transformer(\n",
    "    embed_dim,\n",
    "    depth,\n",
    "    num_heads,\n",
    "    dim_head,\n",
    "    mlp_dim,\n",
    "    use_rope=use_rope_emb,\n",
    "    grid_time=num_frames // frame_patch_size,\n",
    "    grid_depth=image_depth // patch_depth,\n",
    "    grid_height=image_height // patch_height,\n",
    "    grid_width=image_width // patch_width,\n",
    "    cls_token=use_cls_token,\n",
    ")\n",
    "print(\"x_encoder\")\n",
    "print(utils.count_params(x_encoder))\n",
    "y_encoder = Transformer(\n",
    "    embed_dim,\n",
    "    depth,\n",
    "    num_heads,\n",
    "    dim_head,\n",
    "    mlp_dim,\n",
    "    use_rope=use_rope_emb,\n",
    "    grid_time=num_frames // frame_patch_size,\n",
    "    grid_depth=image_depth // patch_depth,\n",
    "    grid_height=image_height // patch_height,\n",
    "    grid_width=image_width // patch_width,\n",
    "    cls_token=use_cls_token,\n",
    ")\n",
    "print(\"y_encoder\")\n",
    "print(utils.count_params(y_encoder))\n",
    "predictor = Transformer(\n",
    "    embed_dim,\n",
    "    depth,\n",
    "    num_heads,\n",
    "    dim_head,\n",
    "    mlp_dim,\n",
    "    use_rope=use_rope_emb,\n",
    "    grid_time=num_frames // frame_patch_size,\n",
    "    grid_depth=image_depth // patch_depth,\n",
    "    grid_height=image_height // patch_height,\n",
    "    grid_width=image_width // patch_width,\n",
    "    cls_token=use_cls_token,\n",
    ")\n",
    "print(\"predictor\")\n",
    "print(utils.count_params(predictor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0b543f5a-65a9-4294-b708-b5ec67dd0fff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param counts:\n",
      "64,026,880 total\n",
      "64,026,880 trainable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "64026880"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SimpleViT(\n",
    "    x_encoder=x_encoder,\n",
    "    y_encoder=y_encoder,\n",
    "    predictor=predictor,\n",
    "    image_size=image_size, \n",
    "    image_patch_size=image_patch_size, \n",
    "    num_frames=num_frames,\n",
    "    frame_patch_size=frame_patch_size,\n",
    "    channels=1,\n",
    "    use_rope_emb=use_rope_emb,\n",
    "    use_cls_token=use_cls_token,\n",
    ")\n",
    "if not distributed:\n",
    "    model = model.to(device)\n",
    "utils.count_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "478ba6bb-150a-498f-98fb-29deef53389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_transform = utils.DataPrepper(\n",
    "    num_frames=num_frames,\n",
    "    masking_strategy=masking_strategy,\n",
    "    patch_depth=patch_size,\n",
    "    patch_height=patch_size,\n",
    "    patch_width=patch_size,\n",
    "    frame_patch_size=frame_patch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f0441c-1e4d-40d2-b2fc-f0dc560e0a56",
   "metadata": {},
   "source": [
    "# Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dce27aac-53e0-4960-a19a-edb634b51d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/scratch/gpfs/ks9249/nsdfoundation/wds/{000005..000099}.tar']\n",
      "Adding decoder ImageHandler to decoders.\n",
      "####################################################################################################\n",
      "Building dataloader with the following parameters\n",
      "batch_size: 2, num_workers: 1\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "from dataloader import create_dataset, create_loader\n",
    "\n",
    "if not is_s3:\n",
    "    print(train_urls)\n",
    "    if distributed: dist.barrier()\n",
    "    train_dp = create_dataset(train_urls, \n",
    "                              is_s3=is_s3, \n",
    "                              sample_shuffle=1, shard_shuffle=100)\n",
    "    train_dl = create_loader(train_dp, batch_size=batch_size, num_workers=num_workers)\n",
    "else:\n",
    "    print(\"Dataloading from s3!\")\n",
    "    train_urls = s3_train_urls\n",
    "    print(train_urls)\n",
    "    train_dp = create_dataset(train_urls, \n",
    "                              is_s3=is_s3, \n",
    "                              sample_shuffle=1, shard_shuffle=100)\n",
    "    train_dl = create_loader(train_dp, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "244e3be1-6075-42d4-9171-0b2350883f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yielding 2 batches\n",
      "iter 0\n",
      "iter 1\n",
      "Done!\n",
      "input_func torch.Size([2, 32, 88, 104, 72])\n"
     ]
    }
   ],
   "source": [
    "if not distributed:\n",
    "    num_it = 2\n",
    "    print(f\"Yielding {num_it} batches\")\n",
    "    \n",
    "    for i, batch in enumerate(train_dl):\n",
    "        print(\"iter\",i)\n",
    "        input_func = batch['func.npy']\n",
    "        if i >= (num_it-1):\n",
    "            break\n",
    "    \n",
    "    print(\"Done!\")\n",
    "    print(\"input_func\", input_func.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7040a835-6189-4d6d-8219-0f837fb3893f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if distributed:    \n",
    "    my_auto_wrap_policy = functools.partial(\n",
    "        size_based_auto_wrap_policy, min_num_params=200000\n",
    "    )\n",
    "    print(f\"\\nPrepping FSDP on {global_rank} {node}...\\n\")\n",
    "    model = FSDP(\n",
    "        model,\n",
    "        sharding_strategy=ShardingStrategy.HYBRID_SHARD,\n",
    "        auto_wrap_policy=my_auto_wrap_policy,\n",
    "        use_orig_params=False,\n",
    "        cpu_offload=None, #CPUOffload(offload_params=True)\n",
    "        sync_module_states=True,\n",
    "        limit_all_gathers=True, # See https://github.com/pytorch/pytorch/issues/91165\n",
    "        device_id=device,\n",
    "    )\n",
    "    print(f\"\\nSuccessfully loaded FSDP model to device on global_rank {global_rank}\\n\")\n",
    "    dist.barrier()\n",
    "    print(f\"\\nSuccessfully passed barrier! {global_rank}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d66a5ce1-6dd1-42c9-82c8-d402e7317ec0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0087, -0.0038, -0.0279,  ...,  0.0268,  0.0393, -0.0420],\n",
      "        [-0.0150,  0.0623,  0.0413,  ..., -0.0182, -0.0174,  0.0160],\n",
      "        [ 0.0046, -0.0187, -0.0054,  ..., -0.0396, -0.0146, -0.0042],\n",
      "        ...,\n",
      "        [ 0.0280, -0.0210, -0.0012,  ..., -0.0058,  0.0055, -0.0107],\n",
      "        [ 0.0094,  0.0228,  0.0162,  ..., -0.0138, -0.0223,  0.0107],\n",
      "        [-0.0055, -0.0041, -0.0225,  ..., -0.0313, -0.0336, -0.0035]],\n",
      "       device='cuda:0', requires_grad=True) h\n",
      "Parameter containing:\n",
      "tensor([[-0.0087, -0.0038, -0.0279,  ...,  0.0268,  0.0393, -0.0420],\n",
      "        [-0.0150,  0.0623,  0.0413,  ..., -0.0182, -0.0174,  0.0160],\n",
      "        [ 0.0046, -0.0187, -0.0054,  ..., -0.0396, -0.0146, -0.0042],\n",
      "        ...,\n",
      "        [ 0.0280, -0.0210, -0.0012,  ..., -0.0058,  0.0055, -0.0107],\n",
      "        [ 0.0094,  0.0228,  0.0162,  ..., -0.0138, -0.0223,  0.0107],\n",
      "        [-0.0055, -0.0041, -0.0225,  ..., -0.0313, -0.0336, -0.0035]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0173,  0.0039,  0.0042,  ...,  0.0134,  0.0135, -0.0137],\n",
      "        [-0.0063,  0.0133,  0.0082,  ...,  0.0185, -0.0262, -0.0120],\n",
      "        [-0.0197, -0.0184,  0.0123,  ..., -0.0041,  0.0022,  0.0243],\n",
      "        ...,\n",
      "        [-0.0134, -0.0076, -0.0104,  ...,  0.0008,  0.0070,  0.0079],\n",
      "        [ 0.0071, -0.0248, -0.0088,  ..., -0.0031, -0.0120, -0.0372],\n",
      "        [-0.0180,  0.0081,  0.0119,  ...,  0.0079,  0.0084, -0.0042]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "num_iterations_per_epoch 512\n",
      "total_steps 153600\n",
      "\n",
      "Done with model preparations!\n",
      "param counts:\n",
      "64,026,880 total\n",
      "64,026,880 trainable\n",
      "\n",
      "momentum_scheduler set\n",
      "\n",
      "lr_scheduler set\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "opt_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.x_encoder.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 1e-2},\n",
    "    {'params': [p for n, p in model.predictor.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 1e-2},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n",
    "] #we only update the xencoder and predictor, the yencoder is updated through a moving average of the xencoder\n",
    "model.y_encoder.requires_grad_(False)\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, torch.nn.Linear):\n",
    "        utils.trunc_normal_(m.weight, std=0.02)\n",
    "        if m.bias is not None:\n",
    "            torch.nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, torch.nn.LayerNorm):\n",
    "        torch.nn.init.constant_(m.bias, 0)\n",
    "        torch.nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "for m in model.x_encoder.modules():\n",
    "    init_weights(m)\n",
    "for m in  model.predictor.modules():\n",
    "    init_weights(m)\n",
    "\n",
    "model.y_encoder = copy.deepcopy(model.x_encoder)\n",
    "\n",
    "for m in model.x_encoder.modules():\n",
    "    if isinstance(m, torch.nn.Linear):\n",
    "        print(m.weight, \"h\")\n",
    "        break\n",
    "\n",
    "for m in model.y_encoder.modules():\n",
    "    if isinstance(m, torch.nn.Linear):\n",
    "        print(m.weight)\n",
    "        break\n",
    "\n",
    "for m in model.predictor.modules():\n",
    "    if isinstance(m, torch.nn.Linear):\n",
    "        print(m.weight)\n",
    "        break\n",
    "    \n",
    "\n",
    "    \n",
    "optimizer = torch.optim.AdamW(opt_grouped_parameters)\n",
    "num_iterations_per_epoch = num_samples_per_epoch // global_batch_size\n",
    "print(\"num_iterations_per_epoch\", num_iterations_per_epoch)\n",
    "total_steps = num_epochs * num_iterations_per_epoch * num_devices\n",
    "print(\"total_steps\", total_steps)\n",
    "\n",
    "print(\"\\nDone with model preparations!\")\n",
    "num_params = utils.count_params(model)\n",
    "\n",
    "#momentum_scheduler = (ema[0] + i*(ema[1]-ema[0])/(num_iterations_per_epoch*num_epochs*ipe_scale)\n",
    "                          #for i in range(int(num_iterations_per_epoch*num_epochs*ipe_scale)+1))\n",
    "momentum_scheduler = (ema[0] + i*(ema[1]-ema[0])/(total_steps*ipe_scale)\n",
    "                          for i in range(int(total_steps*ipe_scale)+1))\n",
    "count=0\n",
    "print(\"\\nmomentum_scheduler set\")\n",
    "\n",
    "#lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    #optimizer,\n",
    "    #max_lr=max_lr,\n",
    "    #total_steps=total_steps,\n",
    "#)\n",
    "\n",
    "lr_scheduler = schedulers.WarmupCosineSchedule(\n",
    "        optimizer,\n",
    "        warmup_steps=int(warmup * num_iterations_per_epoch),\n",
    "        start_lr=start_lr,\n",
    "        ref_lr=lr,\n",
    "        final_lr=final_lr,\n",
    "        T_max=int(ipe_scale * num_epochs * num_iterations_per_epoch),\n",
    "    )\n",
    "print(\"\\nlr_scheduler set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e8a0f425-076c-46e4-9184-4475a44dad1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if masking_strategy==\"MNI\":\n",
    "    MNI_brain = nib.load(\"/scratch/gpfs/ks9249/fMRI-foundation-model/dataset_creation/afni_conversion/tpl-MNI152NLin2009cAsym_res-02_T1w_brain.nii.gz\").get_fdata()\n",
    "    brain_pos_voxels = MNI_brain[6:94,8:112,10:82]\n",
    "    brain_pos_pats = model.patchify(torch.Tensor(brain_pos_voxels)[None,None,None])\n",
    "    brain_pos_pats_vit = rearrange(brain_pos_pats, \"b ... d -> b (...) d\").mean(-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "233c03de-3475-4ffa-872b-ca6d9c98103d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "default_ckpt_path = outdir+f'/last.pth'\n",
    "\n",
    "def save_ckpt(model,tag=\"last\"):\n",
    "    if distributed: dist.barrier()\n",
    "    model_states = model.state_dict()\n",
    "    if global_rank == 0:\n",
    "        ckpt_path = outdir+f'/{tag}.pth'\n",
    "        os.makedirs(outdir,exist_ok=True)\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model_states,\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }, ckpt_path)\n",
    "        print(f\"\\n---saved {ckpt_path}!---\\n\")\n",
    "        # save config.yaml copy\n",
    "        with open(f'{outdir}/config.yaml', 'w') as file:\n",
    "            yaml.dump(config, file)\n",
    "\n",
    "def resume_ckpt(model, optimizer, device, ckpt_path=default_ckpt_path):\n",
    "    if global_rank == 0:\n",
    "        checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        lr_scheduler.load_state_dict(checkpoint['lr_scheduler_state_dict'])\n",
    "        epoch = checkpoint['epoch']\n",
    "    else:\n",
    "        epoch = 0\n",
    "    if distributed: dist.barrier()\n",
    "    torch.cuda.empty_cache()\n",
    "    return model, optimizer, lr_scheduler, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54e45f79-e050-4173-b42d-005fc66a2494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_MODE\"]=\"offline\"\n",
    "\n",
    "if utils.is_interactive():\n",
    "    wandb_log = False\n",
    "if global_rank==0 and wandb_log: # only use main process for wandb logging\n",
    "    import wandb\n",
    "    wandb_project = 'found'\n",
    "    print(f\"wandb {wandb_project} run {model_name}\")\n",
    "    # need to configure wandb beforehand in terminal with \"wandb init\"!\n",
    "    wandb_config = {\n",
    "      \"model_name\": model_name,\n",
    "      \"global_batch_size\": global_batch_size,\n",
    "      \"batch_size\": batch_size,\n",
    "      \"num_epochs\": num_epochs,\n",
    "      \"num_samples_per_epoch\": num_samples_per_epoch,\n",
    "      \"depth\": depth,\n",
    "      \"mlp_dim\": mlp_dim,\n",
    "      \"x_encoder_start_masking_ratio\": x_encoder_start_masking_ratio,\n",
    "      \"x_encoder_end_masking_ratio\": x_encoder_end_masking_ratio,\n",
    "      \"y_encoder_mask_ratio\": y_encoder_mask_ratio,\n",
    "      \"num_frames\": num_frames,\n",
    "      \"patch_size\": patch_size,\n",
    "      \"frame_patch_size\": frame_patch_size,\n",
    "      \"use_contrastive_loss\": use_contrastive_loss,\n",
    "      \"use_cls_token\": use_cls_token,\n",
    "      \"constrastive_loss_weight\": constrastive_loss_weight,\n",
    "      \"num_params\": num_params,\n",
    "      \"ckpt_interval\": ckpt_interval,\n",
    "      \"ckpt_saving\": ckpt_saving,\n",
    "      \"seed\": seed,\n",
    "      \"distributed\": distributed,\n",
    "      \"num_devices\": num_devices,\n",
    "      \"world_size\": world_size,\n",
    "      \"train_urls\": train_urls,\n",
    "      \"is_s3\": is_s3,\n",
    "    }\n",
    "    print(\"wandb_config:\\n\",wandb_config)\n",
    "    print(\"wandb_id:\",model_name)\n",
    "    wandb.init(\n",
    "        id=model_name,\n",
    "        project=wandb_project,\n",
    "        name=model_name,\n",
    "        config=wandb_config,\n",
    "        resume=\"allow\",\n",
    "    )\n",
    "else:\n",
    "    wandb_log = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5102a6b4-8587-4121-b422-a8232ea9898c",
   "metadata": {},
   "source": [
    "# Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f7ed4a-2abf-42af-b1ca-798c703d00f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "lrs, recon_losses, contrastive_losses, test_losses,train_reg, test_reg = [], [], [], [], [], []\n",
    "best_test_loss = 1e9\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a97f07-9781-45e3-bb49-76a667a3dcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if resume_from_ckpt is True:\n",
    "    if os.path.exists(default_ckpt_path):\n",
    "        print(f\"Resuming from {default_ckpt_path}...\")\n",
    "        model, optimizer, lr_scheduler, epoch = resume_ckpt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7e4373-0b1b-444d-8b81-749e387096a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(z, h):\n",
    "    loss = 0.\n",
    "    # Compute loss and accumulate for each mask-enc/mask-pred pair\n",
    "    for zi, hi in zip(z, h):\n",
    "        loss += torch.mean(torch.abs(zi - hi)**loss_exp) / loss_exp\n",
    "    loss /= len(z)\n",
    "    return loss\n",
    "\n",
    "def reg_fn(z):\n",
    "    return sum([torch.sqrt(zi.var(dim=1) + 0.0001) for zi in z]) / len(z)\n",
    "\n",
    "def cos_fn(z):\n",
    "    # Flatten z from [batch, channels, height, width] to [batch, -1]\n",
    "    z_flat = z.flatten(1)\n",
    "    \n",
    "    # Compute normalized vectors to prevent division by zero\n",
    "    z_norm = torch.nn.functional.normalize(z_flat, p=2, dim=1)\n",
    "    \n",
    "    # Compute cosine similarity matrix\n",
    "    cossim_matrix = torch.mm(z_norm, z_norm.transpose(0, 1))\n",
    "    \n",
    "    # Compute the sum of cosine similarities of distinct pairs\n",
    "    cossim_sum = (cossim_matrix.sum() - len(z))/2\n",
    "    \n",
    "    # Compute the total number of distinct pairs\n",
    "    cossim_num = len(z) * (len(z) - 1) / 2\n",
    "    \n",
    "    # Return the average cosine similarity for distinct pairs\n",
    "    return cossim_sum / cossim_num\n",
    "\n",
    "l1 = nn.L1Loss() #Following VJEPA architecture, which uses L1 loss not L2 loss\n",
    "\n",
    "if use_contrastive_loss:\n",
    "    logit_scale = nn.Parameter(torch.ones([]) * np.log(1 / 0.07))  # learned logit scale\n",
    "    \n",
    "if distributed: dist.barrier()\n",
    "progress_bar = tqdm(range(epoch, num_epochs), disable=global_rank!=0)\n",
    "for epoch in progress_bar:\n",
    "    # get the masking ratio for the current epoch\n",
    "    tube_mask_ratio = utils.get_masking_ratio(\n",
    "        current_epoch=epoch, \n",
    "        total_epochs=num_epochs, \n",
    "        start_masking_ratio=x_encoder_start_masking_ratio, \n",
    "        end_masking_ratio=x_encoder_end_masking_ratio\n",
    "    )\n",
    "    with torch.cuda.amp.autocast(dtype=data_type):\n",
    "        model.train()\n",
    "        for train_i, batch in enumerate(train_dl):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            input_func = batch['func.npy']\n",
    "            \n",
    "            if masking_strategy==\"MNI\":\n",
    "                func, _ = aug_transform(input_func)\n",
    "            else:\n",
    "                func, brain_pos_voxels = aug_transform(input_func)\n",
    "                brain_pos_pats = model.patchify(torch.Tensor(brain_pos_voxels)[None,None,None])\n",
    "                brain_pos_pats_vit = rearrange(brain_pos_pats, \"b ... d -> b (...) d\").mean(-1)[0]\n",
    "                \n",
    "            if use_contrastive_loss:  # create positive pairs by duplicating the batch\n",
    "                func = torch.cat([func, func], dim=0)\n",
    "                meansd = torch.cat([meansd, meansd], dim=0)\n",
    "                brain_pos_pats = torch.cat([brain_pos_pats, brain_pos_pats], dim=0)\n",
    "                \n",
    "            func = func.unsqueeze(1).to(device)\n",
    "\n",
    "            # create tube mask (i.e., a mask that is the same for all frames/timepoints)\n",
    "            tube_mask = torch.zeros(num_patches // num_frames).to(torch.bool)\n",
    "            batch_positive_approx = (brain_pos_pats_vit > 0)\n",
    "            mask_idx_candidates = torch.where(batch_positive_approx)[0]\n",
    "            mask_idx_candidates = mask_idx_candidates[torch.randperm(len(mask_idx_candidates))]\n",
    "            tube_idx = mask_idx_candidates[:int(num_patches / num_frames * (1 - tube_mask_ratio))]\n",
    "            tube_mask[tube_idx] = True\n",
    "            tube_mask = tube_mask.tile(num_frames)\n",
    "\n",
    "            # print(\"before encoder\");utils.print_cuda_memory_usage()\n",
    "            \n",
    "            # feed into x-encoder\n",
    "            xencoder_out = model(func, encoder_mask=tube_mask, encoder_type = \"x\")\n",
    "            # print(\"x_encoder\");utils.print_cuda_memory_usage()\n",
    "            \n",
    "            # feed entire func into y-encoder\n",
    "            yencoder_out = model(func, encoder_mask=tube_mask, encoder_type = \"y\")\n",
    "            # print(\"y_encoder\");utils.print_cuda_memory_usage()\n",
    "            \n",
    "            # feed output of x-encoder into predictor\n",
    "            predictor_out = model(xencoder_out, encoder_mask=tube_mask, encoder_type=\"p\")\n",
    "            # print(\"predictor\");utils.print_cuda_memory_usage()\n",
    "\n",
    "\n",
    "            # compare output of predictor to output of y-encoder and calculate L1 Loss\n",
    "            loss_jepa = l1(predictor_out,yencoder_out)  # jepa prediction loss\n",
    "            loss_reg = cos_fn(yencoder_out)\n",
    "            loss = loss_jepa + reg_coeff * loss_reg\n",
    "            #loss = l1(predictor_out,yencoder_out)\n",
    "\n",
    "            \n",
    "            # contrastive loss\n",
    "            if use_contrastive_loss:\n",
    "                n_b = len(func) // 2\n",
    "                cls_token1 = enc_cls_token[:n_b, 0, :]  # first half of batch, cls_token shape B, 1, d_model\n",
    "                cls_token2 = enc_cls_token[n_b:, 0, :]\n",
    "                contrastive_loss = utils.contrastive_loss(cls_token1, cls_token2, temperature=logit_scale)\n",
    "                loss += constrastive_loss_weight * contrastive_loss\n",
    "                contrastive_losses.append(contrastive_loss.item())\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            if train_i==0 and epoch==0:\n",
    "                print(\"calculated first loss\")\n",
    "            if train_i==1 and epoch==0:\n",
    "                print(\"reached train_i=1\")\n",
    "            if train_i==0 and epoch==1:\n",
    "                print(\"reached epoch1\")\n",
    "            \n",
    "            # backwards + step\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            recon_losses.append(loss.item())\n",
    "            lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "            train_reg.append(loss_reg.item())\n",
    "            \n",
    "            # update y-encoder using exponential-moving average of x-encoder params to prevent collapse\n",
    "            m = next(momentum_scheduler)\n",
    "            with torch.no_grad():\n",
    "                for param_q, param_k in zip(model.x_encoder.parameters(), model.y_encoder.parameters()):\n",
    "                    param_k.data.mul_(m).add_((1.-m) * param_q.detach().data)\n",
    "\n",
    "            if train_i==0 and epoch==0:\n",
    "                print(\"finished first epoch!\")\n",
    "\n",
    "            if train_i >= (num_iterations_per_epoch-1):\n",
    "                print(\"train_i\", train_i, \"local_rank\", local_rank, \"global_rank\", global_rank)\n",
    "                break\n",
    "\n",
    "        logs = {\n",
    "            \"train/loss\": np.mean(recon_losses[-(train_i + 1) :]),\n",
    "            \"train/num_steps\": len(recon_losses),\n",
    "            \"lr\": np.mean(lrs[-(train_i + 1) :]),\n",
    "            \"epoch\": epoch,\n",
    "            \"tube_mask_ratio\": tube_mask_ratio,\n",
    "            \"train/loss_reg\": np.mean(train_reg[-(train_i + 1) :]),\n",
    "        }\n",
    "        progress_bar.set_postfix(**logs)\n",
    "        if distributed: print(logs)\n",
    "            \n",
    "        if global_rank==0:\n",
    "            if wandb_log: wandb.log(logs)\n",
    "                    \n",
    "        # Save model checkpoint\n",
    "        if (ckpt_saving) and ((epoch % ckpt_interval == 0) or (epoch==num_epochs-1)):\n",
    "            save_ckpt(model,\"last\")\n",
    "            \n",
    "        # wait for other GPUs to catch up if needed\n",
    "        if distributed: dist.barrier()\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "if distributed:\n",
    "    dist.barrier()\n",
    "    dist.destroy_process_group()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
