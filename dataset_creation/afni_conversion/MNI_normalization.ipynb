{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d41070df-0572-4e70-9b9a-fba4e0c85022",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standard Library Imports\n",
    "import os\n",
    "import sys\n",
    "from subprocess import call, check_output\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Third-Party Library Imports\n",
    "import numpy as np\n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.client import Config\n",
    "import webdataset as wds\n",
    "import nibabel as nib\n",
    "import pickle as pkl\n",
    "import h5py\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d33f9b6d-f595-48c2-b673-0c9b293d1d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_id = int(sys.argv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cd5c087-dbe8-4536-ad24-11de4c8e1901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/temp1\n",
      "/weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/MNIs1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/temp1/*': No such file or directory\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_dir = os.getcwd() + f\"/temp{worker_id}\" # the folder where the AFNI container will do its work\n",
    "mni_dir = os.getcwd() + f\"/MNIs{worker_id}\" # the folder where MNI outputs will go\n",
    "\n",
    "command = f\"rm -r {temp_dir}\"\n",
    "call(command,shell=True)\n",
    "command = f\"rm -r {mni_dir}\"\n",
    "call(command,shell=True)\n",
    "\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "os.makedirs(mni_dir, exist_ok=True)\n",
    "print(temp_dir)\n",
    "print(mni_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f15254df-2596-4e93-b0d3-4b5e05e92b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discarded_dataset_ids ['ds000138', 'ds000144', 'ds000148', 'ds000157']\n",
      "len(file_name_list) = 167200\n",
      "len(file_name_list) = 5766\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.client('s3')\n",
    "bucket_name = 'proj-fmri'\n",
    "prefix = 'fmri_foundation_datasets/parallel_openneuro/'\n",
    "\n",
    "if os.path.exists(f\"discarded_dataset_ids_{worker_id}.npy\"):\n",
    "    discarded_dataset_ids = np.load(f\"discarded_dataset_ids_{worker_id}.npy\").tolist()\n",
    "else:\n",
    "    discarded_dataset_ids = []\n",
    "print(\"discarded_dataset_ids\",discarded_dataset_ids)\n",
    "\n",
    "paginator = s3.get_paginator('list_objects_v2')\n",
    "file_name_list = []\n",
    "for page in paginator.paginate(Bucket=bucket_name, Prefix=prefix):\n",
    "    for obj in page.get('Contents', []):\n",
    "        file_name = obj['Key']\n",
    "        file_name_list.append(file_name)\n",
    "print(\"len(file_name_list) =\", len(file_name_list))\n",
    "\n",
    "# subset to current worker\n",
    "worker_id_idx = np.linspace(0,len(file_name_list),30)[worker_id:worker_id+2].astype(np.int32).tolist()\n",
    "file_name_list = file_name_list[worker_id_idx[0]:worker_id_idx[1]]\n",
    "print(\"len(file_name_list) =\", len(file_name_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d3ca1e5-f755-4b88-b624-8a39ef04f0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting...\n",
      "downloading /weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/temp0/ds000107/sub-13_task-onebacktask_run-01_bold.nii.gz\n",
      "waiting...\n",
      "waiting time exceeded...\n",
      "downloading /weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/temp0/ds000107/sub-13_task-onebacktask_run-02_bold.nii.gz\n",
      "waiting...\n",
      "upload: MNIs0/ds000107/sub-13_task-onebacktask_run-02_bold_MNI.nii.gz to s3://proj-fmri/fmri_foundation_datasets/openneuro_MNI/ds000107/sub-13_task-onebacktask_run-02_bold_MNI.nii.gz\n",
      "Removing _MNI file... /weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/MNIs0/ds000107/sub-13_task-onebacktask_run-02_bold_MNI.nii.gz\n",
      "downloading /weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/temp0/ds000107/sub-14_task-onebacktask_run-01_bold.nii.gz\n",
      "waiting...\n",
      "upload: MNIs0/ds000107/sub-14_task-onebacktask_run-01_bold_MNI.nii.gz to s3://proj-fmri/fmri_foundation_datasets/openneuro_MNI/ds000107/sub-14_task-onebacktask_run-01_bold_MNI.nii.gz\n",
      "Removing _MNI file... /weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/MNIs0/ds000107/sub-14_task-onebacktask_run-01_bold_MNI.nii.gz\n",
      "downloading /weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/temp0/ds000107/sub-14_task-onebacktask_run-02_bold.nii.gz\n",
      "waiting...\n",
      "upload: MNIs0/ds000107/sub-14_task-onebacktask_run-02_bold_MNI.nii.gz to s3://proj-fmri/fmri_foundation_datasets/openneuro_MNI/ds000107/sub-14_task-onebacktask_run-02_bold_MNI.nii.gz\n",
      "Removing _MNI file... /weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/MNIs0/ds000107/sub-14_task-onebacktask_run-02_bold_MNI.nii.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_wait = 500\n",
    "overlap_cnt = 0\n",
    "print(\"starting...\")\n",
    "for file_name in file_name_list:\n",
    "    if file_name.endswith('_bold.nii.gz'):\n",
    "        dataset_id = file_name.split('/')[2]\n",
    "        \n",
    "        if np.any(np.isin(dataset_id, discarded_dataset_ids)):\n",
    "            continue\n",
    "        \n",
    "        func_path = file_name.split('/')[-1]\n",
    "        temp_file_path = temp_dir + '/' + dataset_id + '/' + func_path\n",
    "        mni_file_path = mni_dir + '/' + dataset_id + '/' + func_path\n",
    "        \n",
    "        os.makedirs(temp_dir + '/' + dataset_id, exist_ok=True)\n",
    "        os.makedirs(mni_dir + '/' + dataset_id, exist_ok=True)\n",
    "        \n",
    "        afni_filename = mni_dir + '/' + dataset_id + '/' + func_path.split(\".nii.gz\")[0] + \"_MNI.nii.gz\"\n",
    "        s3_afni_filename = f\"s3://proj-fmri/fmri_foundation_datasets/openneuro_MNI/{dataset_id}/{func_path.split('.nii.gz')[0] + '_MNI.nii.gz'}\"\n",
    "        \n",
    "        # check if MNI output already exists\n",
    "        MNI_done = call(f\"aws s3 ls s3://{bucket_name}/{file_name}\",shell=True)\n",
    "        if MNI_done==0:\n",
    "            print(f\"      done: s3://{bucket_name}/{file_name}\")\n",
    "            continue\n",
    "            \n",
    "        # download from s3\n",
    "        print(f\"downloading {temp_file_path}\")\n",
    "        try:\n",
    "            #s3.download_file(bucket_name, file_name, temp_file_path)\n",
    "            command = f\"aws s3 cp s3://{bucket_name}/{file_name} {temp_file_path}\"\n",
    "            call(command,shell=True)\n",
    "        except:\n",
    "            print(\"failed to download? 1\")\n",
    "\n",
    "        while not os.path.exists(f\"{temp_file_path}\"):\n",
    "            print(f\"s3 download failed. trying again... {temp_file_path}\")\n",
    "            try:\n",
    "                # s3.download_file(bucket_name, file_name, temp_file_path)\n",
    "                command = f\"aws s3 cp s3://{bucket_name}/{file_name} {temp_file_path}\"\n",
    "                call(command,shell=True)\n",
    "            except:\n",
    "                print(\"failed to download? 2\")\n",
    "            time.sleep(5)\n",
    "\n",
    "        # Wait for AFNI to be complete\n",
    "        print(f'waiting for {afni_filename}')\n",
    "        waiting_time = 0\n",
    "        while not os.path.exists(afni_filename):\n",
    "            time.sleep(5)     \n",
    "            waiting_time += 5\n",
    "            if waiting_time > max_wait:\n",
    "                break\n",
    "\n",
    "        if waiting_time <= max_wait:\n",
    "            time.sleep(5) # wait to ensure file was fully created\n",
    "            with open(mni_file_path.split(\".nii.gz\")[0] + \"_overlap.txt\", 'r') as file:\n",
    "                try:\n",
    "                    overlap = file.readlines()\n",
    "                    overlap = np.array(overlap).astype(np.float32)[0]\n",
    "                except:\n",
    "                    print(\"overlap error!\")\n",
    "                    overlap = 0 # in case some weird error occurs where overlap txt is empty, assume its ok\n",
    "            \n",
    "            # if overlap >20%, discard outputs and skip this dataset\n",
    "            if overlap>20:\n",
    "                overlap_cnt += 1\n",
    "                if overlap_cnt>5:\n",
    "                    discarded_dataset_ids.append(dataset_id)\n",
    "                    print(\"discarded_dataset_ids\")\n",
    "                    print(discarded_dataset_ids)\n",
    "                    np.save(f\"discarded_dataset_ids_{worker_id}.npy\",discarded_dataset_ids)\n",
    "                    overlap_cnt = 0\n",
    "            else:   \n",
    "                overlap_cnt = 0\n",
    "                \n",
    "                command = f\"aws s3 cp {afni_filename} {s3_afni_filename}\"\n",
    "                call(command,shell=True)\n",
    "        else:\n",
    "            print(\"waiting time exceeded...\")\n",
    "            \n",
    "        # remove files\n",
    "        command = f\"rm {temp_file_path}\"\n",
    "        call(command,shell=True)\n",
    "        \n",
    "        command = f\"rm {afni_filename}\"\n",
    "        call(command,shell=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "found",
   "language": "python",
   "name": "found"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
