# Model Config
model_name: "test5" #"patch8_ViTS_1gpu_8gbs_50epoch"
use_cls_token: False
use_contrastive_loss: False
constrastive_loss_weight: 1.0

# Training Configs
global_batch_size: 12
num_workers: 8
max_steps: 15000
eval_per_n_steps: 2000
limit_val_batches: 1000
seed: 42
max_lr: 3.0e-3 # Keep the x.0 else will be converted to string

# Saving progress
ckpt_saving: True
ckpt_interval: 50
resume_from_ckpt: False
wandb_log: True

# MAE Config
tube_start_masking_ratio: 0.75
tube_end_masking_ratio: 0.75
decoder_mask_ratio: 0.25

# Model Config
encoder_model: "vit_large"
decoder_model: "vit_small"
patch_size: 8
frame_patch_size: 2
use_rope_emb: False
masking_strategy: "MNI"

# Data Config
img_size: [88, 104, 72] # Image Size
num_frames: 4
is_s3: False
test_urls: s3://proj-fmri/fmri_foundation_datasets/NSD_MNI_wds/000740.tar
train_urls: ["s3://proj-fmri/fmri_foundation_datasets/NSD_MNI_wds/{000000..000494}.tar","s3://proj-fmri/fmri_foundation_datasets/NSD_MNI_wds/{000496..000739}.tar"]
