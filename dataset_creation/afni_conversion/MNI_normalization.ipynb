{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d41070df-0572-4e70-9b9a-fba4e0c85022",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standard Library Imports\n",
    "import os\n",
    "import sys\n",
    "from subprocess import call, check_output\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Third-Party Library Imports\n",
    "import numpy as np\n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.client import Config\n",
    "import webdataset as wds\n",
    "import nibabel as nib\n",
    "import pickle as pkl\n",
    "import h5py\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d33f9b6d-f595-48c2-b673-0c9b293d1d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_id = int(sys.argv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cd5c087-dbe8-4536-ad24-11de4c8e1901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/temp0\n",
      "/weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/MNIs0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/temp0/ds000001': Is a directory\n",
      "rm: cannot remove '/weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/temp0/ds000002': Is a directory\n",
      "rm: cannot remove '/weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/temp0/ds000003': Is a directory\n",
      "rm: cannot remove '/weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/temp0/ds000005': Is a directory\n",
      "rm: cannot remove '/weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/temp0/ds000006': Is a directory\n",
      "rm: cannot remove '/weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/temp0/ds000007': Is a directory\n",
      "rm: cannot remove '/weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/temp0/ds000008': Is a directory\n",
      "rm: cannot remove '/weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/temp0/ds000009': Is a directory\n",
      "rm: cannot remove '/weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/temp0/ds000011': Is a directory\n",
      "rm: cannot remove '/weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/temp0/ds000017': Is a directory\n",
      "rm: cannot remove '/weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/temp0/ds000030': Is a directory\n",
      "rm: cannot remove '/weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/temp0/ds000031': Is a directory\n",
      "rm: cannot remove '/weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/temp0/ds000051': Is a directory\n",
      "rm: cannot remove '/weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/temp0/ds000052': Is a directory\n",
      "rm: cannot remove '/weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/temp0/ds000053': Is a directory\n",
      "rm: cannot remove '/weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/temp0/ds000101': Is a directory\n",
      "rm: cannot remove '/weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/temp0/ds000102': Is a directory\n",
      "rm: cannot remove '/weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/temp0/ds000105': Is a directory\n",
      "rm: cannot remove '/weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/temp0/ds000107': Is a directory\n",
      "rm: cannot remove '/weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/temp0/temp0': Is a directory\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_dir = os.getcwd() + f\"/temp{worker_id}\" # the folder where the AFNI container will do its work\n",
    "mni_dir = os.getcwd() + f\"/MNIs{worker_id}\" # the folder where MNI outputs will go\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "os.makedirs(mni_dir, exist_ok=True)\n",
    "print(temp_dir)\n",
    "print(mni_dir)\n",
    "\n",
    "# if any files currently in temp_dir, remove it\n",
    "command = f\"rm {temp_dir}/*\"\n",
    "call(command,shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f15254df-2596-4e93-b0d3-4b5e05e92b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discarded_dataset_ids ['ds000002', 'ds000007', 'ds000009', 'ds000017', 'ds000030', 'ds000031', 'ds000051', 'ds000105']\n",
      "len(file_name_list) = 167200\n",
      "len(file_name_list) = 5765\n"
     ]
    }
   ],
   "source": [
    "# def afni_worker():\n",
    "s3 = boto3.client('s3')\n",
    "bucket_name = 'proj-fmri'\n",
    "prefix = 'fmri_foundation_datasets/parallel_openneuro/'\n",
    "\n",
    "if os.path.exists(f\"discarded_dataset_ids_{worker_id}.npy\"):\n",
    "    discarded_dataset_ids = np.load(f\"discarded_dataset_ids_{worker_id}.npy\").tolist()\n",
    "else:\n",
    "    discarded_dataset_ids = []\n",
    "print(\"discarded_dataset_ids\",discarded_dataset_ids)\n",
    "\n",
    "# sample_idx = -1\n",
    "# mni_count = 0\n",
    "# sink = wds.TarWriter(f\"{mni_dir}/{mni_count}.tar\")\n",
    "\n",
    "paginator = s3.get_paginator('list_objects_v2')\n",
    "file_name_list = []\n",
    "for page in paginator.paginate(Bucket=bucket_name, Prefix=prefix):\n",
    "    for obj in page.get('Contents', []):\n",
    "        file_name = obj['Key']\n",
    "        file_name_list.append(file_name)\n",
    "print(\"len(file_name_list) =\", len(file_name_list))\n",
    "\n",
    "# subset to current worker\n",
    "worker_id_idx = np.linspace(0,len(file_name_list),30)[worker_id:worker_id+2].astype(np.int32).tolist()\n",
    "file_name_list = file_name_list[worker_id_idx[0]:worker_id_idx[1]]\n",
    "print(\"len(file_name_list) =\", len(file_name_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d3ca1e5-f755-4b88-b624-8a39ef04f0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting...\n",
      "downloading /weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/temp0/ds000107/sub-13_task-onebacktask_run-01_bold.nii.gz\n",
      "waiting...\n",
      "waiting time exceeded...\n",
      "downloading /weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/temp0/ds000107/sub-13_task-onebacktask_run-02_bold.nii.gz\n",
      "waiting...\n",
      "upload: MNIs0/ds000107/sub-13_task-onebacktask_run-02_bold_MNI.nii.gz to s3://proj-fmri/fmri_foundation_datasets/openneuro_MNI/ds000107/sub-13_task-onebacktask_run-02_bold_MNI.nii.gz\n",
      "Removing _MNI file... /weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/MNIs0/ds000107/sub-13_task-onebacktask_run-02_bold_MNI.nii.gz\n",
      "downloading /weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/temp0/ds000107/sub-14_task-onebacktask_run-01_bold.nii.gz\n",
      "waiting...\n",
      "upload: MNIs0/ds000107/sub-14_task-onebacktask_run-01_bold_MNI.nii.gz to s3://proj-fmri/fmri_foundation_datasets/openneuro_MNI/ds000107/sub-14_task-onebacktask_run-01_bold_MNI.nii.gz\n",
      "Removing _MNI file... /weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/MNIs0/ds000107/sub-14_task-onebacktask_run-01_bold_MNI.nii.gz\n",
      "downloading /weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/temp0/ds000107/sub-14_task-onebacktask_run-02_bold.nii.gz\n",
      "waiting...\n",
      "upload: MNIs0/ds000107/sub-14_task-onebacktask_run-02_bold_MNI.nii.gz to s3://proj-fmri/fmri_foundation_datasets/openneuro_MNI/ds000107/sub-14_task-onebacktask_run-02_bold_MNI.nii.gz\n",
      "Removing _MNI file... /weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/MNIs0/ds000107/sub-14_task-onebacktask_run-02_bold_MNI.nii.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"starting...\")\n",
    "for file_name in file_name_list:\n",
    "    if file_name.endswith('_bold.nii.gz'):\n",
    "        dataset_id = file_name.split('/')[2]\n",
    "\n",
    "        if np.any(np.isin(dataset_id, discarded_dataset_ids)):\n",
    "            continue\n",
    "\n",
    "        func_path = file_name.split('/')[-1]\n",
    "        temp_file_path = temp_dir + '/' + dataset_id + '/' + func_path\n",
    "        mni_file_path = mni_dir + '/' + dataset_id + '/' + func_path\n",
    "        \n",
    "        os.makedirs(temp_dir + '/' + dataset_id, exist_ok=True)\n",
    "        os.makedirs(mni_dir + '/' + dataset_id, exist_ok=True)\n",
    "\n",
    "        if os.path.exists(f\"{temp_file_path.split('.nii.gz')[0] + '.txt'}\") or os.path.exists(mni_file_path.split(\".nii.gz\")[0] + \"_overlap.txt\"):\n",
    "            continue\n",
    "           \n",
    "        # download from s3\n",
    "        print(f\"downloading {temp_file_path}\")\n",
    "        try:\n",
    "            s3.download_file(bucket_name, file_name, temp_file_path)\n",
    "        except:\n",
    "            print(\"failed to download? 1\")\n",
    "\n",
    "        while not os.path.exists(f\"{temp_file_path}\"):\n",
    "            print(f\"s3 download failed. trying again... {temp_file_path}\")\n",
    "            try:\n",
    "                s3.download_file(bucket_name, file_name, temp_file_path)\n",
    "            except:\n",
    "                print(\"failed to download? 2\")\n",
    "            time.sleep(10)\n",
    "\n",
    "        # make temp lock file so other parallel jobs dont do duplicate work\n",
    "        command = f\"touch {temp_file_path.split('.nii.gz')[0] + '.txt'}\"\n",
    "        call(command, shell=True)\n",
    "\n",
    "        # ### AFNI COMMANDS (see afni_watch.sh) ###\n",
    "        # # define func variable\n",
    "        # command = f\"export func='{func_path}'\"\n",
    "        # call(command,shell=True)\n",
    "\n",
    "        # # define suffix variable\n",
    "        # command = f\"export suffix='_MNI'\"\n",
    "        # call(command,shell=True)\n",
    "\n",
    "        # # motion correction and nonlinear alignment to 2mm resolution MNI T1w brain\n",
    "        # command = \"align_epi_anat.py -anat tpl-MNI152NLin2009cAsym_res-02_T1w_brain.nii.gz -epi $func'.nii.gz' -epi_base 0 -epi_strip 3dAutomask -epi2anat -ginormous_move -anat_has_skull no -suffix $suffix -volreg on -tshift off -save_resample -master_epi 2.00\"\n",
    "        # call(command,shell=True)\n",
    "\n",
    "        # # convert AFNI outputs to NIFTI\n",
    "        # command = \"3dAFNItoNIFTI -prefix $func$suffix'.nii.gz' $func$suffix'+tlrc'\"\n",
    "\n",
    "        # # remove leftover AFNI files\n",
    "        # call(\"rm *+tlrc.*\",shell=True)\n",
    "        # call(\"rm *vr_motion.*\",shell=True)\n",
    "        # call(\"rm *mat.aff*\",shell=True)\n",
    "\n",
    "        # # create overlap txt to depict values for %(A \\ B), the percent voxels from T1w that ARENT in func\n",
    "        # call(\"3dABoverlap -no_automask tpl-MNI152NLin2009cAsym_res-02_T1w_brain.nii.gz ${func}.nii.gz | awk 'NR==3 {print $7}' >> ${func}_overlap.txt\",shell=True)\n",
    "        # ### END OF AFNI COMMANDS \n",
    "\n",
    "        # Wait for AFNI to be complete\n",
    "        print('waiting...')\n",
    "        waiting_time = 0\n",
    "        while not os.path.exists(mni_file_path.split(\".nii.gz\")[0] + \"_overlap.txt\"):\n",
    "            time.sleep(5)     \n",
    "            waiting_time += 5\n",
    "            if waiting_time > 180:\n",
    "                break\n",
    "\n",
    "        if waiting_time <= 180:\n",
    "            time.sleep(10) # wait to ensure txt file was fully created\n",
    "            with open(mni_file_path.split(\".nii.gz\")[0] + \"_overlap.txt\", 'r') as file:\n",
    "                try:\n",
    "                    overlap = file.readlines()\n",
    "                    overlap = np.array(overlap).astype(np.float32)[0]\n",
    "                except:\n",
    "                    print(\"overlap error!\")\n",
    "                    overlap = 0 # in case some weird error occurs where overlap txt is empty, assume its ok\n",
    "            \n",
    "            # if overlap >20%, discard outputs and skip this dataset\n",
    "            if overlap>20:\n",
    "                discarded_dataset_ids.append(dataset_id)\n",
    "                print(\"discarded_dataset_ids\")\n",
    "                print(discarded_dataset_ids)\n",
    "                np.save(f\"discarded_dataset_ids_{worker_id}.npy\",discarded_dataset_ids)\n",
    "            else:\n",
    "                afni_filename = mni_dir + '/' + dataset_id + '/' + func_path.split(\".nii.gz\")[0] + \"_MNI.nii.gz\"\n",
    "    \n",
    "                command = f\"aws s3 cp {afni_filename} s3://proj-fmri/fmri_foundation_datasets/openneuro_MNI/{dataset_id}/{func_path.split('.nii.gz')[0] + '_MNI.nii.gz'}\"\n",
    "                call(command,shell=True)\n",
    "    \n",
    "                # load contents of Nifti\n",
    "                # func_nii = nib.load(afni_filename).get_fdata()\n",
    "                \n",
    "                # for batch in np.arange(0,func_nii.shape[-1],24):\n",
    "                #     batch_nii = func_nii[:,:,:,batch:batch+24]\n",
    "                #     if len(batch_nii)<4:\n",
    "                #         continue\n",
    "    \n",
    "                #     # send to aws s3\n",
    "                #     np.save(f\"{mni_dir}/npy/{func_path.split('.nii.gz')[0]}_{batch}_to_{batch+24}.npy\", batch_nii)\n",
    "                    \n",
    "                # command = f\"aws s3 sync {mni_dir}/npy s3://proj-fmri/fmri_foundation_datasets/openneuro_MNI_npy\"\n",
    "                # call(command,shell=True)\n",
    "    \n",
    "                # # remove npy files from local\n",
    "                # command = f\"rm {mni_dir}/npy/*.npy\"\n",
    "                # call(command,shell=True)\n",
    "    \n",
    "                # print(\"Done! Creating done txt file...\")\n",
    "                # command = f\"touch {mni_file_path.split('.nii.gz')[0] + '.txt'}\"\n",
    "                # call(command,shell=True)\n",
    "    \n",
    "                print(f\"Removing _MNI file... {afni_filename}\")\n",
    "                command = f\"rm {afni_filename}\"\n",
    "                call(command,shell=True)\n",
    "    \n",
    "                time.sleep(5)\n",
    "                    \n",
    "                    # sample_idx += 1\n",
    "                    # sink.write({\n",
    "                    #     \"__key__\": \"%06d\" % sample_idx,\n",
    "                    #     \"func.npy\": batch_nii,\n",
    "                    # })\n",
    "                # if sample_idx > 1024:\n",
    "                #     sink.close()\n",
    "                #     sample_idx = -1\n",
    "                #     mni_count += 1\n",
    "                #     sink = wds.TarWriter(f\"{mni_dir}/{mni_count}.tar\")\n",
    "                # print(f\"wrote {func_path.split('.nii.gz')[0]} to {mni_dir}/0.tar\")\n",
    "        else:\n",
    "            print(\"waiting time exceeded...\")\n",
    "            \n",
    "            # remove all files\n",
    "            command = f\"rm {temp_dir}/{dataset_id}/*\"\n",
    "            call(command,shell=True)\n",
    "\n",
    "            # write placeholder txt overlap file\n",
    "            with open(mni_file_path.split(\".nii.gz\")[0] + \"_overlap.txt\", 'w') as file:\n",
    "                file.write('-999')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "found",
   "language": "python",
   "name": "found"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
