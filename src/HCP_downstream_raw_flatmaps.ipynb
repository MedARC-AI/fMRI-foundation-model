{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8e236f1-385a-4d93-bb39-bea3ee384d76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PID of this process = 3695926\n"
     ]
    }
   ],
   "source": [
    "# Import packages and setup gpu configuration.\n",
    "# This code block shouldnt need to be adjusted!\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import yaml\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "import webdataset as wds\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import utils\n",
    "from mae_utils.flat_models import *\n",
    "import h5py\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import argparse\n",
    "\n",
    "# tf32 data type is faster than standard float32\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "# following fixes a Conv3D CUDNN_NOT_SUPPORTED error\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# ## MODEL TO LOAD ##\n",
    "# model_name = \"HCPflat_large_gsrFalse_\"\n",
    "# parquet_folder = \"epoch99\"\n",
    "\n",
    "# # outdir = os.path.abspath(f'checkpoints/{model_name}')\n",
    "# outdir = os.path.abspath(f'checkpoints/{model_name}')\n",
    "\n",
    "# print(\"outdir\", outdir)\n",
    "# # Load previous config.yaml if available\n",
    "# if os.path.exists(f\"{outdir}/config.yaml\"):\n",
    "#     config = yaml.load(open(f\"{outdir}/config.yaml\", 'r'), Loader=yaml.FullLoader)\n",
    "#     print(f\"Loaded config.yaml from ckpt folder {outdir}\")\n",
    "#     # create global variables from the config\n",
    "#     print(\"\\n__CONFIG__\")\n",
    "#     for attribute_name in config.keys():\n",
    "#         print(f\"{attribute_name} = {config[attribute_name]}\")\n",
    "#         globals()[attribute_name] = config[f'{attribute_name}']\n",
    "#     print(\"\\n\")\n",
    "\n",
    "# world_size = os.getenv('WORLD_SIZE')\n",
    "# if world_size is None: \n",
    "#     world_size = 1\n",
    "# else:\n",
    "#     world_size = int(world_size)\n",
    "# print(f\"WORLD_SIZE={world_size}\")\n",
    "\n",
    "# if utils.is_interactive():\n",
    "#     # Following allows you to change functions in models.py or utils.py and \n",
    "#     # have this notebook automatically update with your revisions\n",
    "#     %load_ext autoreload\n",
    "#     %autoreload 2\n",
    "\n",
    "# batch_size = probe_batch_size\n",
    "# num_epochs = probe_num_epochs\n",
    "\n",
    "# data_type = torch.float32 # change depending on your mixed_precision\n",
    "# global_batch_size = batch_size * world_size\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# hcp_flat_path = \"/weka/proj-medarc/shared/HCP-Flat\"\n",
    "# seed = 42\n",
    "num_frames = 16\n",
    "gsr = False\n",
    "# num_workers = 5\n",
    "batch_size = 256\n",
    "# target = 'sex' # This can be 'trial_type' 'age' 'sex'\n",
    "\n",
    "print(\"PID of this process =\",os.getpid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2539698-5566-48cf-8022-90cb70d94f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name_suffix: testing\n",
      "--hcp_flat_path=/weka/proj-medarc/shared/HCP-Flat                     --target=trial_type                     --model_suffix=testing                     --batch_size=256                     --max_lr=1e-5 --num_epochs=40 --no-save_ckpt --no-wandb_log --num_workers=10                     --weight_decay=1e-5\n"
     ]
    }
   ],
   "source": [
    "# if running this interactively, can specify jupyter_args here for argparser to use\n",
    "if utils.is_interactive():\n",
    "    model_name_suffix = \"testing\"\n",
    "    print(\"model_name_suffix:\", model_name_suffix)\n",
    "    \n",
    "    # global_batch_size and batch_size should already be defined in the 2nd cell block\n",
    "    jupyter_args = f\"--hcp_flat_path=/weka/proj-medarc/shared/HCP-Flat \\\n",
    "                    --target=trial_type \\\n",
    "                    --model_suffix={model_name_suffix} \\\n",
    "                    --batch_size={batch_size} \\\n",
    "                    --max_lr=1e-5 --num_epochs=40 --no-save_ckpt --no-wandb_log --num_workers=10 \\\n",
    "                    --weight_decay=1e-5\"\n",
    "    # --multisubject_ckpt=../train_logs/multisubject_subj01_1024_24bs_nolow\n",
    "\n",
    "    print(jupyter_args)\n",
    "    jupyter_args = jupyter_args.split()\n",
    "    \n",
    "    from IPython.display import clear_output # function to clear print outputs in cell\n",
    "    %load_ext autoreload \n",
    "    # this allows you to change functions in models.py or utils.py and have this notebook automatically update with your revisions\n",
    "    %autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3b9ee45-5409-4a03-b1a1-f59af40ccc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ ARGS ------- \n",
      " Namespace(model_suffix='testing', hcp_flat_path='/weka/proj-medarc/shared/HCP-Flat', batch_size=256, wandb_log=False, num_epochs=40, lr_scheduler_type='cycle', save_ckpt=False, seed=42, max_lr=1e-05, target='trial_type', num_workers=10, weight_decay=1e-05)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=\"Model Training Configuration\")\n",
    "parser.add_argument(\n",
    "    \"--model_suffix\", type=str, default=\"Testing_flat\",\n",
    "    help=\"name of model, used for ckpt saving and wandb logging (if enabled)\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--hcp_flat_path\", type=str, default=os.getcwd(),\n",
    "    help=\"Path to where NSD data is stored / where to download it to\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--batch_size\", type=int, default=128,\n",
    "    help=\"Batch size can be increased by 10x if only training retreival submodule and not diffusion prior\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--wandb_log\",action=argparse.BooleanOptionalAction,default=False,\n",
    "    help=\"whether to log to wandb\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--num_epochs\",type=int,default=150,\n",
    "    help=\"number of epochs of training\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--lr_scheduler_type\",type=str,default='cycle',choices=['cycle','linear'],\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--save_ckpt\",action=argparse.BooleanOptionalAction,default=True,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--seed\",type=int,default=42,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--max_lr\",type=float,default=3e-4,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--target\",type=str,default='trial_type',choices=['trial_type','sex','age'],\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--num_workers\",type=int,default=10,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--weight_decay\",type=float,default=1e-5,\n",
    ")\n",
    "\n",
    "if utils.is_interactive():\n",
    "    args = parser.parse_args(jupyter_args)\n",
    "else:\n",
    "    args = parser.parse_args()\n",
    "\n",
    "print(f\"------ ARGS ------- \\n {args}\")\n",
    "\n",
    "# create global variables without the args prefix\n",
    "for attribute_name in vars(args).keys():\n",
    "    globals()[attribute_name] = getattr(args, attribute_name)\n",
    "    \n",
    "# seed all random functions\n",
    "utils.seed_everything(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc00235a-a9e1-4dc4-8fd3-359c1d91bfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### UNCOMMENT THIS TO SAVE THE HCP-FLAT IN HDF5 FORMAT\n",
    "\n",
    "\n",
    "# from torch.utils.data import default_collate\n",
    "# from mae_utils.flat import load_hcp_flat_mask\n",
    "# from mae_utils.flat import create_hcp_flat\n",
    "# from mae_utils.flat import batch_unmask\n",
    "# import mae_utils.visualize as vis\n",
    "\n",
    "\n",
    "# batch_size = 1\n",
    "# print(f\"changed batch_size to {batch_size}\")\n",
    "# load_file_frames = num_frames * 2\n",
    "# print(f\"Calculating with {load_file_frames} frames, doubling to approximate TR\")\n",
    "\n",
    "# ## Test ##\n",
    "# datasets_to_include = \"HCP\"\n",
    "# assert \"HCP\" in datasets_to_include\n",
    "# test_dataset = create_hcp_flat(root=hcp_flat_path, \n",
    "#                 clip_mode=\"event\", frames=load_file_frames, shuffle=False, gsr=gsr, sub_list = 'test')\n",
    "# test_dl = wds.WebLoader(\n",
    "#     test_dataset.batched(batch_size, partial=False, collation_fn=default_collate),\n",
    "#     batch_size=None,\n",
    "#     shuffle=False,\n",
    "#     num_workers=num_workers,\n",
    "#     pin_memory=True,\n",
    "# )\n",
    "\n",
    "# ## Train ##\n",
    "# assert \"HCP\" in datasets_to_include\n",
    "# train_dataset = create_hcp_flat(root=hcp_flat_path, \n",
    "#                 clip_mode=\"event\", frames=load_file_frames, shuffle=False, gsr=gsr, sub_list = 'train')\n",
    "# train_dl = wds.WebLoader(\n",
    "#     train_dataset.batched(batch_size, partial=True, collation_fn=default_collate),\n",
    "#     batch_size=None,\n",
    "#     shuffle=False,\n",
    "#     num_workers=num_workers,\n",
    "#     pin_memory=True,\n",
    "# )\n",
    "\n",
    "# def flatten_meta(meta_dict):\n",
    "#     \"\"\"\n",
    "#     Flatten the meta dictionary by:\n",
    "#     - Replacing single-item lists with the item itself.\n",
    "#     - Converting tensors to scalar numbers.\n",
    "#     \"\"\"\n",
    "#     flattened = {}\n",
    "#     for key, value in meta_dict.items():\n",
    "#         if isinstance(value, list):\n",
    "#             if len(value) == 1:\n",
    "#                 flattened[key] = value[0]  # Replace list with its single item\n",
    "#             else:\n",
    "#                 flattened[key] = value  # Keep as is if multiple items\n",
    "#         elif isinstance(value, torch.Tensor):\n",
    "#             # Convert tensor to scalar\n",
    "#             if value.numel() == 1:\n",
    "#                 flattened[key] = value.item()\n",
    "#             else:\n",
    "#                 flattened[key] = value.tolist()  # Convert multi-element tensor to list\n",
    "#         else:\n",
    "#             flattened[key] = value  # Keep the value as is\n",
    "#     return flattened\n",
    "\n",
    "\n",
    "# import h5py\n",
    "# meta_array = np.array([], dtype=object)\n",
    "# # Open an HDF5 file in write mode\n",
    "# with h5py.File(f'test_HCP_raw_flatmaps_{load_file_frames}f.hdf5', 'w') as h5f:\n",
    "#     flatmaps_dset = None\n",
    "    \n",
    "#     total_samples = 0\n",
    "\n",
    "#     for i, batch in tqdm(enumerate(test_dl), total = 12000):\n",
    "#         images = batch[0]\n",
    "#         meta = batch[1]\n",
    "#         batch_size = images.shape[0]\n",
    "#         meta_serializable = meta.copy()\n",
    "        \n",
    "        \n",
    "#         # Step 2: Serialize the dictionary to a JSON string\n",
    "#         meta_str = json.dumps(flatten_meta(meta_serializable), indent=4)\n",
    "#         meta_array = np.append(meta_array, meta_str)\n",
    "#         if flatmaps_dset is None:\n",
    "#             # Initialize datasets with unlimited (None) maxshape along the first axis\n",
    "#             flatmaps_shape = (0,) + images.shape[1:]\n",
    "#             flatmaps_maxshape = (None,) + images.shape[1:]\n",
    "\n",
    "#             flatmaps_dset = h5f.create_dataset(\n",
    "#                 'flatmaps',\n",
    "#                 shape=flatmaps_shape,\n",
    "#                 maxshape=flatmaps_maxshape,\n",
    "#                 dtype=np.float16,\n",
    "#                 chunks=True  # Enable chunking for efficient resizing\n",
    "#             )\n",
    "\n",
    "#         # Resize datasets to accommodate new data\n",
    "#         flatmaps_dset.resize(total_samples + batch_size, axis=0)\n",
    "\n",
    "#         # Write data to the datasets\n",
    "#         flatmaps_dset[total_samples:total_samples + batch_size] = images.numpy().astype(np.float16)\n",
    "\n",
    "#         total_samples += batch_size\n",
    "        \n",
    "#     print(f\"Processed {total_samples} samples\")\n",
    "# np.save(f'metadata_test_HCP_raw_flatmaps_{load_file_frames}f.npy', meta_array)\n",
    "\n",
    "\n",
    "# import h5py\n",
    "# meta_array = np.array([], dtype=object)\n",
    "# # Open an HDF5 file in write mode\n",
    "# with h5py.File(f'train_HCP_raw_flatmaps_{load_file_frames}f.hdf5', 'w') as h5f:\n",
    "#     flatmaps_dset = None\n",
    "    \n",
    "#     total_samples = 0\n",
    "\n",
    "#     for i, batch in tqdm(enumerate(train_dl), total = 120000):\n",
    "#         images = batch[0]\n",
    "#         meta = batch[1]\n",
    "#         batch_size = images.shape[0]\n",
    "#         meta_serializable = meta.copy()\n",
    "        \n",
    "        \n",
    "#         # Step 2: Serialize the dictionary to a JSON string\n",
    "#         meta_str = json.dumps(flatten_meta(meta_serializable), indent=4)\n",
    "#         meta_array = np.append(meta_array, meta_str)\n",
    "#         if flatmaps_dset is None:\n",
    "#             # Initialize datasets with unlimited (None) maxshape along the first axis\n",
    "#             flatmaps_shape = (0,) + images.shape[1:]\n",
    "#             flatmaps_maxshape = (None,) + images.shape[1:]\n",
    "\n",
    "#             flatmaps_dset = h5f.create_dataset(\n",
    "#                 'flatmaps',\n",
    "#                 shape=flatmaps_shape,\n",
    "#                 maxshape=flatmaps_maxshape,\n",
    "#                 dtype=np.float16,\n",
    "#                 chunks=True  # Enable chunking for efficient resizing\n",
    "#             )\n",
    "\n",
    "#         # Resize datasets to accommodate new data\n",
    "#         flatmaps_dset.resize(total_samples + batch_size, axis=0)\n",
    "\n",
    "#         # Write data to the datasets\n",
    "#         flatmaps_dset[total_samples:total_samples + batch_size] = images.numpy().astype(np.float16)\n",
    "\n",
    "#         total_samples += batch_size\n",
    "        \n",
    "#     print(f\"Processed {total_samples} samples\")\n",
    "# np.save(f'metadata_train_HCP_raw_flatmaps_{load_file_frames}f.npy', meta_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98629867-6d64-45ef-823d-5f4fdb279ec7",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e66e2c0-6a73-42d7-8414-3b8acafdb0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded flatmaps\n"
     ]
    }
   ],
   "source": [
    "hdf5_base_path_raw_file = '.'  # use this /weka/proj-fmri/ckadirt/fMRI-foundation-model/src if you don't want to store them again\n",
    "load_file_frames = num_frames * 2\n",
    "\n",
    "try:\n",
    "    f_train = h5py.File(f'{hdf5_base_path_raw_file}/train_HCP_raw_flatmaps_{load_file_frames}f.hdf5', 'r')\n",
    "    flatmaps_train = f_train['flatmaps']\n",
    "    \n",
    "    f_test = h5py.File(f'{hdf5_base_path_raw_file}/test_HCP_raw_flatmaps_{load_file_frames}f.hdf5', 'r')\n",
    "    flatmaps_test = f_test['flatmaps']\n",
    "    \n",
    "    metadata_train = np.load(f'{hdf5_base_path_raw_file}/metadata_train_HCP_raw_flatmaps_{load_file_frames}f.npy', allow_pickle=True)\n",
    "    metadata_test = np.load(f'{hdf5_base_path_raw_file}/metadata_test_HCP_raw_flatmaps_{load_file_frames}f.npy', allow_pickle=True)\n",
    "    print(\"Loaded flatmaps\")\n",
    "except:\n",
    "    print(f\"Make sure you have the raw flatmaps precomputed for this num frames: {load_file_frames}. You can do it uncommenting the cell above\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9788d371-c6ce-44d9-8ebc-d0a13d202378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import argparse\n",
    "# import json\n",
    "# import os\n",
    "# import pickle\n",
    "# from pathlib import Path\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.linear_model import LogisticRegressionCV\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# target = \"trial_type\"\n",
    "# print(f\"Target: {target}\")\n",
    "\n",
    "# # train_features = pd.read_parquet(f\"{outdir}/{parquet_folder}/HCP/train.parquet\")\n",
    "# # test_features = pd.read_parquet(f\"{outdir}/{parquet_folder}/HCP_/test.parquet\")\n",
    "\n",
    "# # print(f\"train: {train_features.shape}, test: {test_features.shape}\")\n",
    "# # print(f\"test: {test_features.shape}\")\n",
    "\n",
    "# X_train = np.array(flatmaps_train[0:5000])\n",
    "# # flatten the flatmaps\n",
    "# X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "# X_test = np.array(flatmaps_test[0:1000])\n",
    "# X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "# print(f\"X_test: {X_test.shape}\")\n",
    "\n",
    "\n",
    "# # if target == \"task\":\n",
    "# #     labels_train = train_features[\"task\"].str.rstrip(\"1234\").values\n",
    "# #     labels_test = test_features[\"task\"].str.rstrip(\"1234\").values\n",
    "# # elif target == \"trial_type\":\n",
    "# #     labels_train = train_features[\"trial_type\"].values\n",
    "# #     labels_test = test_features[\"trial_type\"].values\n",
    "\n",
    "# labels_train = [json.loads(string)['trial_type'] for string in metadata_train[0:5000]]\n",
    "# labels_test = [json.loads(string)['trial_type'] for string in metadata_test[0:1000]]\n",
    "\n",
    "# label_enc = LabelEncoder()\n",
    "# y_train = label_enc.fit_transform(labels_train)\n",
    "# y_test = label_enc.transform(labels_test)\n",
    "\n",
    "# print(f\"classes ({len(label_enc.classes_)}): {label_enc.classes_}\")\n",
    "# print(\n",
    "#     f\"\\ny_train: {y_train.shape} {y_train[:20]}\\n\"\n",
    "#     f\"y_test: {y_test.shape} {y_test[:20]}\"\n",
    "# )\n",
    "# # del train_features, test_features\n",
    "\n",
    "# train_ind, val_ind = train_test_split(\n",
    "#     np.arange(len(X_train)), train_size=0.9, random_state=42\n",
    "# )\n",
    "# print(\n",
    "#     f\"\\ntrain_ind: {len(train_ind)} {train_ind[:10]}\\n\"\n",
    "#     f\"val_ind: {len(val_ind)} {val_ind[:10]}\"\n",
    "# )\n",
    "# X_train, X_val = X_train[train_ind], X_train[val_ind]\n",
    "# y_train, y_val = y_train[train_ind], y_train[val_ind]\n",
    "\n",
    "# print(\"Fitting PCA projection\")\n",
    "# pca = PCA(n_components=384, whiten=True, svd_solver=\"randomized\")\n",
    "# pca.fit(X_train)\n",
    "\n",
    "# X_train = pca.transform(X_train)\n",
    "# X_val = pca.transform(X_val)\n",
    "# X_test = pca.transform(X_test)\n",
    "\n",
    "# print(\"Fitting logistic regression\")\n",
    "# clf = LogisticRegressionCV()\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# train_acc = clf.score(X_train, y_train)\n",
    "# val_acc = clf.score(X_val, y_val)\n",
    "# test_acc = clf.score(X_test, y_test)\n",
    "\n",
    "# result = {\n",
    "#     \"target\": target,\n",
    "#     \"train_acc\": train_acc,\n",
    "#     \"val_acc\": val_acc,\n",
    "#     \"test_acc\": test_acc,\n",
    "# }\n",
    "# print(f\"Done:\\n{json.dumps(result)}\")\n",
    "# with open(f\"{outdir}/{parquet_folder}/HCP/downstream.json\", 'w') as out_json:\n",
    "#     json.dump(result, out_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a368c4fa-f2f3-4997-8ea4-ae6542efc32c",
   "metadata": {},
   "source": [
    "### Create the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b52b668f-c143-40fe-b3d4-c21c7a406d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class HCPFlatDataset(Dataset):\n",
    "    def __init__(self, flatmaps, metadata):\n",
    "        self.flatmaps = flatmaps\n",
    "        self.metadata = metadata\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.flatmaps[idx], json.loads(self.metadata[idx])\n",
    "\n",
    "# Loading to cpu for faster training, this can take several minutes.  Remove this [:] if you want to move one at the time.\n",
    "train_dataset = HCPFlatDataset(flatmaps_train, metadata_train)\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers//2)\n",
    "\n",
    "test_dataset = HCPFlatDataset(flatmaps_test, metadata_test)\n",
    "test_dl = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers//2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfe0e0bb-a67e-468d-a21a-b0add258eaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_dl:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71674f50-3bdc-428b-9fcd-585f2285e3d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 1, 32, 144, 320])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247a9b16-3c06-4c40-8c81-5b6169ef166e",
   "metadata": {},
   "source": [
    "### Load subject information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7d8760b-2e62-4ba5-ae34-b42376ad0eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the file containing subject information\n",
    "if target == \"age\" or target == \"sex\":\n",
    "    subject_information_HCP_path = os.path.join(hcp_flat_path, \"subjects_data_restricted.csv\")\n",
    "    try:\n",
    "        subject_information_HCP = pd.read_csv(subject_information_HCP_path)\n",
    "    except:\n",
    "        try:\n",
    "            subject_information_HCP = pd.read_csv('./unrestricted_clane9_4_23_2024_13_28_14.csv')   \n",
    "        except:\n",
    "            assert False, \"Subject information file not found\"\n",
    "\n",
    "    ###### This is for unrestricted\n",
    "    # age_related_columns = [\n",
    "    #     'Age', 'PicSeq_AgeAdj', 'CardSort_AgeAdj', 'Flanker_AgeAdj',\n",
    "    #     'ReadEng_AgeAdj', 'PicVocab_AgeAdj', 'ProcSpeed_AgeAdj',\n",
    "    #     'CogFluidComp_AgeAdj', 'CogEarlyComp_AgeAdj', 'CogTotalComp_AgeAdj',\n",
    "    #     'CogCrystalComp_AgeAdj', 'Endurance_AgeAdj', 'Dexterity_AgeAdj',\n",
    "    #     'Strength_AgeAdj', 'Odor_AgeAdj', 'Taste_AgeAdj'\n",
    "    # ]\n",
    "    \n",
    "    # sex_related_columns = [\n",
    "    #     'Gender'\n",
    "    # ]\n",
    "\n",
    "    ###### This is for restricted\n",
    "    gender_related_columns = [\n",
    "        'Gender'\n",
    "    ]\n",
    "\n",
    "    age_related_columns = [\n",
    "        'Age_in_Yrs',\n",
    "        'Menstrual_AgeBegan',\n",
    "        'Menstrual_AgeIrreg',\n",
    "        'Menstrual_AgeStop',\n",
    "        'SSAGA_Alc_Age_1st_Use',\n",
    "        'SSAGA_TB_Age_1st_Cig',\n",
    "        'SSAGA_Mj_Age_1st_Use',\n",
    "        'Endurance_AgeAdj',\n",
    "        'Dexterity_AgeAdj',\n",
    "        'Strength_AgeAdj',\n",
    "        'PicSeq_AgeAdj',\n",
    "        'CardSort_AgeAdj',\n",
    "        'Flanker_AgeAdj',\n",
    "        'ReadEng_AgeAdj',\n",
    "        'PicVocab_AgeAdj',\n",
    "        'ProcSpeed_AgeAdj',\n",
    "        'Odor_AgeAdj',\n",
    "        'Taste_AgeAdj'\n",
    "    ]\n",
    "\n",
    "    # # show the first few rows of the subject information\n",
    "    # subject_information_HCP[age_related_columns + sex_related_columns].head()\n",
    "\n",
    "    # Handle missing values (e.g., impute with mean)\n",
    "    mean_age = subject_information_HCP['Age_in_Yrs'].mean()\n",
    "    \n",
    "    # Initialize the scaler\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Perform z-score normalization\n",
    "    subject_information_HCP['Age_in_Yrs_z'] = scaler.fit_transform(subject_information_HCP[['Age_in_Yrs']])\n",
    "\n",
    "\n",
    "    \n",
    "def get_label_unrestricted(subject_id: List[str], target: str, method_for_age: str = 'mean') -> List:\n",
    "    \"\"\"\n",
    "    Get the label for the given subject id and target.\n",
    "\n",
    "    For sex 0 is F and 1 is M\n",
    "    \"\"\"\n",
    "\n",
    "    # convert to list of ints\n",
    "    subject_id = [int(x) for x in subject_id]\n",
    "\n",
    "    if target == \"age\":\n",
    "        age_array = []\n",
    "        for subject in subject_id:\n",
    "            c_age = subject_information_HCP[subject_information_HCP['Subject'] == subject]['Age'].values\n",
    "            # if the subject is not in the subject information file trigger an error\n",
    "            if len(c_age) == 0:\n",
    "                assert False, f\"Subject {subject} not found in subject information file\"\n",
    "            if len(c_age) > 1:\n",
    "                print(f\"Warning: Multiple entries for subject {subject}\")\n",
    "\n",
    "            c_age = c_age[0].split('-')\n",
    "            if len(c_age) < 2:\n",
    "                c_age = c_age[0].split('+')\n",
    "                age_array.append(int(c_age[0]))\n",
    "            else:\n",
    "                if method_for_age == 'mean':\n",
    "                    age_array.append(np.mean([int(x) for x in c_age]))\n",
    "                elif method_for_age == 'min':\n",
    "                    age_array.append(np.min([int(x) for x in c_age]))\n",
    "                elif method_for_age == 'max':\n",
    "                    age_array.append(np.max([int(x) for x in c_age]))\n",
    "                else:\n",
    "                    assert False, f\"Method {method_for_age} not recognized\"\n",
    "\n",
    "        return np.array(age_array)  \n",
    "    \n",
    "    elif target == 'sex':\n",
    "        sex_array = []\n",
    "        for subject in subject_id:\n",
    "            c_sex = subject_information_HCP[subject_information_HCP['Subject'] == subject]['Gender'].values\n",
    "            # if the subject is not in the subject information file trigger an error\n",
    "            if len(c_sex) == 0:\n",
    "                assert False, f\"Subject {subject} not found in subject information file\"\n",
    "            if len(c_sex) > 1:\n",
    "                print(f\"Warning: Multiple entries for subject {subject}\")\n",
    "            sex_array.append(int(c_sex[0] == 'M'))\n",
    "        return sex_array\n",
    "\n",
    "def get_label_restricted(subject_id: List[str], target: str, normalized: bool = True) -> List:\n",
    "    \"\"\"\n",
    "    Get the label for the given subject id and target.\n",
    "\n",
    "    For sex 0 is F and 1 is M\n",
    "    \"\"\"\n",
    "\n",
    "    # convert to list of ints\n",
    "    subject_id = [int(x) for x in subject_id]\n",
    "\n",
    "    if target == \"age\":\n",
    "        age_array = []\n",
    "        for subject in subject_id:\n",
    "            c_age = subject_information_HCP[subject_information_HCP['Subject'] == subject]['Age_in_Yrs' if not normalized else 'Age_in_Yrs_z'].values\n",
    "            # if the subject is not in the subject information file trigger an error\n",
    "            if len(c_age) == 0:\n",
    "                assert False, f\"Subject {subject} not found in subject information file\"\n",
    "            if len(c_age) > 1:\n",
    "                print(f\"Warning: Multiple entries for subject {subject}\")\n",
    "\n",
    "            age_array.append(np.int8(c_age[0]))\n",
    "\n",
    "        return np.array(age_array)  \n",
    "    \n",
    "    elif target == 'sex':\n",
    "        sex_array = []\n",
    "        for subject in subject_id:\n",
    "            c_sex = subject_information_HCP[subject_information_HCP['Subject'] == subject]['Gender'].values\n",
    "            # if the subject is not in the subject information file trigger an error\n",
    "            if len(c_sex) == 0:\n",
    "                assert False, f\"Subject {subject} not found in subject information file\"\n",
    "            if len(c_sex) > 1:\n",
    "                print(f\"Warning: Multiple entries for subject {subject}\")\n",
    "            sex_array.append(int(c_sex[0] == 'M'))\n",
    "        return sex_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40f04009-13f1-473d-9808-181a46d3e97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 21\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "if target == \"trial_type\":\n",
    "    \n",
    "    INCLUDE_CONDS = {\n",
    "        \"fear\",\n",
    "        \"neut\",\n",
    "        \"math\",\n",
    "        \"story\",\n",
    "        \"lf\",\n",
    "        \"lh\",\n",
    "        \"rf\",\n",
    "        \"rh\",\n",
    "        \"t\",\n",
    "        \"match\",\n",
    "        \"relation\",\n",
    "        \"mental\",\n",
    "        \"rnd\",\n",
    "        \"0bk_body\",\n",
    "        \"2bk_body\",\n",
    "        \"0bk_faces\",\n",
    "        \"2bk_faces\",\n",
    "        \"0bk_places\",\n",
    "        \"2bk_places\",\n",
    "        \"0bk_tools\",\n",
    "        \"2bk_tools\",\n",
    "    }\n",
    "\n",
    "    # test_data = []\n",
    "\n",
    "    # # Iterate over the DataLoader with a progress bar\n",
    "    # for sample in tqdm(train_dl, desc=\"Processing samples\"):\n",
    "    #     x = sample['image']\n",
    "    #     y = sample['meta']['trial_type']\n",
    "    #     key = sample['meta']['key']\n",
    "    #     print(x.shape, y, key)\n",
    "    #     break\n",
    "    # Initialize the label encoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(sorted(INCLUDE_CONDS))  # Ensure consistent ordering\n",
    "\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    print(f\"Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "592b3cd3-6232-4cff-8d90-9034067b3ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sample in tqdm(train_dl):\n",
    "#     x = sample[0]\n",
    "#     subject_id = sample[1]['sub']\n",
    "\n",
    "#     # benchmark time\n",
    "#     start = time.time()\n",
    "#     y = get_label(subject_id, 'age')\n",
    "#     end = time.time()\n",
    "#     print(f\"Time taken: {end - start}\")\n",
    "#     print(x.shape, y, subject_id, torch.Tensor(y).shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2d7e4f-eb34-498b-bbc6-127eb4a7bdc8",
   "metadata": {},
   "source": [
    "### Create pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a2c6527-fa75-42ba-be43-3d753ed8100c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimension: 1474560\n"
     ]
    }
   ],
   "source": [
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Flatten the input except for the batch dimension\n",
    "        x = x.view(x.size(0), -1)\n",
    "        out = self.linear(x)\n",
    "        return out  # Raw logits\n",
    "\n",
    "# Determine the input dimension from a single sample\n",
    "# Assuming images are of shape [1, 16, 144, 320]\n",
    "sample_batch = next(iter(train_dl))\n",
    "sample_image = sample_batch[0][0]  # Shape: [16, 144, 320]\n",
    "input_dim = sample_image.view(-1).size(0)\n",
    "print(f\"Input dimension: {input_dim}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8983a0b-c810-4424-8c31-32b9921ebd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_steps 13720\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "\n",
    "if target == \"trial_type\":\n",
    "    model = LinearClassifier(input_dim=input_dim, num_classes=num_classes)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "elif target == \"age\":\n",
    "    model = LinearClassifier(input_dim=input_dim, num_classes=1)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "elif target == \"sex\":\n",
    "    model = LinearClassifier(input_dim=input_dim, num_classes=1)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# import schedulefree\n",
    "# optimizer = schedulefree.AdamWScheduleFree(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=max_lr, weight_decay=weight_decay)\n",
    "\n",
    "num_iterations_per_epoch = math.ceil(flatmaps_train.shape[0]/batch_size)\n",
    "\n",
    "if lr_scheduler_type == 'linear':\n",
    "    lr_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "        optimizer,\n",
    "        total_iters=int(np.floor(num_epochs*num_iterations_per_epoch)),\n",
    "        last_epoch=-1\n",
    "    )\n",
    "elif lr_scheduler_type == 'cycle':\n",
    "    total_steps=int(np.floor(num_epochs*num_iterations_per_epoch))\n",
    "    print(\"total_steps\", total_steps)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, \n",
    "        max_lr=max_lr,\n",
    "        total_steps=total_steps,\n",
    "        final_div_factor=1000,\n",
    "        last_epoch=-1, pct_start=2/num_epochs\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b205b2c-730c-4d9e-89b7-c28031de78a7",
   "metadata": {},
   "source": [
    "### Wandb logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63ce8f26-a1b9-4e29-badc-7b9b30d0d3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in interactive notebook. Disabling W&B and ckpt saving.\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import uuid\n",
    "\n",
    "myuuid = uuid.uuid4()\n",
    "str(myuuid)\n",
    "if utils.is_interactive():\n",
    "    print(\"Running in interactive notebook. Disabling W&B and ckpt saving.\")\n",
    "    wandb_log = False\n",
    "    save_ckpt = False\n",
    "\n",
    "if wandb_log:\n",
    "    wandb_project = 'fMRI-foundation-model'\n",
    "    wandb_config = {\n",
    "        \"model_name\": f\"HCPflat_raw_{target}\",\n",
    "        \"batch_size\": batch_size,\n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"num_epochs\": num_epochs,\n",
    "        \"seed\": seed,\n",
    "        \"lr_scheduler_type\": lr_scheduler_type,\n",
    "        \"save_ckpt\": save_ckpt,\n",
    "        \"seed\": seed,\n",
    "        \"max_lr\": max_lr,\n",
    "        \"target\": target,\n",
    "        \"num_workers\": num_workers,\n",
    "        \"weight_decay\": weight_decay\n",
    "    }\n",
    "    print(\"wandb_config:\\n\", wandb_config)\n",
    "    random_id = random.randint(0, 100000)\n",
    "    wandb_id = \"HCPflat_raw\" + f\"_{model_suffix}_{target}_{myuuid}\"\n",
    "    print(\"wandb_id:\", wandb_id)\n",
    "    wandb.init(\n",
    "        id=wandb_id,\n",
    "        project=wandb_project,\n",
    "        name=\"HCPflat_raw\"+ f\"_{model_suffix}_{target}\",\n",
    "        config=wandb_config,\n",
    "        resume=\"allow\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d87e5c-94fc-4528-b2eb-65ef59c79634",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f43535f4-0f6e-4655-b4f0-926416685358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a575e5ad674811bf016897e0a76091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/40 - Training:   0%|          | 0/343 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [100/343] - Training Loss: 1.6492 - Training Accuracy: 36.77%\n",
      "Step [200/343] - Training Loss: 0.6378 - Training Accuracy: 58.88%\n",
      "Step [300/343] - Training Loss: 0.2687 - Training Accuracy: 70.42%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04b9ee71d3284d87823a5deb73e63e74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/40 - Validation:   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/40] - Training Loss: 1.1483, Training Accuracy: 73.67% - Validation Loss: 0.2339, Validation Accuracy: 96.55%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba9e9a38ea36453d98b1bd206e426a81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/40 - Training:   0%|          | 0/343 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f92be4d0a40>\n",
      "Traceback (most recent call last):\n",
      "  File \"/admin/home-ckadirt/foundation_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1477, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/admin/home-ckadirt/foundation_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1441, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 948, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt: \n",
      "Process Process-24:\n",
      "Process Process-22:\n",
      "Process Process-25:\n",
      "Process Process-23:\n",
      "Process Process-21:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 317, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 317, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 317, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 317, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/lib/python3.11/multiprocessing/util.py\", line 363, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/usr/lib/python3.11/multiprocessing/util.py\", line 363, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/usr/lib/python3.11/multiprocessing/util.py\", line 363, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/usr/lib/python3.11/multiprocessing/util.py\", line 363, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/usr/lib/python3.11/multiprocessing/util.py\", line 303, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/lib/python3.11/multiprocessing/util.py\", line 303, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/lib/python3.11/multiprocessing/util.py\", line 303, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/lib/python3.11/multiprocessing/util.py\", line 303, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/lib/python3.11/multiprocessing/util.py\", line 227, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/util.py\", line 227, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/util.py\", line 227, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/usr/lib/python3.11/multiprocessing/util.py\", line 227, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 1119, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 1119, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 1119, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 1139, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 1139, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 1119, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 1139, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 1139, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 317, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/lib/python3.11/multiprocessing/util.py\", line 363, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/usr/lib/python3.11/multiprocessing/util.py\", line 303, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/lib/python3.11/multiprocessing/util.py\", line 227, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 199, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 1119, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 1139, in _wait_for_tstate_lock\n",
      "    if lock.acquire(block, timeout):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f92be4d0a40>\n",
      "Traceback (most recent call last):\n",
      "  File \"/admin/home-ckadirt/foundation_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1477, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/admin/home-ckadirt/foundation_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1441, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 948, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/admin/home-ckadirt/foundation_env/lib/python3.11/site-packages/torch/utils/data/_utils/signal_handling.py\", line 67, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 3811972) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# Reset gradients before starting training\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEpoch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m - Training\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Shape: [batch_size, num_frames, 144, 320]\u001b[39;49;00m\n",
      "File \u001b[0;32m~/foundation_env/lib/python3.11/site-packages/tqdm/notebook.py:250\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    249\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 250\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# return super(tqdm...) will not catch exception\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/foundation_env/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/foundation_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/foundation_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1327\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1327\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/foundation_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1293\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1289\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1290\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1293\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1294\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1295\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/foundation_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1131\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1128\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1131\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.11/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py:440\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 440\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py:948\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    945\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    947\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 948\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    949\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    950\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/usr/lib/python3.11/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selector\u001b[38;5;241m.\u001b[39mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    running_train_loss = 0.0\n",
    "    correct_train = 0\n",
    "    mse_age_train = 0.0\n",
    "    total_train = 0\n",
    "    step = 0\n",
    "\n",
    "    # Training Phase\n",
    "    model.train()\n",
    "    optimizer.zero_grad()  # Reset gradients before starting training\n",
    "\n",
    "    for batch in tqdm(train_dl, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n",
    "        optimizer.zero_grad()\n",
    "        images = batch[0].to(device).float()  # Shape: [batch_size, num_frames, 144, 320]\n",
    "\n",
    "        # Prepare labels based on target type\n",
    "        if target == \"trial_type\":\n",
    "            labels = batch[1]['trial_type']  # List of labels\n",
    "            labels = label_encoder.transform(labels)\n",
    "            labels = torch.tensor(labels, dtype=torch.long).to(device)  # Shape: [batch_size]\n",
    "        elif target == \"age\":\n",
    "            labels = get_label_restricted(batch[1]['sub'], 'age')\n",
    "            labels = torch.tensor(labels, dtype=torch.float).to(device)  # Shape: [batch_size]\n",
    "        elif target == \"sex\":\n",
    "            labels = get_label_restricted(batch[1]['sub'], 'sex')\n",
    "            labels = torch.tensor(labels, dtype=torch.float).to(device)  # Shape: [batch_size]\n",
    "        # labels = labels.unsqueeze(1)\n",
    "        # Forward pass\n",
    "        outputs = model(images)  # Output shape depends on the target\n",
    "\n",
    "        # Compute loss\n",
    "        if target in [\"trial_type\", \"sex\"]:\n",
    "            # For classification, ensure outputs are logits\n",
    "            loss = criterion(outputs.squeeze(), labels.squeeze())\n",
    "        elif target == \"age\":\n",
    "            # For regression, ensure outputs are single values\n",
    "            loss = criterion(outputs.squeeze(), labels.squeeze())\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss\n",
    "        running_train_loss += loss.item() * images.size(0)\n",
    "\n",
    "        # Calculate and accumulate metrics\n",
    "        if target == \"trial_type\":\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "        elif target == \"age\":\n",
    "            mse_age_train += (torch.sum((outputs.squeeze() - labels) ** 2).item()) / outputs.shape[0]\n",
    "        elif target == \"sex\":\n",
    "            threshold = 0.5\n",
    "            predicted = (torch.sigmoid(outputs) > threshold).float().squeeze()\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        total_train += labels.size(0)\n",
    "        step += 1\n",
    "\n",
    "        # Print intermediate metrics every 100 steps\n",
    "        if step % 100 == 0:\n",
    "            if target in [\"trial_type\", \"sex\"]:\n",
    "                current_accuracy = 100 * correct_train / total_train if total_train > 0 else 0.0\n",
    "                print(f\"Step [{step}/{len(train_dl)}] - Training Loss: {loss.item():.4f} - Training Accuracy: {current_accuracy:.2f}%\")\n",
    "            elif target == \"age\":\n",
    "                current_mse = mse_age_train / total_train if total_train > 0 else 0.0\n",
    "                print(f\"Step [{step}/{len(train_dl)}] - Training Loss: {loss.item():.4f} - Training MSE: {current_mse:.4f}\")\n",
    "\n",
    "        if lr_scheduler_type is not None:\n",
    "                lr_scheduler.step()\n",
    "\n",
    "    # Calculate epoch-level metrics\n",
    "    epoch_train_loss = running_train_loss / total_train if total_train > 0 else 0.0\n",
    "\n",
    "    if target in [\"trial_type\", \"sex\"]:\n",
    "        train_accuracy = 100 * correct_train / total_train if total_train > 0 else 0.0\n",
    "    elif target == \"age\":\n",
    "        train_mse = mse_age_train / total_train if total_train > 0 else 0.0\n",
    "\n",
    "    # Validation Phase\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    mse_age_val = 0.0\n",
    "    total_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dl, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\"):\n",
    "            images = batch[0].to(device).float()  # Removed unsqueeze(1) unless specifically needed\n",
    "\n",
    "            # Prepare labels based on target type\n",
    "            if target == \"trial_type\":\n",
    "                labels = batch[1]['trial_type']  # List of labels\n",
    "                labels = label_encoder.transform(labels)\n",
    "                labels = torch.tensor(labels, dtype=torch.long).to(device)  # Shape: [batch_size]\n",
    "            elif target == \"age\":\n",
    "                labels = get_label_restricted(batch[1]['sub'], 'age')\n",
    "                labels = torch.tensor(labels, dtype=torch.float).to(device)  # Shape: [batch_size]\n",
    "            elif target == \"sex\":\n",
    "                labels = get_label_restricted(batch[1]['sub'], 'sex')\n",
    "                labels = torch.tensor(labels, dtype=torch.float).to(device)  # Shape: [batch_size]\n",
    "\n",
    "            # labels = labels.unsqueeze(1)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Compute loss\n",
    "            if target in [\"trial_type\", \"sex\"]:\n",
    "                loss = criterion(outputs.squeeze(), labels.squeeze())\n",
    "            elif target == \"age\":\n",
    "                loss = criterion(outputs.squeeze(), labels.squeeze())\n",
    "\n",
    "            # Accumulate loss\n",
    "            running_val_loss += loss.item() * images.size(0)\n",
    "\n",
    "            # Calculate and accumulate metrics\n",
    "            if target == \"trial_type\":\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "            elif target == \"age\":\n",
    "                mse_age_val += (torch.sum((outputs.squeeze() - labels) ** 2).item()) / outputs.shape[0]\n",
    "            elif target == \"sex\":\n",
    "                threshold = 0.5\n",
    "                predicted = (torch.sigmoid(outputs) > threshold).float().squeeze()\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "            total_val += labels.size(0)\n",
    "\n",
    "    # Calculate epoch-level validation metrics\n",
    "    epoch_val_loss = running_val_loss / total_val if total_val > 0 else 0.0\n",
    "\n",
    "    if target in [\"trial_type\", \"sex\"]:\n",
    "        val_accuracy = 100 * correct_val / total_val if total_val > 0 else 0.0\n",
    "    elif target == \"age\":\n",
    "        val_mse = mse_age_val / total_val if total_val > 0 else 0.0\n",
    "\n",
    "    # Print epoch-level metrics\n",
    "    if target in [\"trial_type\", \"sex\"]:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "              f\"- Training Loss: {epoch_train_loss:.4f}, Training Accuracy: {train_accuracy:.2f}% \"\n",
    "              f\"- Validation Loss: {epoch_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "    elif target == \"age\":\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "              f\"- Training Loss: {epoch_train_loss:.4f}, Training MSE: {train_mse:.4f} \"\n",
    "              f\"- Validation Loss: {epoch_val_loss:.4f}, Validation MSE: {val_mse:.4f}\")\n",
    "\n",
    "    # Log metrics with wandb\n",
    "    if wandb_log:\n",
    "        log_dict = {\n",
    "            \"epoch_train_loss\": epoch_train_loss,\n",
    "            \"epoch_val_loss\": epoch_val_loss,\n",
    "        }\n",
    "        if target in [\"trial_type\", \"sex\"]:\n",
    "            log_dict.update({\n",
    "                f\"train_accuracy_{target}\": train_accuracy,\n",
    "                f\"val_accuracy_{target}\": val_accuracy,\n",
    "            })\n",
    "        elif target == \"age\":\n",
    "            log_dict.update({\n",
    "                f\"train_mse_{target}\": train_mse,\n",
    "                f\"val_mse_{target}\": val_mse,\n",
    "            })\n",
    "        wandb.log(log_dict)\n",
    "\n",
    "# Save checkpoint if required\n",
    "if save_ckpt:\n",
    "    outdir = os.path.abspath(f'checkpoints/{\"HCPflat_raw\"+ f\"_{model_suffix}_{target}\"}_{random_id}')\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    print(\"Saving checkpoint to:\", outdir)\n",
    "    # Save model state\n",
    "    torch.save(model.state_dict(), os.path.join(outdir, \"model.pth\"))\n",
    "    # Save configuration\n",
    "    with open(os.path.join(outdir, \"config.yaml\"), 'w') as f:\n",
    "        yaml.dump(wandb_config, f)\n",
    "    print(f\"Model and config saved to {outdir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foundation_env",
   "language": "python",
   "name": "foundation_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
