{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8e236f1-385a-4d93-bb39-bea3ee384d76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import packages and setup gpu configuration.\n",
    "# This code block shouldnt need to be adjusted!\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import yaml\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "import webdataset as wds\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import utils\n",
    "from mae_utils.flat_models import *\n",
    "import h5py\n",
    "from mae_utils import flat_models\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import argparse\n",
    "\n",
    "# tf32 data type is faster than standard float32\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "# following fixes a Conv3D CUDNN_NOT_SUPPORTED error\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44bcbd9d-d802-4bb9-af40-b6f0b0746227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name_suffix: testing\n",
      "--found_model_name=NSDflat_large_gsrFalse_5sess_57734 --epoch_checkpoint epoch99.pth                     --hcp_flat_path=/weka/proj-medarc/shared/HCP-Flat                     --target=subject_id                     --model_suffix=testing                     --batch_size=16                     --max_lr=1e-5 --num_epochs=20 --no-save_ckpt --no-wandb_log --num_workers=10                     --weight_decay=1e-5                     --global_pool\n"
     ]
    }
   ],
   "source": [
    "# if running this interactively, can specify jupyter_args here for argparser to use\n",
    "if utils.is_interactive():\n",
    "    model_name_suffix = \"testing\"\n",
    "    print(\"model_name_suffix:\", model_name_suffix)\n",
    "    batch_size = 16\n",
    "    # global_batch_size and batch_size should already be defined in the 2nd cell block\n",
    "    jupyter_args = f\"--found_model_name=NSDflat_large_gsrFalse_5sess_57734 --epoch_checkpoint epoch99.pth \\\n",
    "                    --hcp_flat_path=/weka/proj-medarc/shared/HCP-Flat \\\n",
    "                    --target=subject_id \\\n",
    "                    --model_suffix={model_name_suffix} \\\n",
    "                    --batch_size={batch_size} \\\n",
    "                    --max_lr=1e-5 --num_epochs=20 --no-save_ckpt --no-wandb_log --num_workers=10 \\\n",
    "                    --weight_decay=1e-5 \\\n",
    "                    --global_pool\"\n",
    "    # --multisubject_ckpt=../train_logs/multisubject_subj01_1024_24bs_nolow\n",
    "    # suggested hyperparameters for trial_type: wd = 1e-5, max_lr = 3e-4\n",
    "    print(jupyter_args)\n",
    "    jupyter_args = jupyter_args.split()\n",
    "    \n",
    "    from IPython.display import clear_output # function to clear print outputs in cell\n",
    "    %load_ext autoreload \n",
    "    # this allows you to change functions in models.py or utils.py and have this notebook automatically update with your revisions\n",
    "    %autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe5db9ac-76fb-4eb8-8074-43268b246606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ ARGS ------- \n",
      " Namespace(found_model_name='NSDflat_large_gsrFalse_5sess_57734', epoch_checkpoint='epoch99.pth', model_suffix='testing', hcp_flat_path='/weka/proj-medarc/shared/HCP-Flat', nsd_flat_path='/weka/proj-medarc/shared/NSD-Flat', batch_size=16, wandb_log=False, num_epochs=20, lr_scheduler_type='cycle', save_ckpt=False, seed=42, max_lr=1e-05, target='subject_id', num_workers=10, weight_decay=1e-05, global_pool=True)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=\"Model Training Configuration\")\n",
    "parser.add_argument(\n",
    "    \"--found_model_name\", type=str, default=\"Testing_flat\",\n",
    "    help=\"name of model, used for ckpt saving and wandb logging (if enabled)\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--epoch_checkpoint\", type=str, default=\"epoch99.pth\",\n",
    "    help=\"the epoch number of the found_model_name checkpoint\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--model_suffix\", type=str, default=\"Testing_flat\",\n",
    "    help=\"name of model, used for ckpt saving and wandb logging (if enabled)\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--hcp_flat_path\", type=str, default=os.getcwd(),\n",
    "    help=\"Path to where NSD data is stored / where to download it to\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--nsd_flat_path\", type=str, default='/weka/proj-medarc/shared/NSD-Flat',\n",
    "    help=\"Path to where NSD data is stored / where to download it to\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--batch_size\", type=int, default=128,\n",
    "    help=\"Batch size can be increased by 10x if only training retreival submodule and not diffusion prior\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--wandb_log\",action=argparse.BooleanOptionalAction,default=False,\n",
    "    help=\"whether to log to wandb\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--num_epochs\",type=int,default=150,\n",
    "    help=\"number of epochs of training\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--lr_scheduler_type\",type=str,default='cycle',choices=['cycle','linear'],\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--save_ckpt\",action=argparse.BooleanOptionalAction,default=True,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--seed\",type=int,default=42,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--max_lr\",type=float,default=3e-4,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--target\",type=str,default='trial_type',  # \"trial_type\" or \"subject_id\" or see table on HCP_downstream.ipynb\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--num_workers\",type=int,default=10,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--weight_decay\",type=float,default=1e-5,\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--global_pool\",action=argparse.BooleanOptionalAction,default=False,\n",
    "    help=\"not implemented yet\",\n",
    ")\n",
    "\n",
    "if utils.is_interactive():\n",
    "    args = parser.parse_args(jupyter_args)\n",
    "else:\n",
    "    args = parser.parse_args()\n",
    "\n",
    "print(f\"------ ARGS ------- \\n {args}\")\n",
    "\n",
    "# create global variables without the args prefix\n",
    "for attribute_name in vars(args).keys():\n",
    "    globals()[attribute_name] = getattr(args, attribute_name)\n",
    "    \n",
    "# seed all random functions\n",
    "utils.seed_everything(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0e82ea6-3ee2-456b-be1e-a9460fb20ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## MODEL TO LOAD ##\n",
    "# if utils.is_interactive():\n",
    "#     model_name = \"HCPflat_large_gsrFalse_\"\n",
    "# else:\n",
    "#     model_name = sys.argv[1]\n",
    "    \n",
    "# target = 'sex' # This can be 'trial_type' 'age' 'sex'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f8f866d-c68f-4a35-bb51-398b2b2f8313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outdir /weka/proj-fmri/ckadirt/fMRI-foundation-model/src/checkpoints/NSDflat_large_gsrFalse_5sess_57734\n",
      "Loaded config.yaml from ckpt folder /weka/proj-fmri/ckadirt/fMRI-foundation-model/src/checkpoints/NSDflat_large_gsrFalse_5sess_57734\n",
      "\n",
      "__CONFIG__\n",
      "base_lr = 0.001\n",
      "batch_size = 32\n",
      "ckpt_interval = 25\n",
      "ckpt_saving = True\n",
      "cls_embed = False\n",
      "cls_forward = False\n",
      "contrastive_loss_weight = 1.0\n",
      "datasets_to_include = NSD\n",
      "decoder_cls_embed = False\n",
      "decoder_embed_dim = 512\n",
      "global_pool = False\n",
      "grad_accumulation_steps = 1\n",
      "grad_clip = 1.0\n",
      "gsr = False\n",
      "hcp_flat_path = /weka/proj-medarc/shared/HCP-Flat\n",
      "mask_ratio = 0.75\n",
      "model_name = NSDflat_large_gsrFalse_5sess\n",
      "model_size = large\n",
      "no_qkv_bias = False\n",
      "norm_pix_loss = False\n",
      "nsd_flat_path = /weka/proj-medarc/shared/NSD-Flat\n",
      "num_epochs = 100\n",
      "num_frames = 16\n",
      "num_samples_per_epoch = 200000\n",
      "num_sessions = 5\n",
      "num_workers = 8\n",
      "patch_size = 16\n",
      "pct_masks_to_decode = 1\n",
      "plotting = True\n",
      "pred_t_dim = 8\n",
      "print_interval = 20\n",
      "probe_base_lr = 0.0003\n",
      "probe_batch_size = 8\n",
      "probe_num_epochs = 30\n",
      "probe_num_samples_per_epoch = 100000\n",
      "resume_from_ckpt = True\n",
      "seed = 42\n",
      "sep_pos_embed = True\n",
      "source_embed_mode = add\n",
      "source_embed_train_mode = ce\n",
      "t_patch_size = 2\n",
      "test_num_samples_per_epoch = 50000\n",
      "test_set = False\n",
      "trunc_init = False\n",
      "use_contrastive_loss = False\n",
      "use_decoder_contrastive_loss = False\n",
      "use_source_embeds = False\n",
      "wandb_log = True\n",
      "wandb_rand = 0\n",
      "\n",
      "\n",
      "WORLD_SIZE=1\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "PID of this process = 350108\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# outdir = os.path.abspath(f'checkpoints/{model_name}')\n",
    "outdir = os.path.abspath(f'checkpoints/{found_model_name}')\n",
    "\n",
    "print(\"outdir\", outdir)\n",
    "# Load previous config.yaml if available\n",
    "if os.path.exists(f\"{outdir}/config.yaml\"):\n",
    "    config = yaml.load(open(f\"{outdir}/config.yaml\", 'r'), Loader=yaml.FullLoader)\n",
    "    print(f\"Loaded config.yaml from ckpt folder {outdir}\")\n",
    "    # create global variables from the config\n",
    "    print(\"\\n__CONFIG__\")\n",
    "    for attribute_name in config.keys():\n",
    "        print(f\"{attribute_name} = {config[attribute_name]}\")\n",
    "        globals()[attribute_name] = config[f'{attribute_name}']\n",
    "    print(\"\\n\")\n",
    "\n",
    "world_size = os.getenv('WORLD_SIZE')\n",
    "if world_size is None: \n",
    "    world_size = 1\n",
    "else:\n",
    "    world_size = int(world_size)\n",
    "print(f\"WORLD_SIZE={world_size}\")\n",
    "\n",
    "if utils.is_interactive():\n",
    "    # Following allows you to change functions in models.py or utils.py and \n",
    "    # have this notebook automatically update with your revisions\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "\n",
    "# batch_size = probe_batch_size\n",
    "# num_epochs = probe_num_epochs\n",
    "\n",
    "data_type = torch.float32 # change depending on your mixed_precision\n",
    "global_batch_size = batch_size * world_size\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# hcp_flat_path = \"/weka/proj-medarc/shared/HCP-Flat\"\n",
    "# seed = 42\n",
    "# num_frames = 16\n",
    "# gsr = False\n",
    "# num_workers = 10\n",
    "# batch_size = 128\n",
    "# save_ckpt = True\n",
    "# wandb_log = True\n",
    "print(\"PID of this process =\",os.getpid())\n",
    "utils.seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "128b23ed-5094-4f7d-8305-e5196d14e21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_pool = False\n",
      "gsr = False\n"
     ]
    }
   ],
   "source": [
    "# if os.getenv('global_pool') == \"False\":\n",
    "#     global_pool = False\n",
    "# else:\n",
    "#     global_pool = True\n",
    "print(f\"global_pool = {global_pool}\")\n",
    "\n",
    "try:\n",
    "    gsr\n",
    "except:\n",
    "    gsr = True\n",
    "    print(\"set gsr to True\")\n",
    "print(f\"gsr = {gsr}\")\n",
    "\n",
    "for attribute_name in vars(args).keys():\n",
    "    globals()[attribute_name] = getattr(args, attribute_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc00235a-a9e1-4dc4-8fd3-359c1d91bfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### UNCOMMENT THIS TO SAVE THE HCP-FLAT IN HDF5 FORMAT\n",
    "\n",
    "\n",
    "# from torch.utils.data import default_collate\n",
    "# from mae_utils.flat import load_hcp_flat_mask\n",
    "# from mae_utils.flat import create_hcp_flat\n",
    "# from mae_utils.flat import batch_unmask\n",
    "# import mae_utils.visualize as vis\n",
    "\n",
    "\n",
    "# batch_size = 1\n",
    "# print(f\"changed batch_size to {batch_size}\")\n",
    "# load_file_frames = num_frames * 2\n",
    "# print(f\"Calculating with {load_file_frames} frames, doubling to approximate TR\")\n",
    "\n",
    "# ## Test ##\n",
    "# datasets_to_include = \"HCP\"\n",
    "# assert \"HCP\" in datasets_to_include\n",
    "# test_dataset = create_hcp_flat(root=hcp_flat_path, \n",
    "#                 clip_mode=\"event\", frames=load_file_frames, shuffle=False, gsr=gsr, sub_list = 'test')\n",
    "# test_dl = wds.WebLoader(\n",
    "#     test_dataset.batched(batch_size, partial=False, collation_fn=default_collate),\n",
    "#     batch_size=None,\n",
    "#     shuffle=False,\n",
    "#     num_workers=num_workers,\n",
    "#     pin_memory=True,\n",
    "# )\n",
    "\n",
    "# ## Train ##\n",
    "# assert \"HCP\" in datasets_to_include\n",
    "# train_dataset = create_hcp_flat(root=hcp_flat_path, \n",
    "#                 clip_mode=\"event\", frames=load_file_frames, shuffle=False, gsr=gsr, sub_list = 'train')\n",
    "# train_dl = wds.WebLoader(\n",
    "#     train_dataset.batched(batch_size, partial=True, collation_fn=default_collate),\n",
    "#     batch_size=None,\n",
    "#     shuffle=False,\n",
    "#     num_workers=num_workers,\n",
    "#     pin_memory=True,\n",
    "# )\n",
    "\n",
    "# def flatten_meta(meta_dict):\n",
    "#     \"\"\"\n",
    "#     Flatten the meta dictionary by:\n",
    "#     - Replacing single-item lists with the item itself.\n",
    "#     - Converting tensors to scalar numbers.\n",
    "#     \"\"\"\n",
    "#     flattened = {}\n",
    "#     for key, value in meta_dict.items():\n",
    "#         if isinstance(value, list):\n",
    "#             if len(value) == 1:\n",
    "#                 flattened[key] = value[0]  # Replace list with its single item\n",
    "#             else:\n",
    "#                 flattened[key] = value  # Keep as is if multiple items\n",
    "#         elif isinstance(value, torch.Tensor):\n",
    "#             # Convert tensor to scalar\n",
    "#             if value.numel() == 1:\n",
    "#                 flattened[key] = value.item()\n",
    "#             else:\n",
    "#                 flattened[key] = value.tolist()  # Convert multi-element tensor to list\n",
    "#         else:\n",
    "#             flattened[key] = value  # Keep the value as is\n",
    "#     return flattened\n",
    "\n",
    "\n",
    "# import h5py\n",
    "# meta_array = np.array([], dtype=object)\n",
    "# # Open an HDF5 file in write mode\n",
    "# with h5py.File(f'test_HCP_raw_flatmaps_{load_file_frames}f.hdf5', 'w') as h5f:\n",
    "#     flatmaps_dset = None\n",
    "    \n",
    "#     total_samples = 0\n",
    "\n",
    "#     for i, batch in tqdm(enumerate(test_dl), total = 12000):\n",
    "#         images = batch[0]\n",
    "#         meta = batch[1]\n",
    "#         batch_size = images.shape[0]\n",
    "#         meta_serializable = meta.copy()\n",
    "        \n",
    "        \n",
    "#         # Step 2: Serialize the dictionary to a JSON string\n",
    "#         meta_str = json.dumps(flatten_meta(meta_serializable), indent=4)\n",
    "#         meta_array = np.append(meta_array, meta_str)\n",
    "#         if flatmaps_dset is None:\n",
    "#             # Initialize datasets with unlimited (None) maxshape along the first axis\n",
    "#             flatmaps_shape = (0,) + images.shape[1:]\n",
    "#             flatmaps_maxshape = (None,) + images.shape[1:]\n",
    "\n",
    "#             flatmaps_dset = h5f.create_dataset(\n",
    "#                 'flatmaps',\n",
    "#                 shape=flatmaps_shape,\n",
    "#                 maxshape=flatmaps_maxshape,\n",
    "#                 dtype=np.float16,\n",
    "#                 chunks=True  # Enable chunking for efficient resizing\n",
    "#             )\n",
    "\n",
    "#         # Resize datasets to accommodate new data\n",
    "#         flatmaps_dset.resize(total_samples + batch_size, axis=0)\n",
    "\n",
    "#         # Write data to the datasets\n",
    "#         flatmaps_dset[total_samples:total_samples + batch_size] = images.numpy().astype(np.float16)\n",
    "\n",
    "#         total_samples += batch_size\n",
    "        \n",
    "#     print(f\"Processed {total_samples} samples\")\n",
    "# np.save(f'metadata_test_HCP_raw_flatmaps_{load_file_frames}f.npy', meta_array)\n",
    "\n",
    "\n",
    "# import h5py\n",
    "# meta_array = np.array([], dtype=object)\n",
    "# # Open an HDF5 file in write mode\n",
    "# with h5py.File(f'train_HCP_raw_flatmaps_{load_file_frames}f.hdf5', 'w') as h5f:\n",
    "#     flatmaps_dset = None\n",
    "    \n",
    "#     total_samples = 0\n",
    "\n",
    "#     for i, batch in tqdm(enumerate(train_dl), total = 120000):\n",
    "#         images = batch[0]\n",
    "#         meta = batch[1]\n",
    "#         batch_size = images.shape[0]\n",
    "#         meta_serializable = meta.copy()\n",
    "        \n",
    "        \n",
    "#         # Step 2: Serialize the dictionary to a JSON string\n",
    "#         meta_str = json.dumps(flatten_meta(meta_serializable), indent=4)\n",
    "#         meta_array = np.append(meta_array, meta_str)\n",
    "#         if flatmaps_dset is None:\n",
    "#             # Initialize datasets with unlimited (None) maxshape along the first axis\n",
    "#             flatmaps_shape = (0,) + images.shape[1:]\n",
    "#             flatmaps_maxshape = (None,) + images.shape[1:]\n",
    "\n",
    "#             flatmaps_dset = h5f.create_dataset(\n",
    "#                 'flatmaps',\n",
    "#                 shape=flatmaps_shape,\n",
    "#                 maxshape=flatmaps_maxshape,\n",
    "#                 dtype=np.float16,\n",
    "#                 chunks=True  # Enable chunking for efficient resizing\n",
    "#             )\n",
    "\n",
    "#         # Resize datasets to accommodate new data\n",
    "#         flatmaps_dset.resize(total_samples + batch_size, axis=0)\n",
    "\n",
    "#         # Write data to the datasets\n",
    "#         flatmaps_dset[total_samples:total_samples + batch_size] = images.numpy().astype(np.float16)\n",
    "\n",
    "#         total_samples += batch_size\n",
    "        \n",
    "#     print(f\"Processed {total_samples} samples\")\n",
    "# np.save(f'metadata_train_HCP_raw_flatmaps_{load_file_frames}f.npy', meta_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75be5d80-64ef-4e07-a15d-054dbc8b4d8a",
   "metadata": {},
   "source": [
    "### Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e66e2c0-6a73-42d7-8414-3b8acafdb0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded flatmaps\n"
     ]
    }
   ],
   "source": [
    "hdf5_base_path_raw_file = '.'  # use this /weka/proj-fmri/ckadirt/fMRI-foundation-model/src if you don't want to store them again\n",
    "load_file_frames = num_frames * 2\n",
    "\n",
    "try:\n",
    "    f_train = h5py.File(f'{hdf5_base_path_raw_file}/train_HCP_raw_flatmaps_{load_file_frames}f.hdf5', 'r')\n",
    "    flatmaps_train = f_train['flatmaps']\n",
    "    \n",
    "    f_test = h5py.File(f'{hdf5_base_path_raw_file}/test_HCP_raw_flatmaps_{load_file_frames}f.hdf5', 'r')\n",
    "    flatmaps_test = f_test['flatmaps']\n",
    "    \n",
    "    metadata_train = np.load(f'{hdf5_base_path_raw_file}/metadata_train_HCP_raw_flatmaps_{load_file_frames}f.npy', allow_pickle=True)\n",
    "    metadata_test = np.load(f'{hdf5_base_path_raw_file}/metadata_test_HCP_raw_flatmaps_{load_file_frames}f.npy', allow_pickle=True)\n",
    "    print(\"Loaded flatmaps\")\n",
    "except:\n",
    "    print(f\"Make sure you have the raw flatmaps precomputed for this num frames: {load_file_frames}. You can do it uncommenting the cell above\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59483d51-3f65-4275-aaed-572ddbb74b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target is subject_id, so creating a new split on datasets\n",
      "Total combined samples: 3300\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "# creating a new test train data split for target subject_id\n",
    "split_type = 'random' \n",
    "if target == 'subject_id':\n",
    "    if split_type == 'uniform':\n",
    "        print(\"Target is subject_id, so creating a new split on datasets\")\n",
    "        # 1. Combine old metadata\n",
    "        combined_metadata = []\n",
    "        # combined_metadata will hold tuples of (json_string, source, index_in_that_source)\n",
    "    \n",
    "        # Append all train metadata\n",
    "        for i, m_str in enumerate(metadata_train):\n",
    "            combined_metadata.append((m_str, 'train', i))\n",
    "        \n",
    "        train_len = len(metadata_train)\n",
    "        \n",
    "        # Append all test metadata\n",
    "        for i, m_str in enumerate(metadata_test):\n",
    "            combined_metadata.append((m_str, 'test', i))\n",
    "        \n",
    "        # Now we have a big list containing all samples from both old train & old test\n",
    "        print(f\"Total combined samples: {len(combined_metadata)}\")\n",
    "    \n",
    "        subject_to_indices = defaultdict(list)\n",
    "        \n",
    "        for global_idx, (m_str, source, idx_in_source) in enumerate(combined_metadata):\n",
    "            m_dict = json.loads(m_str)\n",
    "            subj = m_dict[\"sub\"]      # e.g. \"285446\"\n",
    "            subject_to_indices[subj].append(global_idx)\n",
    "    \n",
    "        train_ratio = 0.9\n",
    "        new_train_indices = []\n",
    "        new_test_indices = []\n",
    "        \n",
    "        for subj, global_idxs in subject_to_indices.items():\n",
    "            # Shuffle the subjectâ€™s indexes in-place so we can do a random split\n",
    "            random.shuffle(global_idxs)\n",
    "            cutoff = max(1, int(len(global_idxs) * train_ratio))        \n",
    "            \n",
    "            subj_train = global_idxs[:cutoff]\n",
    "            subj_test  = global_idxs[cutoff:]\n",
    "            \n",
    "            new_train_indices.extend(subj_train)\n",
    "            new_test_indices.extend(subj_test)\n",
    "\n",
    "    if split_type == 'random':\n",
    "        combined_metadata = []\n",
    "        # Label each sample by whether it came from old train/test\n",
    "        for i, m_str in enumerate(metadata_train):\n",
    "            combined_metadata.append((m_str, 'train', i)) \n",
    "        for i, m_str in enumerate(metadata_test):\n",
    "            combined_metadata.append((m_str, 'test', i)) \n",
    "    \n",
    "        print(f\"Total combined samples: {len(combined_metadata)}\")\n",
    "        p_train = 0.9  # Probability a given sample goes to train\n",
    "    \n",
    "        new_train_indices = []\n",
    "        new_test_indices = []\n",
    "    \n",
    "        # Randomly assign each sample to train or test\n",
    "        for global_idx, (m_str, source, idx_in_source) in enumerate(combined_metadata):\n",
    "            if random.random() < p_train:\n",
    "                new_train_indices.append(global_idx)\n",
    "            else:\n",
    "                new_test_indices.append(global_idx)\n",
    "\n",
    "        # 1) Build a set of subjects already in train\n",
    "        subject_in_train = set()\n",
    "        for g_idx in new_train_indices:\n",
    "            meta_str, source, idx_in_source = combined_metadata[g_idx]\n",
    "            subj = json.loads(meta_str)[\"sub\"]\n",
    "            subject_in_train.add(subj)\n",
    "        \n",
    "        # 2) Group test indices by subject\n",
    "        subject_to_test_indices = defaultdict(list)\n",
    "        for g_idx in new_test_indices:\n",
    "            meta_str, source, idx_in_source = combined_metadata[g_idx]\n",
    "            subj = json.loads(meta_str)[\"sub\"]\n",
    "            subject_to_test_indices[subj].append(g_idx)\n",
    "        \n",
    "        # 3) For any subject not in train, move exactly 1 test sample to train\n",
    "        for subj, test_g_idxs in subject_to_test_indices.items():\n",
    "            alone_samples = 0\n",
    "            if subj not in subject_in_train:\n",
    "                # Move one random test sample for this subject into train\n",
    "                chosen_idx = random.choice(test_g_idxs)\n",
    "                new_test_indices.remove(chosen_idx)\n",
    "                new_train_indices.append(chosen_idx)\n",
    "                subject_in_train.add(subj)\n",
    "                alone_samples = alone_samples + 1\n",
    "        print(f\"Number of subjects on train with just 1 sample: {alone_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b52b668f-c143-40fe-b3d4-c21c7a406d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class HCPSplitDataset(Dataset):\n",
    "    def __init__(self, combined_metadata, indices, flatmaps_train, flatmaps_test):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            combined_metadata: list of (json_string, source, idx_in_source)\n",
    "            indices: the list of global indices that define this split\n",
    "            flatmaps_train: h5py dataset for train\n",
    "            flatmaps_test:  h5py dataset for test\n",
    "        \"\"\"\n",
    "        self.combined_metadata = combined_metadata\n",
    "        self.indices = indices\n",
    "        self.flatmaps_train = flatmaps_train\n",
    "        self.flatmaps_test = flatmaps_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # i here is the i-th sample in our new train/test list\n",
    "        global_idx = self.indices[i]\n",
    "        m_str, source, idx_in_source = self.combined_metadata[global_idx]\n",
    "\n",
    "        # Parse JSON\n",
    "        m_dict = json.loads(m_str)\n",
    "\n",
    "        # Retrieve the actual flatmaps from the correct HDF5\n",
    "        if source == 'train':\n",
    "            # old train set\n",
    "            x = self.flatmaps_train[idx_in_source]\n",
    "        else:\n",
    "            # old test set\n",
    "            x = self.flatmaps_test[idx_in_source]\n",
    "\n",
    "        return x, m_dict\n",
    "\n",
    "class HCPFlatDataset(Dataset):\n",
    "    def __init__(self, flatmaps, metadata):\n",
    "        self.flatmaps = flatmaps\n",
    "        self.metadata = metadata\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.flatmaps[idx], json.loads(self.metadata[idx])\n",
    "\n",
    "if target == 'subject_id':\n",
    "    train_dataset_new = HCPSplitDataset(\n",
    "        combined_metadata,\n",
    "        new_train_indices,\n",
    "        flatmaps_train,\n",
    "        flatmaps_test\n",
    "    )\n",
    "\n",
    "    test_dataset_new = HCPSplitDataset(\n",
    "        combined_metadata,\n",
    "        new_test_indices,\n",
    "        flatmaps_train,\n",
    "        flatmaps_test\n",
    "    )\n",
    "\n",
    "    # And then the dataloaders\n",
    "    train_dl = DataLoader(train_dataset_new, batch_size=batch_size, shuffle=True, num_workers=num_workers//2)\n",
    "    test_dl = DataLoader(test_dataset_new, batch_size=batch_size, shuffle=False, num_workers=num_workers//2)\n",
    "\n",
    "else:\n",
    "    # original approach\n",
    "    train_dataset = HCPFlatDataset(flatmaps_train, metadata_train)\n",
    "    train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers//2)\n",
    "\n",
    "    test_dataset = HCPFlatDataset(flatmaps_test, metadata_test)\n",
    "    test_dl = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5418e44e-23d5-4a5c-9c71-2e1ecad20166",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_dl:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc6513ec-99da-4006-bebd-57479ad3b2e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 32, 144, 320])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cee7abc3-3be5-451c-96fb-775415fa25da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "###### This is for restricted\n",
    "# Categorical columns (e.g., demographic categories, binary diagnoses)\n",
    "categorical_columns = [\n",
    "    \"Gender\",\n",
    "    \"Race\",\n",
    "    \"Ethnicity\",\n",
    "    \"SSAGA_PanicDisorder\",  # Panic disorder diagnosis (yes/no)\n",
    "    \"SSAGA_Depressive_Ep\"   # Depressive episode diagnosis (yes/no)\n",
    "]\n",
    "\n",
    "# Numerical columns (continuous, counts, raw scores, standardized scores, etc.)\n",
    "numerical_columns = [\n",
    "    # Basic demographics\n",
    "    \"Age_in_Yrs\",\n",
    "    \n",
    "    # Cognitive / \"IQ-like\" Measures\n",
    "    \"PMAT24_A_CR\",\n",
    "    \"CardSort_Unadj\",\n",
    "    \"CardSort_AgeAdj\",\n",
    "    \"ListSort_Unadj\",\n",
    "    \"ListSort_AgeAdj\",\n",
    "    \"PicSeq_Unadj\",\n",
    "    \"PicSeq_AgeAdj\",\n",
    "    \n",
    "    # Personality Traits (Big Five)\n",
    "    \"NEOFAC_A\",\n",
    "    \"NEOFAC_O\",\n",
    "    \"NEOFAC_C\",\n",
    "    \"NEOFAC_N\",\n",
    "    \"NEOFAC_E\",\n",
    "    # If you have all 60 NEO item-level responses:\n",
    "    # \"NEORAW_01\", \"NEORAW_02\", ..., \"NEORAW_60\",\n",
    "    \n",
    "    # Psychopathology / Mental Health\n",
    "    \"ASR_Anxd_Raw\",\n",
    "    \"ASR_Attn_Raw\",\n",
    "    \"ASR_Aggr_Raw\",\n",
    "    \"DSM_Depr_Raw\",\n",
    "    \"DSM_Anxi_Raw\",\n",
    "    \"SSAGA_Depressive_Sx\",  # Symptom count or severity\n",
    "    \n",
    "    # Substance Use Phenotypes\n",
    "    \"SSAGA_Alc_12_Frq\",\n",
    "    \"SSAGA_Alc_12_Max_Drinks\",\n",
    "    \"SSAGA_Times_Used_Illicits\",\n",
    "    \"SSAGA_Times_Used_Cocaine\",\n",
    "    \"Total_Drinks_7days\",\n",
    "    \"Total_Any_Tobacco_7days\",\n",
    "    \n",
    "    # Anthropometric / Basic Health\n",
    "    \"BMI\",\n",
    "    \"Height\",\n",
    "    \"Weight\",\n",
    "    \"BPSystolic\",\n",
    "    \"BPDiastolic\",\n",
    "    \"HbA1C\",\n",
    "    \"ThyroidHormone\",\n",
    "    \n",
    "    # Sleep / Quality of Life\n",
    "    \"PSQI_Score\",\n",
    "    # If you have separate PSQI component scores, list them here too, e.g.:\n",
    "    # \"PSQI_Component1\", \"PSQI_Component2\", ...\n",
    "    \"PainInterf_Tscore\",\n",
    "    \"LifeSatisf_Unadj\",\n",
    "    \"MeanPurp_Unadj\"\n",
    "]\n",
    "\n",
    "\n",
    "if target in ['subject_id', 'trial_type']:\n",
    "    target_type = 'special'\n",
    "elif target in categorical_columns:\n",
    "    target_type = 'categorical'\n",
    "elif target in numerical_columns:\n",
    "    target_type = 'numerical'\n",
    "\n",
    "\n",
    "# open the file containing subject information\n",
    "if not (target in ['subject_id', 'trial_type']):\n",
    "    subject_information_HCP_path = os.path.join(hcp_flat_path, \"subjects_data_restricted.csv\")\n",
    "    try:\n",
    "        subject_information_HCP = pd.read_csv(subject_information_HCP_path)\n",
    "    except:\n",
    "        try:\n",
    "            subject_information_HCP = pd.read_csv('./unrestricted_clane9_4_23_2024_13_28_14.csv')   \n",
    "        except:\n",
    "            assert False, \"Subject information file not found\"\n",
    "\n",
    "    # # show the first few rows of the subject information\n",
    "    # subject_information_HCP[age_related_columns + sex_related_columns].head()\n",
    "\n",
    "    # Handle missing values (e.g., impute with mean)\n",
    "    \n",
    "\n",
    "    if target in numerical_columns:\n",
    "        # Count NaNs or missing values\n",
    "        n_missing = subject_information_HCP[target].isnull().sum()\n",
    "        print(f\"Number of missing values in {target}: {n_missing}. Replacing with mean.\")\n",
    "        mean_ = subject_information_HCP[target].mean()\n",
    "        # Replace missing values or NaNs with the mean\n",
    "        subject_information_HCP[target].fillna(mean_, inplace=True)\n",
    "        # Initialize the scaler\n",
    "        scaler = StandardScaler()    \n",
    "        # Perform z-score normalization\n",
    "        subject_information_HCP[f'{target}_z'] = scaler.fit_transform(subject_information_HCP[[target]])\n",
    "\n",
    "    if target in categorical_columns:\n",
    "        # Perform label encoding\n",
    "        label_enc = LabelEncoder()\n",
    "        subject_information_HCP[f'{target}_encoded'] = label_enc.fit_transform(subject_information_HCP[target])\n",
    "\n",
    "def train_test_split_by_subject(df, test_ratio=0.1, random_state=42):\n",
    "    \"\"\"\n",
    "    Split a dataframe into train and test so that\n",
    "    every subject in test also appears in train at least once.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Your dataset, containing at least the columns:\n",
    "        ['sub', ...]\n",
    "    test_ratio : float\n",
    "        Percentage of each subject's rows to allocate to test.\n",
    "    random_state : int\n",
    "        Random seed for reproducibility.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_df : pd.DataFrame\n",
    "    test_df : pd.DataFrame\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    train_dfs = []\n",
    "    test_dfs = []\n",
    "    \n",
    "    # Group by subject\n",
    "    for subject, df_sub in df.groupby('sub'):\n",
    "        n = len(df_sub)\n",
    "        \n",
    "        # If the subject only has 1 row, put it all in train\n",
    "        if n == 1:\n",
    "            train_dfs.append(df_sub)\n",
    "        else:\n",
    "            # Decide how many rows go to test\n",
    "            n_test = int(round(test_ratio * n))\n",
    "            # Ensure at least 1 row ends up in train\n",
    "            # (i.e. if rounding leads to n_test == n, reduce n_test by 1)\n",
    "            if n_test >= n:\n",
    "                n_test = n - 1\n",
    "            \n",
    "            # Randomly sample n_test rows for test\n",
    "            test_rows = df_sub.sample(n_test, random_state=random_state)\n",
    "            # The remaining go to train\n",
    "            train_rows = df_sub.drop(test_rows.index)\n",
    "            \n",
    "            test_dfs.append(test_rows)\n",
    "            train_dfs.append(train_rows)\n",
    "    \n",
    "    # Combine all splits\n",
    "    train_df = pd.concat(train_dfs).sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "    test_df = pd.concat(test_dfs).sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "    \n",
    "def get_label_restricted(subject_id: List[str], target: str, normalized: bool = True) -> List:\n",
    "    \"\"\"\n",
    "    Get the label for the given subject id and target\n",
    "    \"\"\"\n",
    "    subject_id = [int(x) for x in subject_id]\n",
    "\n",
    "    if target in numerical_columns:\n",
    "        target_array = []\n",
    "        for subject in subject_id:\n",
    "            c_target = subject_information_HCP[subject_information_HCP['Subject'] == subject][f'{target}' if not normalized else f'{target}_z'].values\n",
    "            # if the subject is not in the subject information file trigger an error\n",
    "            if len(c_target) == 0:\n",
    "                assert False, f\"Subject {subject} not found in subject information file\"\n",
    "            if len(c_target) > 1:\n",
    "                print(f\"Warning: Multiple entries for subject {subject}\")\n",
    "\n",
    "            target_array.append(np.float32(c_target[0]))\n",
    "\n",
    "        return np.array(target_array)\n",
    "    \n",
    "    elif target in categorical_columns:\n",
    "        target_array = []\n",
    "        for subject in subject_id:\n",
    "            c_target = subject_information_HCP[subject_information_HCP['Subject'] == subject][f'{target}_encoded'].values\n",
    "            # if the subject is not in the subject information file trigger an error\n",
    "            if len(c_target) == 0:\n",
    "                assert False, f\"Subject {subject} not found in subject information file\"\n",
    "            if len(c_target) > 1:\n",
    "                print(f\"Warning: Multiple entries for subject {subject}\")\n",
    "\n",
    "            target_array.append(np.int8(c_target[0]))\n",
    "\n",
    "        return np.array(target_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e64ecf72-3c2f-4634-8440-e07df3a24711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 376\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "if target == \"trial_type\":\n",
    "    INCLUDE_CONDS = {\n",
    "        \"fear\",\n",
    "        \"neut\",\n",
    "        \"math\",\n",
    "        \"story\",\n",
    "        \"lf\",\n",
    "        \"lh\",\n",
    "        \"rf\",\n",
    "        \"rh\",\n",
    "        \"t\",\n",
    "        \"match\",\n",
    "        \"relation\",\n",
    "        \"mental\",\n",
    "        \"rnd\",\n",
    "        \"0bk_body\",\n",
    "        \"2bk_body\",\n",
    "        \"0bk_faces\",\n",
    "        \"2bk_faces\",\n",
    "        \"0bk_places\",\n",
    "        \"2bk_places\",\n",
    "        \"0bk_tools\",\n",
    "        \"2bk_tools\",\n",
    "    }\n",
    "    # Initialize the label encoder\n",
    "    label_enc = LabelEncoder()\n",
    "    label_enc.fit(sorted(INCLUDE_CONDS))  # Ensure consistent ordering\n",
    "elif target == 'subject_id':\n",
    "    all_subs = [json.loads(i_data[0])['sub'] for i_data in combined_metadata]\n",
    "    label_enc = LabelEncoder()\n",
    "    label_enc.fit(all_subs)\n",
    "    \n",
    "if target_type in ['categorical', 'special']:\n",
    "    num_classes = len(label_enc.classes_)\n",
    "    print(f\"Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a535979-1fc4-4e72-9fe2-96bb8897534b",
   "metadata": {},
   "source": [
    "### Creating and loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b92beee5-c65a-4714-b640-ae545dc1b120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_size (144, 320) patch_size (16, 16) frames 16 t_patch_size 2\n",
      "model initialized\n"
     ]
    }
   ],
   "source": [
    "from mae_utils.flat import load_hcp_flat_mask, load_nsd_flat_mask\n",
    "from mae_utils.flat import create_hcp_flat\n",
    "from mae_utils.flat import batch_unmask\n",
    "import mae_utils.visualize as vis\n",
    "\n",
    "\n",
    "if \"HCP\" in datasets_to_include:\n",
    "    flat_mask = load_hcp_flat_mask()\n",
    "    nsd_mask = None\n",
    "    hcp_mask = None\n",
    "elif \"NSD\" in datasets_to_include:\n",
    "    flat_mask = load_nsd_flat_mask()\n",
    "    nsd_mask = None\n",
    "    hcp_mask = None\n",
    "elif \"BOTH\" in datasets_to_include:\n",
    "    flat_mask = None\n",
    "    nsd_mask = load_nsd_flat_mask()\n",
    "    hcp_mask = load_hcp_flat_mask()\n",
    "\n",
    "assert model_size in {\"huge\", \"large\", \"small\"}, \"undefined model_size\"\n",
    "\n",
    "if model_size==\"huge\":\n",
    "    mae_model = flat_models.mae_vit_huge_fmri(\n",
    "        patch_size=patch_size,\n",
    "        decoder_embed_dim=decoder_embed_dim,\n",
    "        t_patch_size=t_patch_size,\n",
    "        pred_t_dim=pred_t_dim,\n",
    "        decoder_depth=4,\n",
    "        cls_embed=cls_embed,\n",
    "        norm_pix_loss=norm_pix_loss,\n",
    "        no_qkv_bias=no_qkv_bias,\n",
    "        sep_pos_embed=sep_pos_embed,\n",
    "        trunc_init=trunc_init,\n",
    "        pct_masks_to_decode=pct_masks_to_decode,\n",
    "        img_mask=flat_mask,\n",
    "        nsd_mask=nsd_mask,\n",
    "        hcp_mask=hcp_mask,\n",
    "        use_source_embeds=use_source_embeds,\n",
    "        use_decoder_contrastive_loss=use_decoder_contrastive_loss,\n",
    "        source_embed_train_mode=source_embed_train_mode,\n",
    "        source_embed_mode=source_embed_mode,\n",
    "        use_contrastive_loss=use_contrastive_loss\n",
    "    )\n",
    "elif model_size==\"large\":\n",
    "    mae_model = flat_models.mae_vit_large_fmri(\n",
    "        patch_size=patch_size,\n",
    "        decoder_embed_dim=decoder_embed_dim,\n",
    "        t_patch_size=t_patch_size,\n",
    "        pred_t_dim=pred_t_dim,\n",
    "        decoder_depth=4,\n",
    "        cls_embed=cls_embed,\n",
    "        norm_pix_loss=norm_pix_loss,\n",
    "        no_qkv_bias=no_qkv_bias,\n",
    "        sep_pos_embed=sep_pos_embed,\n",
    "        trunc_init=trunc_init,\n",
    "        pct_masks_to_decode=pct_masks_to_decode,\n",
    "        img_mask=flat_mask,\n",
    "        nsd_mask=nsd_mask,\n",
    "        hcp_mask=hcp_mask,\n",
    "        use_source_embeds=use_source_embeds,\n",
    "        use_decoder_contrastive_loss=use_decoder_contrastive_loss,\n",
    "        source_embed_train_mode=source_embed_train_mode,\n",
    "        source_embed_mode=source_embed_mode,\n",
    "        use_contrastive_loss=use_contrastive_loss\n",
    "    )\n",
    "elif model_size==\"small\":\n",
    "    mae_model = flat_models.mae_vit_small_fmri(\n",
    "        patch_size=patch_size,\n",
    "        decoder_embed_dim=decoder_embed_dim,\n",
    "        t_patch_size=t_patch_size,\n",
    "        pred_t_dim=pred_t_dim,\n",
    "        decoder_depth=4,\n",
    "        cls_embed=cls_embed,\n",
    "        norm_pix_loss=norm_pix_loss,\n",
    "        no_qkv_bias=no_qkv_bias,\n",
    "        sep_pos_embed=sep_pos_embed,\n",
    "        trunc_init=trunc_init,\n",
    "        pct_masks_to_decode=pct_masks_to_decode,\n",
    "        img_mask=flat_mask,\n",
    "        nsd_mask=nsd_mask,\n",
    "        hcp_mask=hcp_mask,\n",
    "        use_source_embeds=use_source_embeds,\n",
    "        use_decoder_contrastive_loss=use_decoder_contrastive_loss,\n",
    "        source_embed_train_mode=source_embed_train_mode,\n",
    "        source_embed_mode=source_embed_mode,\n",
    "        use_contrastive_loss=use_contrastive_loss\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54cc1fdc-e43d-44ae-a562-a492a59580a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latest_checkpoint: epoch99.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_350108/2629719241.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded checkpoint epoch99.pth from /weka/proj-fmri/ckadirt/fMRI-foundation-model/src/checkpoints/NSDflat_large_gsrFalse_5sess_57734\n",
      "\n"
     ]
    }
   ],
   "source": [
    "checkpoint_files = [f for f in os.listdir(outdir) if f.endswith('.pth')]\n",
    "\n",
    "latest_checkpoint = epoch_checkpoint\n",
    "    \n",
    "print(f\"latest_checkpoint: {latest_checkpoint}\")\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint_path = os.path.join(outdir, latest_checkpoint)\n",
    "\n",
    "state = torch.load(checkpoint_path)\n",
    "mae_model.load_state_dict(state[\"model_state_dict\"], strict=False)\n",
    "mae_model.to(device)\n",
    "\n",
    "print(f\"\\nLoaded checkpoint {latest_checkpoint} from {outdir}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fde712b-36a7-46e7-a39a-7679e6cbe070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 16, 144, 320])\n",
      "Input dimension: 1024\n"
     ]
    }
   ],
   "source": [
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Flatten the input except for the batch dimension\n",
    "        x = x.view(x.size(0), -1)\n",
    "        out = self.linear(x)\n",
    "        return out  # Raw logits\n",
    "\n",
    "# Determine the input dimension from a single sample\n",
    "# Assuming images are of shape [1, 16, 144, 320]\n",
    "with torch.no_grad():\n",
    "    images = batch[0]\n",
    "    images_shape = images.shape\n",
    "    images_reshaped = images.view(len(images), 2, images_shape[2]//2, images_shape[3], images_shape[4])\n",
    "    images = images_reshaped.mean(dim=1).unsqueeze(1).to(torch.float)\n",
    "    print(images.shape)\n",
    "    input_dim = np.prod(mae_model(images.to(device),forward_features=True, global_pool=global_pool, cls_forward=cls_forward).shape[1:])\n",
    "    print(f\"Input dimension: {input_dim}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8576297-ac37-40d9-b871-f23812c16502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mae_model.n_mask_patches, cls_forward, global_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a2c6527-fa75-42ba-be43-3d753ed8100c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullModel(nn.Module):\n",
    "    def __init__(self, lc_model, mae_model):\n",
    "        super(FullModel, self).__init__()\n",
    "        self.lc_model = lc_model\n",
    "        self.mae_model = mae_model\n",
    "        \n",
    "        \n",
    "    def forward(self, x, gsr):\n",
    "        x = self.mae_model(x, forward_features=True, global_pool=global_pool, cls_forward=cls_forward)\n",
    "        x = self.lc_model(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8983a0b-c810-4424-8c31-32b9921ebd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_steps 3760\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "\n",
    "if (target in [\"trial_type\", \"subject_id\"]) or (target in categorical_columns):\n",
    "    lc_model = LinearClassifier(input_dim=input_dim, num_classes=num_classes)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "elif target in numerical_columns:\n",
    "    lc_model = LinearClassifier(input_dim=input_dim, num_classes=1)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "# elif target == \"sex\":\n",
    "#     lc_model = LinearClassifier(input_dim=input_dim, num_classes=1)\n",
    "#     criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "# lc_model = LinearClassifier(input_dim=input_dim, num_classes=num_classes)\n",
    "\n",
    "model = FullModel(lc_model, mae_model)\n",
    "\n",
    "# Move the model to the GPU\n",
    "model.to(device)\n",
    "\n",
    "# Define optimizer with L2 regularization (weight_decay)\n",
    "# learning_rate = 1e-4\n",
    "# weight_decay = 1e-5  # Adjust based on your needs\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=max_lr, weight_decay=weight_decay)\n",
    "\n",
    "num_iterations_per_epoch = math.ceil(flatmaps_train.shape[0]/batch_size)\n",
    "\n",
    "if lr_scheduler_type == 'linear':\n",
    "    lr_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "        optimizer,\n",
    "        total_iters=int(np.floor(num_epochs*num_iterations_per_epoch)),\n",
    "        last_epoch=-1\n",
    "    )\n",
    "elif lr_scheduler_type == 'cycle':\n",
    "    total_steps=int(np.floor(num_epochs*num_iterations_per_epoch))\n",
    "    print(\"total_steps\", total_steps)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, \n",
    "        max_lr=max_lr,\n",
    "        total_steps=total_steps,\n",
    "        final_div_factor=1000,\n",
    "        last_epoch=-1, pct_start=2/num_epochs\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# num_epochs = 20  # Adjust as needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98629867-6d64-45ef-823d-5f4fdb279ec7",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b42844f-0b96-4e68-ae38-3af24720a803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b544ad7c-f39d-4c1c-a38a-2d0f9dc863ac'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "myuuid = uuid.uuid4()\n",
    "str(myuuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63ce8f26-a1b9-4e29-badc-7b9b30d0d3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in interactive notebook. Disabling W&B and ckpt saving.\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "if utils.is_interactive():\n",
    "    print(\"Running in interactive notebook. Disabling W&B and ckpt saving.\")\n",
    "    wandb_log = False\n",
    "    save_ckpt = False\n",
    "\n",
    "if wandb_log:\n",
    "    wandb_project = 'fMRI-foundation-model'\n",
    "    wandb_config = {\n",
    "        \"model_name\": f'{found_model_name}_HCP_FT_{target}',\n",
    "        \"batch_size\": batch_size,\n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"num_epochs\": num_epochs,\n",
    "        \"seed\": seed,\n",
    "        \"lr_scheduler_type\": lr_scheduler_type,\n",
    "        \"save_ckpt\": save_ckpt,\n",
    "        \"seed\": seed,\n",
    "        \"max_lr\": max_lr,\n",
    "        \"target\": target,\n",
    "        \"num_workers\": num_workers,\n",
    "        \"weight_decay\": weight_decay\n",
    "    }\n",
    "    print(\"wandb_config:\\n\", wandb_config)\n",
    "    random_id = random.randint(0, 100000)\n",
    "    wandb_id = f\"{found_model_name}_{model_suffix}_{target}_HCPFT_{myuuid}\"\n",
    "    print(\"wandb_id:\", wandb_id)\n",
    "    wandb.init(\n",
    "        id=wandb_id,\n",
    "        project=wandb_project,\n",
    "        name=f\"{found_model_name}_{model_suffix}_{target}_HCPFT\",\n",
    "        config=wandb_config,\n",
    "        resume=\"allow\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f43535f4-0f6e-4655-b4f0-926416685358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b78193081c1d4fa7a91a90071fce1571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/20 - Training:   0%|          | 0/177 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [100/177] - Training Loss: 6.4023 - Training Accuracy: 0.25%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eda47856b6f144959962f8f439ff89a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/20 - Validation:   0%|          | 0/31 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] - Training Loss: 6.2037, Training Accuracy: 0.39% - Validation Loss: 6.0060, Validation Accuracy: 0.62%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f559a83bf7a4134b170cf667112c5b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/20 - Training:   0%|          | 0/177 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [100/177] - Training Loss: 5.9440 - Training Accuracy: 0.88%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45dac8adb334439a855cd0b531d0340f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/20 - Validation:   0%|          | 0/31 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20] - Training Loss: 5.8740, Training Accuracy: 0.96% - Validation Loss: 5.7398, Validation Accuracy: 1.04%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aebc1339211457f815e4bd66cefa89e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/20 - Training:   0%|          | 0/177 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [100/177] - Training Loss: 5.7783 - Training Accuracy: 1.75%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4faee9ea0e745bd801b8d5f471fbf24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/20 - Validation:   0%|          | 0/31 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20] - Training Loss: 5.4559, Training Accuracy: 2.52% - Validation Loss: 5.2250, Validation Accuracy: 4.36%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc25750b26bb4f2e84548a8061edcc56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/20 - Training:   0%|          | 0/177 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [100/177] - Training Loss: 4.5978 - Training Accuracy: 7.19%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "070d88388c514464888e7eb4abd9c1af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/20 - Validation:   0%|          | 0/31 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20] - Training Loss: 4.5628, Training Accuracy: 8.16% - Validation Loss: 4.3656, Validation Accuracy: 11.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70b9bdef8c044af683efd02d7f6aa607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/20 - Training:   0%|          | 0/177 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [100/177] - Training Loss: 3.9176 - Training Accuracy: 19.50%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "436f32f05ad14a7c9949085e3c412e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/20 - Validation:   0%|          | 0/31 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20] - Training Loss: 3.3801, Training Accuracy: 21.15% - Validation Loss: 3.5673, Validation Accuracy: 19.92%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c75d27324dcf423f9053372b56c6b787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/20 - Training:   0%|          | 0/177 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [100/177] - Training Loss: 2.4073 - Training Accuracy: 39.88%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "786a27eab07542fb8f7ba8827f30a8ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/20 - Validation:   0%|          | 0/31 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20] - Training Loss: 2.2736, Training Accuracy: 42.48% - Validation Loss: 2.6854, Validation Accuracy: 34.44%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d431cbaab3d64c55b06a3cf0aa3d0fc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/20 - Training:   0%|          | 0/177 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [100/177] - Training Loss: 0.7608 - Training Accuracy: 62.94%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e00a896c0c45f08f9870b893948994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/20 - Validation:   0%|          | 0/31 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20] - Training Loss: 1.3764, Training Accuracy: 64.34% - Validation Loss: 2.4143, Validation Accuracy: 39.83%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ebd5c5b67c245b7b2060656dd954162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/20 - Training:   0%|          | 0/177 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [100/177] - Training Loss: 0.7133 - Training Accuracy: 81.31%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad217717dadd4e30a9370e8f3edabd3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/20 - Validation:   0%|          | 0/31 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20] - Training Loss: 0.7527, Training Accuracy: 82.33% - Validation Loss: 2.1406, Validation Accuracy: 46.27%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "396a034a1e5c431fb1d3fabc21cbae06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/20 - Training:   0%|          | 0/177 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [100/177] - Training Loss: 0.3515 - Training Accuracy: 92.94%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "128ac9a79c8841e99c707cd18ecb7377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/20 - Validation:   0%|          | 0/31 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20] - Training Loss: 0.3773, Training Accuracy: 92.51% - Validation Loss: 1.9166, Validation Accuracy: 52.28%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec91764905b495eabeb7e5a5c580f1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/20 - Training:   0%|          | 0/177 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: Exception ignored in: Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ff62c7c4e00><function _MultiProcessingDataLoaderIter.__del__ at 0x7ff62c7c4e00><function _MultiProcessingDataLoaderIter.__del__ at 0x7ff62c7c4e00><function _MultiProcessingDataLoaderIter.__del__ at 0x7ff62c7c4e00>\n",
      "\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/admin/home-ckadirt/foundation_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1477, in __del__\n",
      "Traceback (most recent call last):\n",
      "  File \"/admin/home-ckadirt/foundation_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1477, in __del__\n",
      "  File \"/admin/home-ckadirt/foundation_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1477, in __del__\n",
      "  File \"/admin/home-ckadirt/foundation_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1477, in __del__\n",
      "                self._shutdown_workers()self._shutdown_workers()Exception ignored in: self._shutdown_workers()self._shutdown_workers()\n",
      "\n",
      "\n",
      "\n",
      "  File \"/admin/home-ckadirt/foundation_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1460, in _shutdown_workers\n",
      "  File \"/admin/home-ckadirt/foundation_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1460, in _shutdown_workers\n",
      "  File \"/admin/home-ckadirt/foundation_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1460, in _shutdown_workers\n",
      "  File \"/admin/home-ckadirt/foundation_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1460, in _shutdown_workers\n",
      "            <function _MultiProcessingDataLoaderIter.__del__ at 0x7ff62c7c4e00>    if w.is_alive():if w.is_alive():if w.is_alive():if w.is_alive():\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "      File \"/admin/home-ckadirt/foundation_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1477, in __del__\n",
      "                  self._shutdown_workers()     \n",
      "      File \"/admin/home-ckadirt/foundation_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1460, in _shutdown_workers\n",
      " ^^^^^^^    ^^^^if w.is_alive():^^^^\n",
      "^^^^^ ^^^^ ^^^^ ^^^^^ ^^^^ ^^^^ ^^^^^ \n",
      "^\n",
      "^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "\n",
      "^          File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'    ^    \n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'^assert self._parent_pid == os.getpid(), 'can only test a child process'  \n",
      "^ \n",
      "  ^    ^    ^     ^    ^    ^     \n",
      "      File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "         ^ ^assert self._parent_pid == os.getpid(), 'can only test a child process'^  ^\n",
      "^ ^^^ ^^^^ ^^^^^ ^^^^ ^^^^ ^^^^ ^^^^ ^^^^ ^^^^ ^^^^^^ ^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^\n",
      "AssertionError^^^AssertionError: ^^^: can only test a child process^\n",
      "^can only test a child process\n",
      "AssertionError^\n",
      "\n",
      ": ^AssertionErrorcan only test a child process^: \n",
      "^can only test a child process^\n",
      "^^^^^^^\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [100/177] - Training Loss: 0.1097 - Training Accuracy: 96.69%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae1a61f7f5f42d6a9ed913e25ca58cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/20 - Validation:   0%|          | 0/31 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20] - Training Loss: 0.2007, Training Accuracy: 96.70% - Validation Loss: 1.8844, Validation Accuracy: 54.77%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "022fc7fec7ed4baa8069019767bc628b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/20 - Training:   0%|          | 0/177 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [100/177] - Training Loss: 0.0242 - Training Accuracy: 99.50%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b160f3034d504b488c59aca411c929e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/20 - Validation:   0%|          | 0/31 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20] - Training Loss: 0.0830, Training Accuracy: 99.50% - Validation Loss: 1.7742, Validation Accuracy: 57.68%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2da1c3a6b1a447697a5ca815b173f74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/20 - Training:   0%|          | 0/177 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [100/177] - Training Loss: 0.0443 - Training Accuracy: 99.94%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7bd8fab8f5e4cde97183cbca9b68eae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/20 - Validation:   0%|          | 0/31 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20] - Training Loss: 0.0375, Training Accuracy: 99.96% - Validation Loss: 1.7499, Validation Accuracy: 57.68%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aca7282b70a7436abaab1f8678d7ddfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/20 - Training:   0%|          | 0/177 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [100/177] - Training Loss: 0.0225 - Training Accuracy: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be0c88aafcb46f5b3daa7f495bc884d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/20 - Validation:   0%|          | 0/31 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20] - Training Loss: 0.0242, Training Accuracy: 100.00% - Validation Loss: 1.7274, Validation Accuracy: 57.68%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "849d45f40912491d8f0e40df357115e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/20 - Training:   0%|          | 0/177 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [100/177] - Training Loss: 0.0216 - Training Accuracy: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad9c948212b24497968118c94f199362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/20 - Validation:   0%|          | 0/31 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20] - Training Loss: 0.0194, Training Accuracy: 100.00% - Validation Loss: 1.7368, Validation Accuracy: 58.51%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bd433afc3e04d9796b4b1225a0f5690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/20 - Training:   0%|          | 0/177 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [100/177] - Training Loss: 0.0183 - Training Accuracy: 100.00%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e226679e9c44499b15c5e76ef2d1838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/20 - Validation:   0%|          | 0/31 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20] - Training Loss: 0.0167, Training Accuracy: 100.00% - Validation Loss: 1.7349, Validation Accuracy: 58.09%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95948e92a4984bad9725ba3891ad0645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/20 - Training:   0%|          | 0/177 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Accumulate loss\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m running_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Calculate and accumulate metrics\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecial\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    running_train_loss = 0.0\n",
    "    correct_train = 0\n",
    "    mse_age_train = 0.0\n",
    "    total_train = 0\n",
    "    step = 0\n",
    "\n",
    "    # with torch.amp.autocast(device_type='cuda'):\n",
    "    # Training Phase\n",
    "    model.train()\n",
    "    for batch in tqdm(train_dl, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n",
    "        optimizer.zero_grad()\n",
    "        images = batch[0].to(device).float()  # Shape: [batch_size, 1, 16, 144, 320]\n",
    "\n",
    "        images_shape = images.shape\n",
    "        images_reshaped = images.view(len(images), 2, images_shape[2]//2, images_shape[3], images_shape[4])\n",
    "        images = images_reshaped.mean(dim=1).unsqueeze(1) \n",
    "        \n",
    "        # Prepare labels based on target type\n",
    "        if target == \"trial_type\":\n",
    "            labels = batch[1]['trial_type']  # List of labels\n",
    "            labels = label_enc.transform(labels)\n",
    "            labels = torch.tensor(labels, dtype=torch.long).to(device)  # Shape: [batch_size]\n",
    "        if target == 'subject_id':\n",
    "            labels = label_enc.transform(batch[1]['sub'])\n",
    "            labels = torch.tensor(labels, dtype=torch.long).to(device)  # Shape: [batch_size]\n",
    "        elif target in numerical_columns:\n",
    "            labels = get_label_restricted(batch[1]['sub'], target)\n",
    "            labels = torch.tensor(labels, dtype=torch.float).to(device)  # Shape: [batch_size]\n",
    "        elif target in categorical_columns:\n",
    "            labels = get_label_restricted(batch[1]['sub'], target)\n",
    "            labels = torch.tensor(labels, dtype=torch.long).to(device)  # Shape: [batch_size]\n",
    "        \n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images, gsr=gsr)  # Shape: [num_train_samples, num_classes]\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(outputs.squeeze(), labels.squeeze())\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate loss\n",
    "        running_train_loss += loss.item()\n",
    "\n",
    "        \n",
    "        # Calculate and accumulate metrics\n",
    "        if target_type in [\"categorical\", \"special\"]:\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "        elif target_type == \"numerical\":\n",
    "            mse_age_train += (torch.sum((outputs.squeeze() - labels) ** 2).item())\n",
    "\n",
    "        total_train += labels.size(0)\n",
    "        step += 1\n",
    "\n",
    "        # Print intermediate metrics every 100 steps\n",
    "        if step % 100 == 0:\n",
    "            if target_type in ['categorical', 'special']:\n",
    "                current_accuracy = 100 * correct_train / total_train if total_train > 0 else 0.0\n",
    "                print(f\"Step [{step}/{len(train_dl)}] - Training Loss: {loss.item():.4f} - Training Accuracy: {current_accuracy:.2f}%\")\n",
    "            elif target_type == 'numerical':\n",
    "                current_mse = mse_age_train / total_train if total_train > 0 else 0.0\n",
    "                print(f\"Step [{step}/{len(train_dl)}] - Training Loss: {loss.item():.4f} - Training MSE: {current_mse:.4f}\")\n",
    "\n",
    "        if lr_scheduler_type is not None:\n",
    "                lr_scheduler.step()\n",
    "\n",
    "\n",
    "    # Calculate epoch-level metrics\n",
    "    epoch_train_loss = running_train_loss / step if step > 0 else 0.0\n",
    "\n",
    "    if target_type in ['categorical', 'special']:\n",
    "        train_accuracy = 100 * correct_train / total_train if total_train > 0 else 0.0\n",
    "    elif target_type == 'numerical':\n",
    "        train_mse = mse_age_train / total_train if total_train > 0 else 0.0\n",
    "    \n",
    "    # Validation Phase\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    mse_age_val = 0.0\n",
    "    total_val = 0\n",
    "    step_val = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dl, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\"):\n",
    "            images = batch[0].to(device).float()\n",
    "\n",
    "            images_shape = images.shape\n",
    "            images_reshaped = images.view(len(images), 2, images_shape[2]//2, images_shape[3], images_shape[4])\n",
    "            images = images_reshaped.mean(dim=1).unsqueeze(1) \n",
    "            \n",
    "            # Prepare labels based on target type\n",
    "            if target == \"trial_type\":\n",
    "                labels = batch[1]['trial_type']  # List of labels\n",
    "                labels = label_enc.transform(labels)\n",
    "                labels = torch.tensor(labels, dtype=torch.long).to(device)  # Shape: [batch_size]\n",
    "            if target == 'subject_id':\n",
    "                labels = label_enc.transform(batch[1]['sub'])\n",
    "                labels = torch.tensor(labels, dtype=torch.long).to(device)  # Shape: [batch_size]\n",
    "            elif target in numerical_columns:\n",
    "                labels = get_label_restricted(batch[1]['sub'], target)\n",
    "                labels = torch.tensor(labels, dtype=torch.float).to(device)  # Shape: [batch_size]\n",
    "            elif target in categorical_columns:\n",
    "                labels = get_label_restricted(batch[1]['sub'], target)\n",
    "                labels = torch.tensor(labels, dtype=torch.long).to(device)  # Shape: [batch_size]\n",
    "                \n",
    "            # Forward pass\n",
    "            outputs = model(images, gsr=gsr)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = criterion(outputs.squeeze(), labels.squeeze())\n",
    "\n",
    "            # Accumulate loss\n",
    "            running_val_loss += loss.item()\n",
    "\n",
    "            # Calculate and accumulate metrics\n",
    "            if target_type in [\"categorical\", \"special\"]:\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "            elif target_type == \"numerical\":\n",
    "                mse_age_val += (torch.sum((outputs.squeeze() - labels) ** 2).item())\n",
    "\n",
    "            total_val += labels.size(0)\n",
    "            step_val += 1\n",
    "\n",
    "    # Calculate epoch-level validation metrics\n",
    "    epoch_val_loss = running_val_loss / step_val if step_val > 0 else 0.0\n",
    "\n",
    "    if target_type in ['categorical', 'special']:\n",
    "        val_accuracy = 100 * correct_val / total_val if total_val > 0 else 0.0\n",
    "    elif target_type == 'numerical':\n",
    "        val_mse = mse_age_val / total_val if total_val > 0 else 0.0\n",
    "\n",
    "    # Print epoch-level metrics\n",
    "    if target_type in ['categorical', 'special']:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "              f\"- Training Loss: {epoch_train_loss:.4f}, Training Accuracy: {train_accuracy:.2f}% \"\n",
    "              f\"- Validation Loss: {epoch_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "    elif target_type == 'numerical':\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "              f\"- Training Loss: {epoch_train_loss:.4f}, Training MSE: {train_mse:.4f} \"\n",
    "              f\"- Validation Loss: {epoch_val_loss:.4f}, Validation MSE: {val_mse:.4f}\")\n",
    "\n",
    "    # Log metrics with wandb\n",
    "    if wandb_log:\n",
    "        log_dict = {\n",
    "            \"epoch_train_loss\": epoch_train_loss,\n",
    "            \"epoch_val_loss\": epoch_val_loss,\n",
    "        }\n",
    "        if target in [\"trial_type\", \"sex\"]:\n",
    "            log_dict.update({\n",
    "                f\"train_accuracy_{target}\": train_accuracy,\n",
    "                f\"val_accuracy_{target}\": val_accuracy,\n",
    "            })\n",
    "        elif target == \"age\":\n",
    "            log_dict.update({\n",
    "                f\"train_mse_{target}\": train_mse,\n",
    "                f\"val_mse_{target}\": val_mse,\n",
    "            })\n",
    "        wandb.log(log_dict)\n",
    "        \n",
    "    if save_ckpt:\n",
    "        outdir = os.path.abspath(f'checkpoints/{f\"{found_model_name}_{model_suffix}_{target}_HCPFT\"}')\n",
    "        os.makedirs(outdir, exist_ok=True)\n",
    "        print(\"outdir\", outdir)\n",
    "        # Save model and config\n",
    "        torch.save(model.state_dict(), f\"{outdir}/model.pth\")\n",
    "        with open(f\"{outdir}/config.yaml\", 'w') as f:\n",
    "            yaml.dump(wandb_config, f)\n",
    "        print(f\"Saved model and config to {outdir}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foundation_env",
   "language": "python",
   "name": "foundation_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
