# Model Config
model_name: "patch8_100eps_4gpu_accelerate_b"
use_cls_token: False
use_contrastive_loss: False
constrastive_loss_weight: 1.0

# Training Configs
global_batch_size: 4
num_workers: 4
num_epochs: 300
seed: 42
max_lr: 3.0e-5 # Keep the x.0 else will be converted to string
num_samples_per_epoch: 1024
cache_dir: "cache/"
ema:
  - 0.998
  - 1.0
ipe_scale: 1.25

# Saving progress
ckpt_saving: True
ckpt_interval: 50
resume_from_ckpt: False
wandb_log: True

# MAE Config
tube_start_masking_ratio: 0.85
tube_end_masking_ratio: 0.85
decoder_mask_ratio: 0.85

# Model Config
depth: 12
heads: 12
dim: 512
mlp_dim: 512
patch_size: 8
frame_patch_size: 1
use_rope_emb: False

# Data Config
img_size: [64, 64, 48] # Image Size
num_frames: 4
train_urls: "s3://proj-fmri/fmri_foundation_datasets/openneuro/{000005..000664}.tar"
test_urls: "s3://proj-fmri/fmri_foundation_datasets/openneuro/{000000..000004}.tar"