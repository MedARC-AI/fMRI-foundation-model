# Model Config
model_name: "ME_patch8_60ep_nopretrain"
mae_model_name: "patch8"

# Training Configs
global_batch_size: 64
num_workers: 8
mixed_precision: "fp16"
num_epochs: 60
seed: 42
max_lr: 3.0e-4 # Keep the x.0 else will be converted to string
num_samples_per_epoch: 512

# Saving progress
ckpt_saving: True
ckpt_interval: 99
resume_from_ckpt: False
wandb_log: True

# Model Config
in_dim: 409600
hidden_dim: 512
drop: .15
mixup_pct: 0.33

# Data Config
nsd_wds_path: "/weka/proj-fmri/shared/mindeyev2_dataset/wds"
nsd_raw_path: "/weka/proj-fmri/shared/mindeyev2_dataset"
nsd_image_path: "/weka/proj-fmri/shared/mindeyev2_dataset"
num_sessions: 10