# Model Config
model_name: "mar24_encoder_decoder_mamba64_lr3e-4"
use_cls_token: False
use_contrastive_loss: False
constrastive_loss_weight: 1.0

# Training Configs
global_batch_size: 64
num_workers: 4
num_epochs: 400
seed: 42
max_lr: 3.0e-4 # Keep the x.0 else will be converted to string
num_samples_per_epoch: 1024
cache_dir: "cache"

# Saving progress
ckpt_saving: True
ckpt_interval: 50
resume_from_ckpt: False
wandb_log: True
wandb_group_name: "mamba"

# MAE Config
tube_start_masking_ratio: 0.75
tube_end_masking_ratio: 0.75
decoder_mask_ratio: 0.75

# Model Config
encoder_model: "vit_base"
decoder_model: "vit_small"
patch_size: 8
frame_patch_size: 1
use_rope_emb: False

# Data Config
img_size: [64, 64, 48] # Image Size
num_frames: 4
train_urls: "s3://proj-fmri/fmri_foundation_datasets/openneuro_MNI_wds/{000005..000173}.tar"
test_urls: "s3://proj-fmri/fmri_foundation_datasets/openneuro_MNI_wds/{000000..000004}.tar"