{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d078f7e7-ccbc-4a88-9d12-93510fe1814b",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b56bbd92-27d1-4f94-a579-029661eb72f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standard Library Imports\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "from subprocess import call\n",
    "import json\n",
    "import time\n",
    "import traceback\n",
    "import asyncio\n",
    "import aiohttp\n",
    "\n",
    "# Third-Party Library Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.client import Config\n",
    "import webdataset as wds\n",
    "import nibabel as nib\n",
    "import pickle as pkl\n",
    "from einops import rearrange\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchio as tio\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449c1ba3-39ff-458c-bc3c-e452445eb10c",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46adfbe0-91ef-43ae-87a9-c2e4ea89033a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reshape_to_2d(tensor):\n",
    "    return rearrange(tensor, 'b h w c -> (b h) (c w)')\n",
    "\n",
    "def reshape_to_original(tensor_2d, h=64, w=64, c=48):\n",
    "    return rearrange(tensor_2d, \"(tr h) (c w) -> tr h w c\", h=h, w=w, c=c)\n",
    "\n",
    "def header_to_dict(header):\n",
    "    readable_header = {}\n",
    "    for key, value in header.items():\n",
    "        readable_header[key] = value\n",
    "    return readable_header\n",
    "\n",
    "def temporal_interp1d(fmri_data, change_TR):\n",
    "    original_time_points = np.arange(fmri_data.shape[0])  # Time points: 0, 1, 2, ..., T-1\n",
    "    new_time_points = np.arange(0, fmri_data.shape[0], change_TR)  # New time points: 0, 2, 4, ...\n",
    "\n",
    "    reshaped_data = fmri_data.reshape(fmri_data.shape[0], -1)  # Reshape to (T, X*Y*Z)\n",
    "    interpolate = interp1d(original_time_points, reshaped_data, kind='linear', axis=0, bounds_error=False, fill_value=\"extrapolate\")\n",
    "    resampled_fmri_data = interpolate(new_time_points).reshape((len(new_time_points),) + fmri_data.shape[1:])\n",
    "    return resampled_fmri_data\n",
    "\n",
    "def list_folders(bucket, prefix='', delimiter='/'):\n",
    "    folder_names = []\n",
    "    continuation_token = None\n",
    "    while True:\n",
    "        # Include the continuation token in the request if it exists\n",
    "        kwargs = {'Bucket': bucket, 'Prefix': prefix, 'Delimiter': delimiter}\n",
    "        if continuation_token:\n",
    "            kwargs['ContinuationToken'] = continuation_token\n",
    "\n",
    "        response = s3.list_objects_v2(**kwargs)\n",
    "        folder_names.extend([x['Prefix'].split('/')[-2] for x in response.get('CommonPrefixes', [])])\n",
    "\n",
    "        # Check if more items are available to retrieve\n",
    "        if 'NextContinuationToken' in response:\n",
    "            continuation_token = response['NextContinuationToken']\n",
    "        else:\n",
    "            break\n",
    "    return folder_names\n",
    "\n",
    "def list_all_objects(bucket, prefix):\n",
    "    continuation_token = None\n",
    "    while True:\n",
    "        if continuation_token:\n",
    "            response = s3.list_objects_v2(Bucket=bucket, Prefix=prefix, ContinuationToken=continuation_token)\n",
    "        else:\n",
    "            response = s3.list_objects_v2(Bucket=bucket, Prefix=prefix)\n",
    "\n",
    "        for content in response.get('Contents', []):\n",
    "            yield content\n",
    "\n",
    "        continuation_token = response.get('NextContinuationToken')\n",
    "        if not continuation_token:\n",
    "            break\n",
    "\n",
    "def torchio_slice(data,xslice=None,yslice=None,zslice=None):    \n",
    "    if xslice is None: xslice = data.shape[1] // 2\n",
    "    if yslice is None: yslice = data.shape[2] // 2\n",
    "    if zslice is None: zslice = data.shape[3] // 2\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(5,5))\n",
    "\n",
    "    # Plot the three different slices\n",
    "    axs[0].imshow(data[0, xslice], cmap='gray')\n",
    "    axs[0].axis('off')\n",
    "    axs[0].set_title(f'Slice [0, {xslice}]', fontsize=8)\n",
    "\n",
    "    axs[1].imshow(data[0, :, yslice], cmap='gray')\n",
    "    axs[1].axis('off')\n",
    "    axs[1].set_title(f'Slice [0, :, {yslice}]', fontsize=8)\n",
    "\n",
    "    axs[2].imshow(data[0, :, :, zslice], cmap='gray')\n",
    "    axs[2].axis('off')\n",
    "    axs[2].set_title(f'Slice [0, :, :, {zslice}]', fontsize=8)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def is_interactive():\n",
    "    import __main__ as main\n",
    "    return not hasattr(main, '__file__')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb8f6f9-ce59-46fc-9b77-43d6ce5a3920",
   "metadata": {},
   "source": [
    "## Create dir to save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9852d060-955e-47ec-ad04-1a285ee38059",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subject = \"sub-01\"\n",
    "proj_name = \"nsd_minimal\"\n",
    "outpath=f\"/weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/{proj_name}\"\n",
    "os.makedirs(os.path.dirname(outpath), exist_ok=True)\n",
    "os.makedirs(f\"{outpath}/{subject}\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a054802-8edd-4e37-9824-94d354eee709",
   "metadata": {},
   "source": [
    "## Sync metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358944ba-a39b-43b9-a4ce-b03b34c1e4fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "```bash\n",
    "aws s3 rm  s3://proj-fmri/fmri_foundation_datasets/conscioustahoe/openneuro/ --recursive\n",
    "\n",
    "aws s3 cp s3://proj-fmri/fmri_foundation_datasets/openneuro/metadata.json s3://proj-fmri/fmri_foundation_datasets/conscioustahoe/openneuro/ --region us-west-2\n",
    "\n",
    "aws s3 ls  s3://proj-fmri/fmri_foundation_datasets/conscioustahoe/openneuro/\n",
    "\n",
    "aws s3 sync s3://proj-fmri/fmri_foundation_datasets/openneuro/tars s3://proj-fmri/fmri_foundation_datasets/conscioustahoe/openneuro --region us-west-2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c684fb6-30f5-4413-97bc-91eac75e1aa7",
   "metadata": {},
   "source": [
    "## Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "041e2607-8045-48e6-901a-fcf01e33042e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a boto3 client without signing requests\n",
    "s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cd67c0-011b-4d49-9fc6-4c14a21d41f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: nsddata_rawdata.\n",
      "nsddata_rawdata/sub-01/ses-nsd01/func/sub-01_ses-nsd01_task-nsdcore_run-01_bold.nii.gz\n",
      "1 188\n",
      "nsddata_rawdata/sub-01/ses-nsd01/func/sub-01_ses-nsd01_task-nsdcore_run-02_bold.nii.gz\n",
      "2 376\n",
      "nsddata_rawdata/sub-01/ses-nsd01/func/sub-01_ses-nsd01_task-nsdcore_run-03_bold.nii.gz\n",
      "3 564\n",
      "nsddata_rawdata/sub-01/ses-nsd01/func/sub-01_ses-nsd01_task-nsdcore_run-04_bold.nii.gz\n",
      "4 752\n",
      "nsddata_rawdata/sub-01/ses-nsd01/func/sub-01_ses-nsd01_task-nsdcore_run-05_bold.nii.gz\n",
      "5 940\n",
      "nsddata_rawdata/sub-01/ses-nsd01/func/sub-01_ses-nsd01_task-nsdcore_run-06_bold.nii.gz\n",
      "6 1128\n",
      "nsddata_rawdata/sub-01/ses-nsd01/func/sub-01_ses-nsd01_task-nsdcore_run-07_bold.nii.gz\n",
      "7 1316\n",
      "nsddata_rawdata/sub-01/ses-nsd01/func/sub-01_ses-nsd01_task-nsdcore_run-08_bold.nii.gz\n",
      "8 1504\n",
      "nsddata_rawdata/sub-01/ses-nsd01/func/sub-01_ses-nsd01_task-nsdcore_run-09_bold.nii.gz\n",
      "9 1692\n",
      "nsddata_rawdata/sub-01/ses-nsd01/func/sub-01_ses-nsd01_task-nsdcore_run-10_bold.nii.gz\n",
      "10 1880\n",
      "nsddata_rawdata/sub-01/ses-nsd01/func/sub-01_ses-nsd01_task-nsdcore_run-11_bold.nii.gz\n",
      "11 2068\n",
      "nsddata_rawdata/sub-01/ses-nsd01/func/sub-01_ses-nsd01_task-nsdcore_run-12_bold.nii.gz\n",
      "12 2256\n",
      "nsddata_rawdata/sub-01/ses-nsd02/func/sub-01_ses-nsd02_task-nsdcore_run-01_bold.nii.gz\n",
      "13 2444\n",
      "nsddata_rawdata/sub-01/ses-nsd02/func/sub-01_ses-nsd02_task-nsdcore_run-02_bold.nii.gz\n",
      "14 2632\n",
      "nsddata_rawdata/sub-01/ses-nsd02/func/sub-01_ses-nsd02_task-nsdcore_run-03_bold.nii.gz\n",
      "15 2820\n",
      "nsddata_rawdata/sub-01/ses-nsd02/func/sub-01_ses-nsd02_task-nsdcore_run-04_bold.nii.gz\n",
      "16 3008\n",
      "nsddata_rawdata/sub-01/ses-nsd02/func/sub-01_ses-nsd02_task-nsdcore_run-05_bold.nii.gz\n",
      "17 3196\n",
      "nsddata_rawdata/sub-01/ses-nsd02/func/sub-01_ses-nsd02_task-nsdcore_run-06_bold.nii.gz\n",
      "18 3384\n",
      "nsddata_rawdata/sub-01/ses-nsd02/func/sub-01_ses-nsd02_task-nsdcore_run-07_bold.nii.gz\n",
      "19 3572\n",
      "nsddata_rawdata/sub-01/ses-nsd02/func/sub-01_ses-nsd02_task-nsdcore_run-08_bold.nii.gz\n",
      "20 3760\n",
      "nsddata_rawdata/sub-01/ses-nsd02/func/sub-01_ses-nsd02_task-nsdcore_run-09_bold.nii.gz\n",
      "21 3948\n",
      "nsddata_rawdata/sub-01/ses-nsd02/func/sub-01_ses-nsd02_task-nsdcore_run-10_bold.nii.gz\n",
      "22 4136\n",
      "nsddata_rawdata/sub-01/ses-nsd02/func/sub-01_ses-nsd02_task-nsdcore_run-11_bold.nii.gz\n",
      "23 4324\n",
      "nsddata_rawdata/sub-01/ses-nsd02/func/sub-01_ses-nsd02_task-nsdcore_run-12_bold.nii.gz\n",
      "24 4512\n",
      "nsddata_rawdata/sub-01/ses-nsd03/func/sub-01_ses-nsd03_task-nsdcore_run-01_bold.nii.gz\n",
      "25 4700\n",
      "nsddata_rawdata/sub-01/ses-nsd03/func/sub-01_ses-nsd03_task-nsdcore_run-02_bold.nii.gz\n",
      "26 4888\n",
      "nsddata_rawdata/sub-01/ses-nsd03/func/sub-01_ses-nsd03_task-nsdcore_run-03_bold.nii.gz\n",
      "27 5076\n",
      "nsddata_rawdata/sub-01/ses-nsd03/func/sub-01_ses-nsd03_task-nsdcore_run-04_bold.nii.gz\n",
      "28 5264\n",
      "nsddata_rawdata/sub-01/ses-nsd03/func/sub-01_ses-nsd03_task-nsdcore_run-05_bold.nii.gz\n",
      "29 5452\n",
      "nsddata_rawdata/sub-01/ses-nsd03/func/sub-01_ses-nsd03_task-nsdcore_run-06_bold.nii.gz\n",
      "30 5640\n",
      "nsddata_rawdata/sub-01/ses-nsd03/func/sub-01_ses-nsd03_task-nsdcore_run-07_bold.nii.gz\n",
      "31 5828\n",
      "nsddata_rawdata/sub-01/ses-nsd03/func/sub-01_ses-nsd03_task-nsdcore_run-08_bold.nii.gz\n",
      "32 6016\n",
      "nsddata_rawdata/sub-01/ses-nsd03/func/sub-01_ses-nsd03_task-nsdcore_run-09_bold.nii.gz\n",
      "33 6204\n",
      "nsddata_rawdata/sub-01/ses-nsd03/func/sub-01_ses-nsd03_task-nsdcore_run-10_bold.nii.gz\n",
      "34 6392\n",
      "nsddata_rawdata/sub-01/ses-nsd03/func/sub-01_ses-nsd03_task-nsdcore_run-11_bold.nii.gz\n",
      "35 6580\n",
      "nsddata_rawdata/sub-01/ses-nsd03/func/sub-01_ses-nsd03_task-nsdcore_run-12_bold.nii.gz\n",
      "36 6768\n",
      "nsddata_rawdata/sub-01/ses-nsd04/func/sub-01_ses-nsd04_task-nsdcore_run-01_bold.nii.gz\n",
      "37 6956\n",
      "nsddata_rawdata/sub-01/ses-nsd04/func/sub-01_ses-nsd04_task-nsdcore_run-02_bold.nii.gz\n",
      "38 7144\n",
      "nsddata_rawdata/sub-01/ses-nsd04/func/sub-01_ses-nsd04_task-nsdcore_run-03_bold.nii.gz\n",
      "39 7332\n",
      "nsddata_rawdata/sub-01/ses-nsd04/func/sub-01_ses-nsd04_task-nsdcore_run-04_bold.nii.gz\n",
      "40 7520\n",
      "nsddata_rawdata/sub-01/ses-nsd04/func/sub-01_ses-nsd04_task-nsdcore_run-05_bold.nii.gz\n",
      "41 7708\n",
      "nsddata_rawdata/sub-01/ses-nsd04/func/sub-01_ses-nsd04_task-nsdcore_run-06_bold.nii.gz\n",
      "42 7896\n",
      "nsddata_rawdata/sub-01/ses-nsd04/func/sub-01_ses-nsd04_task-nsdcore_run-07_bold.nii.gz\n",
      "43 8084\n",
      "nsddata_rawdata/sub-01/ses-nsd04/func/sub-01_ses-nsd04_task-nsdcore_run-08_bold.nii.gz\n",
      "44 8272\n",
      "nsddata_rawdata/sub-01/ses-nsd04/func/sub-01_ses-nsd04_task-nsdcore_run-09_bold.nii.gz\n",
      "45 8460\n",
      "nsddata_rawdata/sub-01/ses-nsd04/func/sub-01_ses-nsd04_task-nsdcore_run-10_bold.nii.gz\n",
      "46 8648\n",
      "nsddata_rawdata/sub-01/ses-nsd04/func/sub-01_ses-nsd04_task-nsdcore_run-11_bold.nii.gz\n",
      "47 8836\n",
      "nsddata_rawdata/sub-01/ses-nsd04/func/sub-01_ses-nsd04_task-nsdcore_run-12_bold.nii.gz\n",
      "48 9024\n",
      "nsddata_rawdata/sub-01/ses-nsd05/func/sub-01_ses-nsd05_task-nsdcore_run-01_bold.nii.gz\n",
      "49 9212\n",
      "nsddata_rawdata/sub-01/ses-nsd05/func/sub-01_ses-nsd05_task-nsdcore_run-02_bold.nii.gz\n",
      "50 9400\n",
      "nsddata_rawdata/sub-01/ses-nsd05/func/sub-01_ses-nsd05_task-nsdcore_run-03_bold.nii.gz\n",
      "51 9588\n",
      "nsddata_rawdata/sub-01/ses-nsd05/func/sub-01_ses-nsd05_task-nsdcore_run-04_bold.nii.gz\n",
      "52 9776\n",
      "nsddata_rawdata/sub-01/ses-nsd05/func/sub-01_ses-nsd05_task-nsdcore_run-05_bold.nii.gz\n",
      "53 9964\n",
      "nsddata_rawdata/sub-01/ses-nsd05/func/sub-01_ses-nsd05_task-nsdcore_run-06_bold.nii.gz\n",
      "54 10152\n",
      "nsddata_rawdata/sub-01/ses-nsd05/func/sub-01_ses-nsd05_task-nsdcore_run-07_bold.nii.gz\n",
      "55 10340\n",
      "nsddata_rawdata/sub-01/ses-nsd05/func/sub-01_ses-nsd05_task-nsdcore_run-08_bold.nii.gz\n",
      "56 10528\n",
      "nsddata_rawdata/sub-01/ses-nsd05/func/sub-01_ses-nsd05_task-nsdcore_run-09_bold.nii.gz\n",
      "57 10716\n",
      "nsddata_rawdata/sub-01/ses-nsd05/func/sub-01_ses-nsd05_task-nsdcore_run-10_bold.nii.gz\n",
      "58 10904\n",
      "nsddata_rawdata/sub-01/ses-nsd05/func/sub-01_ses-nsd05_task-nsdcore_run-11_bold.nii.gz\n",
      "59 11092\n",
      "nsddata_rawdata/sub-01/ses-nsd05/func/sub-01_ses-nsd05_task-nsdcore_run-12_bold.nii.gz\n",
      "60 11280\n",
      "nsddata_rawdata/sub-01/ses-nsd06/func/sub-01_ses-nsd06_task-nsdcore_run-01_bold.nii.gz\n",
      "61 11468\n",
      "nsddata_rawdata/sub-01/ses-nsd06/func/sub-01_ses-nsd06_task-nsdcore_run-02_bold.nii.gz\n",
      "62 11656\n",
      "nsddata_rawdata/sub-01/ses-nsd06/func/sub-01_ses-nsd06_task-nsdcore_run-03_bold.nii.gz\n",
      "63 11844\n",
      "nsddata_rawdata/sub-01/ses-nsd06/func/sub-01_ses-nsd06_task-nsdcore_run-04_bold.nii.gz\n",
      "64 12032\n",
      "nsddata_rawdata/sub-01/ses-nsd06/func/sub-01_ses-nsd06_task-nsdcore_run-05_bold.nii.gz\n",
      "65 12220\n",
      "nsddata_rawdata/sub-01/ses-nsd06/func/sub-01_ses-nsd06_task-nsdcore_run-06_bold.nii.gz\n",
      "66 12408\n",
      "nsddata_rawdata/sub-01/ses-nsd06/func/sub-01_ses-nsd06_task-nsdcore_run-07_bold.nii.gz\n"
     ]
    }
   ],
   "source": [
    "f.close()\n",
    "\n",
    "def my_split_by_node(urls):\n",
    "    return urls\n",
    "\n",
    "# prep hdf5 creation\n",
    "N = 188*12*40 # number of TRs in entire NSD subj01 dataset\n",
    "R = 12*40 # number of runs in entire NSD subj01 dataset\n",
    "\n",
    "# Open an HDF5 file\n",
    "f = h5py.File('subj01_rawdata.h5', 'w')\n",
    "\n",
    "# Create datasets\n",
    "global_trs_dset = f.create_dataset('global_trs', shape=(N,), dtype=np.int64)\n",
    "funcs_dset = f.create_dataset('funcs', shape=(N, 64, 64, 48), dtype=np.float16)\n",
    "meansds_dset = f.create_dataset('meansds', shape=(R, 2, 64, 64, 48), dtype=np.float16)\n",
    "\n",
    "###\n",
    "global_tr_cnt = 0\n",
    "global_run_cnt = 0\n",
    "\n",
    "# Set the bucket name and folder name\n",
    "bucket_name = 'natural-scenes-dataset'\n",
    "folder_names = list_folders(bucket_name)\n",
    "\n",
    "tio_transforms = tio.Compose(\n",
    "                (\n",
    "                    tio.ToCanonical(), # make sure orientation of brains are consistent (RAS+ orientation)\n",
    "                    tio.RescaleIntensity(out_min_max=(0, 1)),\n",
    "                    tio.Resample(3, image_interpolation='nearest'), # rescale voxels to #mm isotropic\n",
    "                    tio.CropOrPad((64, 64, 48)),\n",
    "                )\n",
    "            )\n",
    "folder_name = \"nsddata_rawdata\"\n",
    "\n",
    "print(f\"Processing dataset: {folder_name}.\")\n",
    "all_objects = list_all_objects(bucket_name, folder_name)\n",
    "for obj in all_objects:\n",
    "    obj_key = obj['Key']\n",
    "\n",
    "    if '_bold.nii.gz' in obj_key and 'nsdcore_run' in obj_key and subject in obj_key:\n",
    "        print(obj_key)\n",
    "        func_subj = obj_key.split('/')[1]\n",
    "\n",
    "        filename = os.getcwd()+f'/{proj_name}/'+obj_key\n",
    "        os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "        if not os.path.exists(filename):\n",
    "            s3.download_file(bucket_name, obj_key, filename)\n",
    "\n",
    "        func_nii = nib.load(filename)\n",
    "\n",
    "        tio_image = tio.ScalarImage(tensor=np.moveaxis(func_nii.get_fdata(),-1,0).astype(np.float32), \n",
    "                                affine=func_nii.affine, \n",
    "                                dtype=np.float32)\n",
    "        out = tio_transforms(tio_image)['data']\n",
    "\n",
    "        # zscore across the run\n",
    "        out_shape = out.shape\n",
    "        out = out.reshape(len(out),-1)\n",
    "        scalar = StandardScaler(with_mean=True, with_std=True).fit(out)\n",
    "        mean = scalar.mean_\n",
    "        sd = scalar.scale_\n",
    "        out = (out - mean) / sd\n",
    "        mean = mean.reshape([out_shape[1],out_shape[2],out_shape[3]])\n",
    "        sd = sd.reshape([out_shape[1],out_shape[2],out_shape[3]])\n",
    "        meansd = np.array([mean,sd])\n",
    "        out = out.reshape(out_shape)\n",
    "\n",
    "        # create 16-bit png of mean and sd volumes\n",
    "        meansd_images = reshape_to_2d(meansd)\n",
    "        meansd_images = torch.Tensor(meansd_images)\n",
    "        min_meansd, max_meansd = meansd_images.min(), meansd_images.max()\n",
    "        minmax_meansd_images = (meansd_images - min_meansd) / (max_meansd - min_meansd) # first you need to rescale to 0 to 1\n",
    "        # rescaled_images = (minmax_meansd_images * 65535).to(torch.int16) # then multiply by constant prior to numpy uint16\n",
    "        # rescaled_images_numpy = rescaled_images.numpy().astype(np.uint16)\n",
    "        # meansd_PIL_image = Image.fromarray(rescaled_images_numpy, mode='I;16')\n",
    "        \n",
    "        meansds_dset[global_run_cnt] = reshape_to_original(minmax_meansd_images)\n",
    "        global_run_cnt += 1\n",
    "\n",
    "        for batch in range(len(out)):\n",
    "            images = reshape_to_2d(out[[batch]])\n",
    "            images = torch.Tensor(images)\n",
    "\n",
    "            # convert tensor to something compatible with 16-bit png\n",
    "            min_, max_ = images.min(), images.max()\n",
    "            minmax_images = (images - min_) / (max_ - min_) # first you need to rescale to 0 to 1\n",
    "            # rescaled_images = (minmax_images * 65535).to(torch.int16) # then multiply by constant prior to numpy uint16\n",
    "            # rescaled_images_numpy = rescaled_images.numpy().astype(np.uint16)\n",
    "            # PIL_image = Image.fromarray(rescaled_images_numpy, mode='I;16')\n",
    "            \n",
    "            funcs_dset[global_tr_cnt] = reshape_to_original(minmax_images)\n",
    "\n",
    "            global_trs_dset[global_tr_cnt] = global_tr_cnt\n",
    "            global_tr_cnt += 1\n",
    "        print(global_run_cnt, global_tr_cnt)\n",
    "###\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dfdf8c1a-3bb4-451d-9305-72ac13f4d7c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480 90240\n"
     ]
    }
   ],
   "source": [
    "print(global_run_cnt, global_tr_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e014c553-2c8e-4706-b441-c952ade78d29",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Matrix of behavioral/stimuli info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1deeaa3-90bc-4466-89a7-faca765e4dbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TR = 1.6\n"
     ]
    }
   ],
   "source": [
    "TR = 1.6\n",
    "TRs_per_run = 188\n",
    "print(\"TR =\",TR)\n",
    "\n",
    "shared1000 = np.load('/weka/proj-fmri/shared/mindeyev2_dataset/shared1000.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "401771a1-9757-458b-999d-def515a6cd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: nsddata_rawdata.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_TR_onsets</th>\n",
       "      <th>global_TR_onsets</th>\n",
       "      <th>coco73k</th>\n",
       "      <th>run_trial</th>\n",
       "      <th>global_trial</th>\n",
       "      <th>global_sess</th>\n",
       "      <th>global_run</th>\n",
       "      <th>trial_type</th>\n",
       "      <th>shared1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>46002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>61882</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>828</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>67573</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.5</td>\n",
       "      <td>17.5</td>\n",
       "      <td>16020</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>162.5</td>\n",
       "      <td>90214.5</td>\n",
       "      <td>13773</td>\n",
       "      <td>57</td>\n",
       "      <td>29995</td>\n",
       "      <td>39</td>\n",
       "      <td>5759</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>165.0</td>\n",
       "      <td>90217.0</td>\n",
       "      <td>66767</td>\n",
       "      <td>58</td>\n",
       "      <td>29996</td>\n",
       "      <td>39</td>\n",
       "      <td>5759</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>167.5</td>\n",
       "      <td>90219.5</td>\n",
       "      <td>53167</td>\n",
       "      <td>59</td>\n",
       "      <td>29997</td>\n",
       "      <td>39</td>\n",
       "      <td>5759</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>170.0</td>\n",
       "      <td>90222.0</td>\n",
       "      <td>1943</td>\n",
       "      <td>60</td>\n",
       "      <td>29998</td>\n",
       "      <td>39</td>\n",
       "      <td>5759</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>172.5</td>\n",
       "      <td>90224.5</td>\n",
       "      <td>5033</td>\n",
       "      <td>61</td>\n",
       "      <td>29999</td>\n",
       "      <td>39</td>\n",
       "      <td>5759</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       run_TR_onsets  global_TR_onsets  coco73k  run_trial  global_trial  \\\n",
       "0                7.5               7.5    46002          0             0   \n",
       "1               10.0              10.0    61882          1             1   \n",
       "2               12.5              12.5      828          2             2   \n",
       "3               15.0              15.0    67573          3             3   \n",
       "4               17.5              17.5    16020          4             4   \n",
       "...              ...               ...      ...        ...           ...   \n",
       "29995          162.5           90214.5    13773         57         29995   \n",
       "29996          165.0           90217.0    66767         58         29996   \n",
       "29997          167.5           90219.5    53167         59         29997   \n",
       "29998          170.0           90222.0     1943         60         29998   \n",
       "29999          172.5           90224.5     5033         61         29999   \n",
       "\n",
       "       global_sess  global_run  trial_type  shared1000  \n",
       "0                0           0           0        True  \n",
       "1                0           0           0       False  \n",
       "2                0           0           0       False  \n",
       "3                0           0           0       False  \n",
       "4                0           0           0       False  \n",
       "...            ...         ...         ...         ...  \n",
       "29995           39        5759           1       False  \n",
       "29996           39        5759           1       False  \n",
       "29997           39        5759           1       False  \n",
       "29998           39        5759           1       False  \n",
       "29999           39        5759           1       False  \n",
       "\n",
       "[30000 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the bucket name and folder name\n",
    "bucket_name = 'natural-scenes-dataset'\n",
    "folder_names = list_folders(bucket_name)\n",
    "\n",
    "folder_name = \"nsddata_rawdata\"\n",
    "print(f\"Processing dataset: {folder_name}.\")\n",
    "\n",
    "stim = {}\n",
    "run_cnt = 0\n",
    "last_trial = 0\n",
    "\n",
    "pattern = r\"ses-nsd(\\d+)/.*?run-(\\d+)\"\n",
    "\n",
    "# List all objects in the folder\n",
    "all_objects = list_all_objects(bucket_name, folder_name)\n",
    "for obj in all_objects:\n",
    "    obj_key = obj['Key']\n",
    "\n",
    "    if '_events.tsv' in obj_key and 'nsdcore_run' in obj_key and subject in obj_key:\n",
    "        # print(obj_key)\n",
    "        \n",
    "        filename = os.getcwd()+f'/{proj_name}/'+obj_key\n",
    "        os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "        if not os.path.exists(filename):\n",
    "            s3.download_file(bucket_name, obj_key, filename)\n",
    "\n",
    "        events = pd.read_csv(filename, delimiter='\\t')\n",
    "        \n",
    "        match = re.search(pattern, filename)\n",
    "        ses, run = match.groups()\n",
    "        \n",
    "        if stim=={}:\n",
    "            stim['run_TR_onsets'] = events['onset'].values / TR\n",
    "            stim['global_TR_onsets'] = (events['onset'].values / TR) + (run_cnt*188)\n",
    "            stim['coco73k'] = events['73k_id'].values - 1\n",
    "            stim['run_trial'] = events['trial_number'].values\n",
    "            stim['global_trial'] = events['trial_number'].values + last_trial\n",
    "            stim['global_sess'] = np.repeat(int(ses), len(events['73k_id'].values))\n",
    "            stim['global_run'] = np.repeat(int(run) + (run_cnt*12), len(events['73k_id'].values))\n",
    "            stim['trial_type'] = events['trial_type'].values\n",
    "        else:\n",
    "            stim['run_TR_onsets'] = np.append(stim['run_TR_onsets'], events['onset'].values / TR)\n",
    "            stim['global_TR_onsets'] = np.append(stim['global_TR_onsets'],(events['onset'].values / TR) + (run_cnt*188))\n",
    "            stim['coco73k'] = np.append(stim['coco73k'], events['73k_id'].values - 1)\n",
    "            stim['run_trial'] = np.append(stim['run_trial'], events['trial_number'].values)\n",
    "            stim['global_trial'] = np.append(stim['global_trial'], events['trial_number'].values + last_trial)\n",
    "            stim['global_sess'] = np.append(stim['global_sess'], np.repeat(int(ses), len(events['73k_id'].values)))\n",
    "            stim['global_run'] = np.append(stim['global_run'], np.repeat(int(run) + (run_cnt*12), len(events['73k_id'].values)))\n",
    "            stim['trial_type'] = np.append(stim['trial_type'], events['trial_type'].values)\n",
    "            \n",
    "        last_trial = stim['global_trial'][-1]\n",
    "        run_cnt += 1\n",
    "\n",
    "stim['shared1000'] = shared1000[stim['coco73k']]\n",
    "        \n",
    "# convert to 0-index\n",
    "stim['run_trial'] = stim['run_trial']-1\n",
    "stim['global_trial'] = stim['global_trial']-1\n",
    "stim['global_run'] = stim['global_run']-1\n",
    "stim['global_sess'] = stim['global_sess']-1\n",
    "\n",
    "df = pd.DataFrame(stim)\n",
    "df.to_csv(f'{proj_name}/{subject}/nsddata_rawdata.csv', index=False)\n",
    "df.to_csv(f'nsddata_rawdata.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb56ca2-7da1-4668-bdf2-d5bd16e343e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Send to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "183d956d-e757-402f-92d6-4f8540ddcc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: nsd_minimal/sub-01/nsddata_rawdata.csv to s3://proj-fmri/fmri_foundation_datasets/nsd_minimal/nsddata_rawdata.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# send to aws s3\n",
    "command = f\"aws s3 sync {outpath}/{subject} s3://proj-fmri/fmri_foundation_datasets/{proj_name} --region us-west-2\"\n",
    "call(command,shell=True)\n",
    "\n",
    "# # delete tars\n",
    "# command = f\"rm {outpath}/{subject}/*.tar\"\n",
    "# call(command,shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41b619e-a8b5-4e44-94d4-52aef5311621",
   "metadata": {},
   "source": [
    "# Making tars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3aeca2-a512-403d-a88a-9cea8d2bb52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_tr_cnt = 0\n",
    "TRs_per_sample = 24\n",
    "max_samples_per_tar = 320 # translates to around 1 Gb per tar\n",
    "max_TRs_per_tar = max_samples_per_tar * TRs_per_sample\n",
    "\n",
    "# Set the bucket name and folder name\n",
    "bucket_name = 'natural-scenes-dataset'\n",
    "folder_names = list_folders(bucket_name)\n",
    "\n",
    "print(f\"TRs_per_sample: {TRs_per_sample} max_samples_per_tar: {max_samples_per_tar} max_TRs_per_tar: {max_TRs_per_tar}\")\n",
    "\n",
    "# If you want to start over webdataset creation from the beginning, uncomment these:\n",
    "tar_count = 0\n",
    "TR_count = 0\n",
    "subj_count = 0\n",
    "dataset_count = 0\n",
    "dataset_list = []\n",
    "obj_key_list = []\n",
    "\n",
    "sample_idx = 0\n",
    "current_dataset = None\n",
    "current_subject = None\n",
    "sink = wds.TarWriter(f\"{outpath}/sub-01/{tar_count:06d}.tar\")\n",
    "\n",
    "tio_transforms = tio.Compose(\n",
    "                (\n",
    "                    tio.ToCanonical(), # make sure orientation of brains are consistent (RAS+ orientation)\n",
    "                    tio.RescaleIntensity(out_min_max=(0, 1)),\n",
    "                    tio.Resample(3, image_interpolation='nearest'), # rescale voxels to #mm isotropic\n",
    "                    tio.CropOrPad((64, 64, 48)),\n",
    "                )\n",
    "            )\n",
    "\n",
    "folder_name = \"nsddata_rawdata\"\n",
    "\n",
    "print(f\"Processing dataset: {folder_name}.\")\n",
    "all_objects = list_all_objects(bucket_name, folder_name)\n",
    "for obj in all_objects:\n",
    "    obj_key = obj['Key']\n",
    "\n",
    "    if '_bold.nii.gz' in obj_key and 'nsdcore_run' in obj_key and subject in obj_key:\n",
    "        print(obj_key)\n",
    "        func_subj = obj_key.split('/')[1]\n",
    "\n",
    "        # if metadata file shows you already processed this file, skip it\n",
    "        if np.isin(obj_key, obj_key_list):\n",
    "            continue\n",
    "\n",
    "        filename = os.getcwd()+f'/{proj_name}/'+obj_key\n",
    "        os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "        if not os.path.exists(filename):\n",
    "            s3.download_file(bucket_name, obj_key, filename)\n",
    "\n",
    "        func_nii = nib.load(filename)\n",
    "        try:\n",
    "            print(obj_key, func_nii.get_fdata().shape, \"| TRs:\", TR_count, \"samp:\", sample_idx)\n",
    "        except Exception as e:\n",
    "            print(f\"get_fdata() error occurred: {e}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            tio_image = tio.ScalarImage(tensor=np.moveaxis(func_nii.get_fdata(),-1,0).astype(np.float32), \n",
    "                                    affine=func_nii.affine, \n",
    "                                    dtype=np.float32)\n",
    "            out = tio_transforms(tio_image)['data']\n",
    "        except Exception as e: # this can happen if the func is actually 3d and not 4d\n",
    "            print(f\"tio processing error occurred: {e}\")\n",
    "            continue\n",
    "\n",
    "        # zscore across the run\n",
    "        out_shape = out.shape\n",
    "        out = out.reshape(len(out),-1)\n",
    "        scalar = StandardScaler(with_mean=True, with_std=True).fit(out)\n",
    "        mean = scalar.mean_\n",
    "        sd = scalar.scale_\n",
    "        out = (out - mean) / sd\n",
    "        mean = mean.reshape([out_shape[1],out_shape[2],out_shape[3]])\n",
    "        sd = sd.reshape([out_shape[1],out_shape[2],out_shape[3]])\n",
    "        meansd = np.array([mean,sd])\n",
    "        out = out.reshape(out_shape)\n",
    "\n",
    "        # create 16-bit png of mean and sd volumes\n",
    "        meansd_images = reshape_to_2d(meansd)\n",
    "        meansd_images = torch.Tensor(meansd_images)\n",
    "        min_meansd, max_meansd = meansd_images.min(), meansd_images.max()\n",
    "        minmax_meansd_images = (meansd_images - min_meansd) / (max_meansd - min_meansd) # first you need to rescale to 0 to 1\n",
    "        rescaled_images = (minmax_meansd_images * 65535).to(torch.int16) # then multiply by constant prior to numpy uint16\n",
    "        rescaled_images_numpy = rescaled_images.numpy().astype(np.uint16)\n",
    "        meansd_PIL_image = Image.fromarray(rescaled_images_numpy, mode='I;16')\n",
    "        \n",
    "        global_tr_cnt += len(out)\n",
    "\n",
    "        # create samples of TRs_per_sample TRs\n",
    "        for batch in range(0,len(out),TRs_per_sample):\n",
    "            if len(out[batch:batch+TRs_per_sample])<TRs_per_sample:\n",
    "                continue\n",
    "            images = reshape_to_2d(out[batch:batch+TRs_per_sample])\n",
    "            images = torch.Tensor(images)\n",
    "\n",
    "            # convert tensor to something compatible with 16-bit png\n",
    "            min_, max_ = images.min(), images.max()\n",
    "            minmax_images = (images - min_) / (max_ - min_) # first you need to rescale to 0 to 1\n",
    "            rescaled_images = (minmax_images * 65535).to(torch.int16) # then multiply by constant prior to numpy uint16\n",
    "            rescaled_images_numpy = rescaled_images.numpy().astype(np.uint16)\n",
    "            PIL_image = Image.fromarray(rescaled_images_numpy, mode='I;16')\n",
    "\n",
    "            sink.write({\n",
    "                \"__key__\": \"%06d\" % sample_idx,\n",
    "                \"dataset.txt\": obj_key,\n",
    "                \"header.npy\": np.array(header_to_dict(func_nii.header)),\n",
    "                \"minmax.npy\": np.array([min_, max_, min_meansd, max_meansd]),\n",
    "                \"meansd.png\": meansd_PIL_image,\n",
    "                \"func.png\": PIL_image, # 27M for 8-bit png vs 48M for 16-bit png vs 144M for numpy\n",
    "                \"run_TR.npy\": np.arange(len(out))[batch:batch+TRs_per_sample],\n",
    "                \"global_TR.npy\": np.arange(len(out))[batch:batch+TRs_per_sample] + (global_tr_cnt - len(out)),\n",
    "            })\n",
    "\n",
    "            if current_dataset != obj['Key'].split('/')[0]:\n",
    "                print(obj_key, \"| TR_count:\", TR_count, \"sample_idx:\", sample_idx)\n",
    "                dataset_list.append(obj['Key'].split('/')[0])\n",
    "                dataset_count += 1\n",
    "                if is_interactive(): # dont want to plot unless you are in interactive notebook\n",
    "                    torchio_slice(out) # plot normalized slices\n",
    "                    torchio_slice((out * sd) + mean) # plot unnormalized slices\n",
    "\n",
    "            if current_subject != obj['Key'].split('/')[1]:\n",
    "                subj_count += 1\n",
    "            current_dataset = obj['Key'].split('/')[0]\n",
    "            current_subject = obj['Key'].split('/')[1]\n",
    "\n",
    "            TR_count += TRs_per_sample\n",
    "            sample_idx += 1\n",
    "\n",
    "            if sample_idx >= max_samples_per_tar:\n",
    "                print(\"HIT MAX SAMPLES PER TAR\")\n",
    "                sink.close()\n",
    "                sample_idx = 0 \n",
    "\n",
    "                # make metadata file and save progress to aws s3\n",
    "                data = {\n",
    "                    \"TR_count\": TR_count,\n",
    "                    \"subj_count\": subj_count,\n",
    "                    \"tar_count\": tar_count,\n",
    "                    \"dataset_count\": dataset_count,\n",
    "                    \"datasets\": dataset_list,\n",
    "                    \"obj_key_list\": obj_key_list,\n",
    "                }\n",
    "                with open(f\"{outpath}/{subject}/metadata.json\", \"w\") as file:\n",
    "                    json.dump(data, file)\n",
    "\n",
    "                tar_count += 1\n",
    "                sink = wds.TarWriter(f\"{outpath}/{subject}/{tar_count:06d}.tar\")\n",
    "\n",
    "        obj_key_list.append(obj['Key'])\n",
    "\n",
    "print(\"TR_count\",TR_count)\n",
    "print(\"subj_count\",subj_count)\n",
    "print(\"dataset_count\",dataset_count)\n",
    "print(\"tar_count\", tar_count)   \n",
    "\n",
    "try:\n",
    "    sink.close()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "data = {\n",
    "    \"TR_count\": TR_count,\n",
    "    \"subj_count\": subj_count,\n",
    "    \"tar_count\": tar_count,\n",
    "    \"datasets\": dataset_list,\n",
    "    \"obj_key_list\": obj_key_list,          \n",
    "}\n",
    "\n",
    "with open(f\"{outpath}/{subject}/metadata.json\", \"w\") as file:\n",
    "    json.dump(data, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "found",
   "language": "python",
   "name": "found"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
