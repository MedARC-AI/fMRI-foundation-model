{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d41070df-0572-4e70-9b9a-fba4e0c85022",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standard Library Imports\n",
    "import os\n",
    "import sys\n",
    "from subprocess import call, check_output\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Third-Party Library Imports\n",
    "import numpy as np\n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.client import Config\n",
    "import webdataset as wds\n",
    "import nibabel as nib\n",
    "import pickle as pkl\n",
    "import h5py\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cd5c087-dbe8-4536-ad24-11de4c8e1901",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/tempNSD\n",
      "/weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/MNIsNSD\n"
     ]
    }
   ],
   "source": [
    "proj_name = \"NSD\"\n",
    "temp_dir = os.getcwd() + f\"/temp{proj_name}\" # the folder where the AFNI container will do its work\n",
    "mni_dir = os.getcwd() + f\"/MNIs{proj_name}\" # the folder where MNI outputs will go\n",
    "\n",
    "# if starting from scratch\n",
    "command = f\"rm -r {temp_dir}\"\n",
    "call(command,shell=True)\n",
    "command = f\"rm -r {mni_dir}\"\n",
    "call(command,shell=True)\n",
    "\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "os.makedirs(mni_dir, exist_ok=True)\n",
    "print(temp_dir)\n",
    "print(mni_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f15254df-2596-4e93-b0d3-4b5e05e92b42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(file_name_list) = 28922\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "bucket_name = 'natural-scenes-dataset'\n",
    "prefix = 'nsddata_rawdata'\n",
    "\n",
    "paginator = s3.get_paginator('list_objects_v2')\n",
    "file_name_list = []\n",
    "for page in paginator.paginate(Bucket=bucket_name, Prefix=prefix):\n",
    "    for obj in page.get('Contents', []):\n",
    "        file_name = obj['Key']\n",
    "        file_name_list.append(file_name)\n",
    "print(\"len(file_name_list) =\", len(file_name_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d3ca1e5-f755-4b88-b624-8a39ef04f0b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'err' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m temp_file_path \u001b[38;5;241m=\u001b[39m temp_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m dataset_id \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m func_path\n\u001b[1;32m      8\u001b[0m mni_file_path \u001b[38;5;241m=\u001b[39m mni_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m dataset_id \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m func_path\n\u001b[0;32m----> 9\u001b[0m \u001b[43merr\u001b[49m\n\u001b[1;32m     11\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(temp_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m dataset_id, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(mni_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m dataset_id, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'err' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"starting...\")\n",
    "for file_name in file_name_list:\n",
    "    if file_name.endswith('_bold.nii.gz'):\n",
    "        dataset_id = file_name.split('/')[2]\n",
    "\n",
    "        func_path = file_name.split('/')[-1]\n",
    "        temp_file_path = temp_dir + '/' + dataset_id + '/' + func_path\n",
    "        mni_file_path = mni_dir + '/' + dataset_id + '/' + func_path\n",
    "        err\n",
    "        \n",
    "        os.makedirs(temp_dir + '/' + dataset_id, exist_ok=True)\n",
    "        os.makedirs(mni_dir + '/' + dataset_id, exist_ok=True)\n",
    "\n",
    "        # download from s3\n",
    "        print(f\"downloading {temp_file_path}\")\n",
    "        try:\n",
    "            # s3.download_file(bucket_name, file_name, temp_file_path)\n",
    "            command = f\"wget https://{bucket_name}.s3.amazonaws.com/{file_name} -q -O {temp_file_path}\"\n",
    "            call(command,shell=True)\n",
    "        except:\n",
    "            print(\"failed to download? 1\")\n",
    "\n",
    "        while not os.path.exists(f\"{temp_file_path}\"):\n",
    "            print(f\"s3 download failed. trying again... {temp_file_path}\")\n",
    "            try:\n",
    "                # s3.download_file(bucket_name, file_name, temp_file_path)\n",
    "                command = f\"wget https://{bucket_name}.s3.amazonaws.com/{file_name} -q -O {temp_file_path}\"\n",
    "                call(command,shell=True)\n",
    "            except:\n",
    "                print(\"failed to download? 2\")\n",
    "            time.sleep(10)\n",
    "\n",
    "        # make temp lock file so other parallel jobs dont do duplicate work\n",
    "        command = f\"touch {temp_file_path.split('.nii.gz')[0] + '.txt'}\"\n",
    "        call(command, shell=True)\n",
    "\n",
    "        # Wait for AFNI to be complete\n",
    "        print('waiting...')\n",
    "        waiting_time = 0\n",
    "        while not os.path.exists(mni_file_path.split(\".nii.gz\")[0] + \"_overlap.txt\"):\n",
    "            time.sleep(5)     \n",
    "            waiting_time += 5\n",
    "            if waiting_time > 180:\n",
    "                break\n",
    "\n",
    "        if waiting_time <= 180:\n",
    "            time.sleep(10) # wait to ensure txt file was fully created\n",
    "            with open(mni_file_path.split(\".nii.gz\")[0] + \"_overlap.txt\", 'r') as file:\n",
    "                try:\n",
    "                    overlap = file.readlines()\n",
    "                    overlap = np.array(overlap).astype(np.float32)[0]\n",
    "                except:\n",
    "                    print(\"overlap error!\")\n",
    "                    overlap = 0 # in case some weird error occurs where overlap txt is empty, assume its ok\n",
    "            \n",
    "            # if overlap >20% is bad\n",
    "            print(\"overlap:\",overlap)\n",
    "            afni_filename = mni_dir + '/' + dataset_id + '/' + func_path.split(\".nii.gz\")[0] + \"_MNI.nii.gz\"\n",
    "\n",
    "            command = f\"aws s3 cp {afni_filename} s3://proj-fmri/fmri_foundation_datasets/NSD_MNI/{dataset_id}/{func_path.split('.nii.gz')[0] + '_MNI.nii.gz'}\"\n",
    "            call(command,shell=True)\n",
    "\n",
    "            print(f\"Removing _MNI file... {afni_filename}\")\n",
    "            command = f\"rm {afni_filename}\"\n",
    "            call(command,shell=True)\n",
    "\n",
    "            time.sleep(5)\n",
    "        else:\n",
    "            print(\"waiting time exceeded...\")\n",
    "            \n",
    "            # remove all files\n",
    "            command = f\"rm {temp_dir}/{dataset_id}/*\"\n",
    "            call(command,shell=True)\n",
    "\n",
    "            # write placeholder txt overlap file\n",
    "            with open(mni_file_path.split(\".nii.gz\")[0] + \"_overlap.txt\", 'w') as file:\n",
    "                file.write('-999')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "found",
   "language": "python",
   "name": "found"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
