{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e6af0bb-19b2-472a-bd32-cd10bd997132",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7a60b5f-c5db-46f5-8569-e10ac40fb8a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import packages and setup gpu configuration.\n",
    "# This code block shouldnt need to be adjusted!\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import math\n",
    "import gc\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "import time\n",
    "import random\n",
    "import h5py\n",
    "import webdataset as wds\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import utils\n",
    "from models import *\n",
    "import nibabel as nib\n",
    "from nilearn import plotting\n",
    "\n",
    "# tf32 data type is faster than standard float32\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "### Multi-GPU config ###\n",
    "device_count = torch.cuda.device_count()\n",
    "print(f\"Number of available CUDA devices: {device_count}\")\n",
    "\n",
    "local_rank = os.getenv('LOCAL_RANK')\n",
    "if local_rank is None: \n",
    "    local_rank = 0\n",
    "else:\n",
    "    local_rank = int(local_rank)\n",
    "print(f\"LOCAL RANK={local_rank}\")\n",
    "\n",
    "num_devices = os.getenv('NUM_GPUS')\n",
    "if num_devices is None: \n",
    "    num_devices = 1\n",
    "else:\n",
    "    num_devices = int(num_devices)\n",
    "print(f\"NUM GPUS={num_devices}\")\n",
    "distributed = True if num_devices>1 else False\n",
    "if distributed: assert device_count==num_devices\n",
    "\n",
    "node = os.getenv('SLURM_NODEID')\n",
    "if node is None:\n",
    "    node = 0\n",
    "else:\n",
    "    node = int(node)\n",
    "print(f\"NODE={node}\")\n",
    "\n",
    "global_rank = os.getenv('RANK')\n",
    "if global_rank is None:\n",
    "    global_rank = 0\n",
    "else:\n",
    "    global_rank = int(global_rank)\n",
    "print(f\"GLOBAL RANK={global_rank}\")\n",
    "\n",
    "world_size = os.getenv('WORLD_SIZE')\n",
    "if world_size is None: \n",
    "    world_size = 1\n",
    "else:\n",
    "    world_size = int(world_size)\n",
    "print(f\"WORLD_SIZE={world_size}\")\n",
    "\n",
    "if utils.is_interactive():\n",
    "    # Following allows you to change functions in models.py or utils.py and \n",
    "    # have this notebook automatically update with your revisions\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    from tqdm.notebook import tqdm\n",
    "else:\n",
    "    from tqdm import tqdm\n",
    "\n",
    "# Load parameters from yaml config\n",
    "config = yaml.load(open('config.yaml', 'r'), Loader=yaml.FullLoader)\n",
    "\n",
    "# create global variables from the config\n",
    "for attribute_name in config.keys():\n",
    "    globals()[attribute_name] = config[f'{attribute_name}']\n",
    "\n",
    "data_type = torch.float16 # change depending on your mixed_precision\n",
    "# batch_size = global_batch_size // num_devices\n",
    "global_batch_size = batch_size * num_devices\n",
    "\n",
    "# FSDP Setup\n",
    "if distributed:\n",
    "    import torch.distributed as dist\n",
    "    import torch.multiprocessing as mp\n",
    "    from torch.distributed.fsdp import FullyShardedDataParallel as FSDP\n",
    "    from torch.distributed.fsdp.api import BackwardPrefetch, CPUOffload, ShardingStrategy\n",
    "    import functools\n",
    "    from torch.distributed.fsdp.wrap import size_based_auto_wrap_policy\n",
    "    print(\"starting init_process_group...\")\n",
    "    dist.init_process_group(\"nccl\", rank=global_rank, world_size=world_size)\n",
    "    print(f\"setting device to cuda:{local_rank}\")\n",
    "    try:\n",
    "        torch.cuda.set_device(local_rank)\n",
    "        device = torch.cuda.current_device() #torch.device('cuda',local_rank)\n",
    "        print(f\"\\nSuccessfully set cuda:{local_rank} | global_rank{global_rank} | node{node}\")\n",
    "    except Exception as error:        \n",
    "        print(f\"\\nFAILED TO SET DEVICE cuda:{local_rank} | global_rank{global_rank} | node{node}\")\n",
    "        print(\"An exception occurred:\", error)\n",
    "    dist.barrier()\n",
    "    print(\"passed barrier\\n\")\n",
    "else:\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "print(\"PID of this process =\",os.getpid())\n",
    "print(\"device =\", device, \"distributed =\",distributed, \"num_devices =\", num_devices, \"local rank =\", local_rank, \"world size =\", world_size, \"data_type =\", data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac630aa-3df9-4ccb-9d93-f638a4fe9c76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(config)\n",
    "\n",
    "# seed all random functions\n",
    "utils.seed_everything(seed)\n",
    "\n",
    "outdir = os.path.abspath(f'../ckpts/{model_name}')\n",
    "print(\"outdir\", outdir)\n",
    "\n",
    "if use_contrastive_loss:\n",
    "    global_batch_size = global_batch_size // 2 # contrastive loss doubles the batch size with the same samples and different masks\n",
    "print(\"global_batch_size\", global_batch_size)\n",
    "\n",
    "use_cls_token = True if use_contrastive_loss else use_cls_token\n",
    "print(\"use_cls_token\", use_cls_token)\n",
    "\n",
    "num_patches = int(\n",
    "    (image_size[0] / patch_size)\n",
    "    * (image_size[1] / patch_size)\n",
    "    * (image_size[2] / patch_size)\n",
    "    * num_frames\n",
    ")\n",
    "num_patches_per_timepoint = num_patches // num_frames\n",
    "num_encoder_patches = int(num_patches_per_timepoint * (1 - x_encoder_start_masking_ratio) * num_frames)\n",
    "num_decoder_patches = int(num_patches_per_timepoint * (1 - y_encoder_mask_ratio) * num_frames)\n",
    "print(\"num_patches\", num_patches)\n",
    "print(\"num_encoder_patches\", num_encoder_patches)\n",
    "print(\"num_decoder_patches\", num_decoder_patches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee5be68-d850-42e9-a693-b78f22a1d19b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Set Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714356a4-1584-4d6a-a947-e8c7cbeef3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_depth, image_height, image_width = image_size\n",
    "image_patch_size=(patch_size,patch_size,patch_size)\n",
    "patch_depth, patch_height, patch_width = image_patch_size\n",
    "x_encoder = Transformer(\n",
    "    embed_dim,\n",
    "    depth,\n",
    "    num_heads,\n",
    "    dim_head,\n",
    "    mlp_dim,\n",
    "    use_rope=use_rope_emb,\n",
    "    grid_time=num_frames // frame_patch_size,\n",
    "    grid_depth=image_depth // patch_depth,\n",
    "    grid_height=image_height // patch_height,\n",
    "    grid_width=image_width // patch_width,\n",
    "    cls_token=use_cls_token,\n",
    ")\n",
    "print(\"x_encoder\")\n",
    "print(utils.count_params(x_encoder))\n",
    "y_encoder = Transformer(\n",
    "    embed_dim,\n",
    "    depth,\n",
    "    num_heads,\n",
    "    dim_head,\n",
    "    mlp_dim,\n",
    "    use_rope=use_rope_emb,\n",
    "    grid_time=num_frames // frame_patch_size,\n",
    "    grid_depth=image_depth // patch_depth,\n",
    "    grid_height=image_height // patch_height,\n",
    "    grid_width=image_width // patch_width,\n",
    "    cls_token=use_cls_token,\n",
    ")\n",
    "print(\"y_encoder\")\n",
    "print(utils.count_params(y_encoder))\n",
    "predictor = Transformer(\n",
    "    embed_dim,\n",
    "    depth,\n",
    "    num_heads,\n",
    "    dim_head,\n",
    "    mlp_dim,\n",
    "    use_rope=use_rope_emb,\n",
    "    grid_time=num_frames // frame_patch_size,\n",
    "    grid_depth=image_depth // patch_depth,\n",
    "    grid_height=image_height // patch_height,\n",
    "    grid_width=image_width // patch_width,\n",
    "    cls_token=use_cls_token,\n",
    ")\n",
    "print(\"predictor\")\n",
    "print(utils.count_params(predictor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507aa93d-7ea9-44b3-b0b7-1b0512178a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleViT(\n",
    "    x_encoder=x_encoder,\n",
    "    y_encoder=y_encoder,\n",
    "    predictor=predictor,\n",
    "    image_size=image_size, \n",
    "    image_patch_size=image_patch_size, \n",
    "    num_frames=num_frames,\n",
    "    frame_patch_size=frame_patch_size,\n",
    "    channels=1,\n",
    "    use_rope_emb=use_rope_emb,\n",
    "    use_cls_token=use_cls_token,\n",
    ")\n",
    "if not distributed:\n",
    "    model = model.to(device)\n",
    "utils.count_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c2deb2-ac87-4e49-a95d-9e9d50c3d426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to select random num_frames from sample and obtain brain-positive patches\n",
    "if masking_strategy==\"MNI\":\n",
    "    MNI_brain = nib.load(\"/weka/proj-fmri/paulscotti/fMRI-foundation-model/dataset_creation/afni_conversion/tpl-MNI152NLin2009cAsym_res-02_T1w_brain.nii.gz\").get_fdata()\n",
    "    brain_pos_voxels = MNI_brain[6:94,8:112,10:82]\n",
    "    brain_pos_pats = model.patchify(torch.Tensor(brain_pos_voxels)[None,None,None])\n",
    "    brain_pos_pats_vit = rearrange(brain_pos_pats, \"b ... d -> b (...) d\").mean(-1)[0]\n",
    "    \n",
    "aug_transform = utils.DataPrepper(\n",
    "    num_frames=num_frames,\n",
    "    masking_strategy=masking_strategy,\n",
    "    patch_depth=patch_size,\n",
    "    patch_height=patch_size,\n",
    "    patch_width=patch_size,\n",
    "    frame_patch_size=frame_patch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b543f5a-65a9-4294-b708-b5ec67dd0fff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test that the model works without error\n",
    "if utils.is_interactive():\n",
    "    input_data = torch.randn(6, 1, num_frames, image_depth, image_height, image_width).to(device)\n",
    "\n",
    "    # if masking_strategy==\"MNI\":\n",
    "    #     # create tube mask (i.e., a mask that is the same for all frames/timepoints)\n",
    "    #     tube_mask = torch.zeros(num_patches // num_frames).to(torch.bool)\n",
    "    #     batch_positive_approx = (brain_pos_pats_vit > 0)\n",
    "    #     mask_idx_candidates = torch.where(batch_positive_approx)[0]\n",
    "    #     mask_idx_candidates = mask_idx_candidates[torch.randperm(len(mask_idx_candidates))]\n",
    "    #     tube_idx = mask_idx_candidates[:int(num_patches / num_frames * (1 - x_encoder_start_masking_ratio))]\n",
    "    #     tube_mask[tube_idx] = True\n",
    "    #     x_encoder_mask = tube_mask.tile(num_frames)\n",
    "\n",
    "    #     # create y_encoder_mask mask similar to x_encoder mask, but ensure no overlap\n",
    "    #     y_encoder_mask = torch.zeros(num_patches // num_frames).to(torch.bool)  \n",
    "    #     remaining_mask_idx = mask_idx_candidates[int(num_patches / num_frames * (1 - x_encoder_start_masking_ratio)) :] \n",
    "    #     y_encoder_mask_idx = remaining_mask_idx[:int(num_patches / num_frames * (1 - y_encoder_mask_ratio))]\n",
    "    #     print(\"num y_encoder patches =\", len(y_encoder_mask_idx))\n",
    "    #     y_encoder_mask[y_encoder_mask_idx] = True\n",
    "    #     y_encoder_mask = y_encoder_mask.tile(num_frames)  # repeat masking for the other timepoints\n",
    "    #     print(\"y_encoder_mask percent\", y_encoder_mask.sum().item() / len(y_encoder_mask))\n",
    "    # else:\n",
    "    x_encoder_mask = torch.zeros(num_patches).to(device).to(torch.bool)\n",
    "    x_encoder_mask[:num_encoder_patches] = True\n",
    "    \n",
    "    masked_tokens = ~x_encoder_mask\n",
    "    print(x_encoder_mask.sum(), x_encoder_mask.shape, x_encoder_mask)\n",
    "    print(masked_tokens.sum(), masked_tokens.shape, masked_tokens)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        print(\"\\nx_encoder\")\n",
    "        xencoder_out = model(\n",
    "                    input_data,\n",
    "                    encoder_mask=x_encoder_mask,\n",
    "                    encoder_type = \"x\",\n",
    "                    verbose=True)\n",
    "        print(\"\\ny_encoder\")\n",
    "        yencoderout = model(\n",
    "                    input_data, \n",
    "                    encoder_mask=x_encoder_mask, \n",
    "                    encoder_type = \"y\",\n",
    "                    verbose=True)\n",
    "        print(\"\\npredictor\")\n",
    "        predictor_out = model(\n",
    "                    xencoder_out, \n",
    "                    encoder_mask=x_encoder_mask, \n",
    "                    encoder_type = \"p\",\n",
    "                    verbose=True)\n",
    "        if use_cls_token:\n",
    "            enc_cls_token = xencoder_out[:, :1, :]\n",
    "            encoder_patches = xencoder_out[:, 1:, :]\n",
    "            pred_cls_token = predictor_out[:, :1, :]\n",
    "            predictor_patches = predictor_out[:, 1:, :]\n",
    "            print(\"\\nenc_cls_token\", enc_cls_token.shape)\n",
    "            print(\"encoder_patches\", encoder_patches.shape)\n",
    "            print(\"pred_cls_token\", pred_cls_token.shape)\n",
    "            print(\"predictor_patches\", predictor_patches.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f0441c-1e4d-40d2-b2fc-f0dc560e0a56",
   "metadata": {},
   "source": [
    "# Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba97778-f876-4fd5-b3ac-c6194f9f2bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import _shard_expand\n",
    "train_urls = _shard_expand(train_urls[0]) + _shard_expand(train_urls[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8193e6-2400-48b4-ba8e-020907572025",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import create_dataset, create_loader\n",
    "\n",
    "def wait_for_files(file_list):\n",
    "    all_files_exist = False\n",
    "    while not all_files_exist:\n",
    "        # Assume all files exist initially\n",
    "        all_files_exist = True\n",
    "        for file_path in file_list:\n",
    "            if not os.path.exists(file_path):\n",
    "                # If any file does not exist, set flag to False and wait\n",
    "                all_files_exist = False\n",
    "                time.sleep(1)  # Wait for 1 second before checking again\n",
    "                break  # No need to check further files if one is missing\n",
    "\n",
    "if not is_s3:\n",
    "    print(train_urls)\n",
    "    waiting = True\n",
    "    if not os.path.exists(train_urls[-1]) and global_rank==0:\n",
    "        s3_directory = '/'.join(s3_train_urls[-1].split('/')[:-1])\n",
    "        local_scratch = '/'.join(train_urls[-1].split('/')[:-1])\n",
    "        print(f\"s3_directory: {s3_directory}\")\n",
    "        print(f\"local_scratch: {local_scratch}\")\n",
    "        \n",
    "        from subprocess import call, DEVNULL\n",
    "        print(f\"\\nsyncing to {local_scratch}\")\n",
    "        command = f\"aws s3 sync {s3_directory} {local_scratch}\"\n",
    "        print(command)\n",
    "        call(command, shell=True)#, stdout=DEVNULL, stderr=DEVNULL)\n",
    "        # DEVNULL stuff prohibits printing a giant wall of text showing every synced file\n",
    "    print(f\"global_rank{global_rank} waiting...\")\n",
    "    wait_for_files(train_urls)\n",
    "    if global_rank==0: print(\"Finished sync!\\n\")\n",
    "    if distributed: dist.barrier()\n",
    "    train_dp = create_dataset(train_urls, \n",
    "                              is_s3=is_s3, \n",
    "                              sample_shuffle=1, shard_shuffle=100)\n",
    "    train_dl = create_loader(train_dp, batch_size=batch_size, num_workers=num_workers)\n",
    "else:\n",
    "    print(\"Dataloading from s3!\")\n",
    "    train_urls = s3_train_urls\n",
    "    print(train_urls)\n",
    "    train_dp = create_dataset(train_urls, \n",
    "                              is_s3=is_s3, \n",
    "                              sample_shuffle=1, shard_shuffle=100)\n",
    "    train_dl = create_loader(train_dp, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2702a313-4959-49ec-b0c4-6cbdcac8fa03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not distributed:\n",
    "    num_it = 2\n",
    "    print(f\"Yielding {num_it} batches\")\n",
    "    \n",
    "    for i, batch in enumerate(train_dl):\n",
    "        print(\"iter\",i)\n",
    "        input_func = batch['func.npy']\n",
    "        if i >= (num_it-1):\n",
    "            break\n",
    "    \n",
    "    print(\"Done!\")\n",
    "    print(\"input_func\", input_func.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e538d4-e0ca-43b2-9dd0-06d3d8920f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if distributed:    \n",
    "    my_auto_wrap_policy = functools.partial(\n",
    "        size_based_auto_wrap_policy, min_num_params=200000\n",
    "    )\n",
    "    print(f\"\\nPrepping FSDP on {global_rank} {node}...\\n\")\n",
    "    model = FSDP(\n",
    "        model,\n",
    "        sharding_strategy=ShardingStrategy.HYBRID_SHARD,\n",
    "        auto_wrap_policy=my_auto_wrap_policy,\n",
    "        use_orig_params=False,\n",
    "        cpu_offload=None, #CPUOffload(offload_params=True)\n",
    "        sync_module_states=True,\n",
    "        limit_all_gathers=True, # See https://github.com/pytorch/pytorch/issues/91165\n",
    "        device_id=device,\n",
    "    )\n",
    "    print(f\"\\nSuccessfully loaded FSDP model to device on global_rank {global_rank}\\n\")\n",
    "    dist.barrier()\n",
    "    print(f\"\\nSuccessfully passed barrier! {global_rank}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66a5ce1-6dd1-42c9-82c8-d402e7317ec0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "opt_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.x_encoder.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 1e-2},\n",
    "    {'params': [p for n, p in model.predictor.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 1e-2},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n",
    "]\n",
    "model.y_encoder.requires_grad_(False)\n",
    "\n",
    "optimizer = torch.optim.AdamW(opt_grouped_parameters, lr=max_lr)\n",
    "num_iterations_per_epoch = num_samples_per_epoch // global_batch_size\n",
    "print(\"num_iterations_per_epoch\", num_iterations_per_epoch)\n",
    "total_steps = num_epochs * num_iterations_per_epoch * num_devices\n",
    "print(\"total_steps\", total_steps)\n",
    "lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=max_lr,\n",
    "    total_steps=total_steps,\n",
    ")\n",
    "\n",
    "print(\"\\nDone with model preparations!\")\n",
    "num_params = utils.count_params(model)\n",
    "\n",
    "momentum_scheduler = (ema[0] + i*(ema[1]-ema[0])/(num_iterations_per_epoch*num_epochs*ipe_scale)\n",
    "                          for i in range(int(num_iterations_per_epoch*num_epochs*ipe_scale)+1))\n",
    "count=0\n",
    "print(\"\\nmomentum_scheduler set\")\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=max_lr,\n",
    "    total_steps=total_steps,\n",
    ")\n",
    "print(\"\\nlr_scheduler set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233c03de-3475-4ffa-872b-ca6d9c98103d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "default_ckpt_path = outdir+f'/last.pth'\n",
    "\n",
    "def save_ckpt(model,tag=\"last\"):\n",
    "    if distributed: dist.barrier()\n",
    "    model_states = model.state_dict()\n",
    "    if global_rank == 0:\n",
    "        ckpt_path = outdir+f'/{tag}.pth'\n",
    "        os.makedirs(outdir,exist_ok=True)\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model_states,\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'lr_scheduler_state_dict': lr_scheduler.state_dict(),\n",
    "        }, ckpt_path)\n",
    "        print(f\"\\n---saved {ckpt_path}!---\\n\")\n",
    "        # save config.yaml copy\n",
    "        with open(f'{outdir}/config.yaml', 'w') as file:\n",
    "            yaml.dump(config, file)\n",
    "\n",
    "def resume_ckpt(model, optimizer, device, ckpt_path=default_ckpt_path):\n",
    "    if global_rank == 0:\n",
    "        checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        lr_scheduler.load_state_dict(checkpoint['lr_scheduler_state_dict'])\n",
    "        epoch = checkpoint['epoch']\n",
    "    else:\n",
    "        epoch = 0\n",
    "    if distributed: dist.barrier()\n",
    "    torch.cuda.empty_cache()\n",
    "    return model, optimizer, lr_scheduler, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90a4cfd-2f67-417a-9251-eac4baa2aee9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if utils.is_interactive():\n",
    "    wandb_log = False\n",
    "if global_rank==0 and wandb_log: # only use main process for wandb logging\n",
    "    import wandb\n",
    "    wandb_project = 'found'\n",
    "    print(f\"wandb {wandb_project} run {model_name}\")\n",
    "    # need to configure wandb beforehand in terminal with \"wandb init\"!\n",
    "    wandb_config = {\n",
    "      \"model_name\": model_name,\n",
    "      \"global_batch_size\": global_batch_size,\n",
    "      \"batch_size\": batch_size,\n",
    "      \"num_epochs\": num_epochs,\n",
    "      \"num_samples_per_epoch\": num_samples_per_epoch,\n",
    "      \"depth\": depth,\n",
    "      \"num_heads\": num_heads,\n",
    "      \"embed_dim\": embed_dim,\n",
    "      \"mlp_dim\": mlp_dim,\n",
    "      \"x_encoder_start_masking_ratio\": x_encoder_start_masking_ratio,\n",
    "      \"x_encoder_end_masking_ratio\": x_encoder_end_masking_ratio,\n",
    "      \"y_encoder_mask_ratio\": y_encoder_mask_ratio,\n",
    "      \"num_frames\": num_frames,\n",
    "      \"patch_size\": patch_size,\n",
    "      \"frame_patch_size\": frame_patch_size,\n",
    "      \"use_contrastive_loss\": use_contrastive_loss,\n",
    "      \"use_cls_token\": use_cls_token,\n",
    "      \"constrastive_loss_weight\": constrastive_loss_weight,\n",
    "      \"num_params\": num_params,\n",
    "      \"max_lr\": max_lr,\n",
    "      \"ckpt_interval\": ckpt_interval,\n",
    "      \"ckpt_saving\": ckpt_saving,\n",
    "      \"seed\": seed,\n",
    "      \"distributed\": distributed,\n",
    "      \"num_devices\": num_devices,\n",
    "      \"world_size\": world_size,\n",
    "      \"train_urls\": train_urls,\n",
    "      \"is_s3\": is_s3,\n",
    "    }\n",
    "    print(\"wandb_config:\\n\",wandb_config)\n",
    "    print(\"wandb_id:\",model_name)\n",
    "    wandb.init(\n",
    "        id=model_name,\n",
    "        project=wandb_project,\n",
    "        name=model_name,\n",
    "        config=wandb_config,\n",
    "        resume=\"allow\",\n",
    "    )\n",
    "else:\n",
    "    wandb_log = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5102a6b4-8587-4121-b422-a8232ea9898c",
   "metadata": {},
   "source": [
    "# Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f7ed4a-2abf-42af-b1ca-798c703d00f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "lrs, recon_losses, contrastive_losses, test_losses = [], [], [], []\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a97f07-9781-45e3-bb49-76a667a3dcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if resume_from_ckpt is True:\n",
    "    if os.path.exists(default_ckpt_path):\n",
    "        print(f\"Resuming from {default_ckpt_path}...\")\n",
    "        model, optimizer, lr_scheduler, epoch = resume_ckpt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58ec911-325d-4d3c-b5e3-6f855661638f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if distributed: dist.barrier()\n",
    "l1 = nn.L1Loss() #Following VJEPA architecture, which uses L1 loss not L2 loss\n",
    "progress_bar = tqdm(range(epoch, num_epochs), disable=global_rank!=0)\n",
    "for epoch in progress_bar:\n",
    "    # get the masking ratio for the current epoch\n",
    "    tube_mask_ratio = utils.get_masking_ratio(\n",
    "        current_epoch=epoch, \n",
    "        total_epochs=num_epochs, \n",
    "        start_masking_ratio=x_encoder_start_masking_ratio, \n",
    "        end_masking_ratio=x_encoder_end_masking_ratio\n",
    "    )\n",
    "    with torch.cuda.amp.autocast(dtype=data_type):\n",
    "        model.train()\n",
    "        for train_i, batch in enumerate(train_dl):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            input_func = batch['func.npy']\n",
    "            if train_i==0 and epoch==0:\n",
    "                print(f\"min {input_func.min()} max {input_func.max()} global_rank={global_rank}\")\n",
    "            input_func = input_func.clamp(0,1)\n",
    "            \n",
    "            if masking_strategy==\"MNI\":\n",
    "                func, _ = aug_transform(input_func)\n",
    "            else:\n",
    "                func, brain_pos_voxels = aug_transform(input_func)\n",
    "                brain_pos_pats = model.patchify(torch.Tensor(brain_pos_voxels)[None,None,None])\n",
    "                brain_pos_pats_vit = rearrange(brain_pos_pats, \"b ... d -> b (...) d\").mean(-1)[0]\n",
    "                \n",
    "            func = func.unsqueeze(1).to(device)\n",
    "\n",
    "            # create tube mask (i.e., a mask that is the same for all frames/timepoints)\n",
    "            tube_mask = torch.zeros(num_patches // num_frames).to(torch.bool)\n",
    "            batch_positive_approx = (brain_pos_pats_vit > 0)\n",
    "            mask_idx_candidates = torch.where(batch_positive_approx)[0]\n",
    "            mask_idx_candidates = mask_idx_candidates[torch.randperm(len(mask_idx_candidates))]\n",
    "            tube_idx = mask_idx_candidates[:int(num_patches / num_frames * (1 - tube_mask_ratio))]\n",
    "            tube_mask[tube_idx] = True\n",
    "            tube_mask = tube_mask.tile(num_frames)\n",
    "\n",
    "            # print(\"before encoder\");utils.print_cuda_memory_usage()\n",
    "            \n",
    "            # feed into x-encoder\n",
    "            xencoder_out = model(func, encoder_mask=tube_mask, encoder_type = \"x\")\n",
    "            # print(\"x_encoder\");utils.print_cuda_memory_usage()\n",
    "            \n",
    "            # feed entire func into y-encoder\n",
    "            yencoder_out = model(func, encoder_mask=tube_mask, encoder_type = \"y\")\n",
    "            # print(\"y_encoder\");utils.print_cuda_memory_usage()\n",
    "            \n",
    "            # feed output of x-encoder into predictor\n",
    "            predictor_out = model(xencoder_out, encoder_mask=tube_mask, encoder_type=\"p\")\n",
    "            # print(\"predictor\");utils.print_cuda_memory_usage()\n",
    "            \n",
    "            # compare output of predictor to output of y-encoder and calculate L1 Loss\n",
    "            loss = l1(predictor_out,yencoder_out)\n",
    "\n",
    "            if train_i==0 and epoch==0:\n",
    "                print(\"calculated first loss\")\n",
    "            if train_i==1 and epoch==0:\n",
    "                print(\"reached train_i=1\")\n",
    "            if train_i==0 and epoch==1:\n",
    "                print(\"reached epoch1\")\n",
    "            \n",
    "            # backwards + step\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            recon_losses.append(loss.item())\n",
    "            lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "            \n",
    "            # update y-encoder using exponential-moving average of x-encoder params to prevent collapse\n",
    "            m = next(momentum_scheduler)\n",
    "            with torch.no_grad():\n",
    "                for param_q, param_k in zip(model.x_encoder.parameters(), model.y_encoder.parameters()):\n",
    "                    param_k.data.mul_(m).add_((1.-m) * param_q.detach().data)\n",
    "\n",
    "            if train_i==0 and epoch==0:\n",
    "                print(\"finished first epoch!\")\n",
    "\n",
    "            if train_i >= (num_iterations_per_epoch-1):\n",
    "                print(\"train_i\", train_i, \"local_rank\", local_rank, \"global_rank\", global_rank)\n",
    "                break\n",
    "\n",
    "        logs = {\n",
    "            \"train/loss\": np.mean(recon_losses[-(train_i + 1) :]),\n",
    "            \"train/num_steps\": len(recon_losses),\n",
    "            \"lr\": np.mean(lrs[-(train_i + 1) :]),\n",
    "            \"epoch\": epoch,\n",
    "            \"tube_mask_ratio\": tube_mask_ratio,\n",
    "        }\n",
    "        progress_bar.set_postfix(**logs)\n",
    "        if distributed: print(logs)\n",
    "            \n",
    "        if global_rank==0:\n",
    "            if wandb_log: wandb.log(logs)\n",
    "                    \n",
    "        # Save model checkpoint\n",
    "        if (ckpt_saving) and ((epoch % ckpt_interval == 0) or (epoch==num_epochs-1)):\n",
    "            save_ckpt(model,\"last\")\n",
    "            \n",
    "        # wait for other GPUs to catch up if needed\n",
    "        if distributed: dist.barrier()\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "if not is_s3 and global_rank==0:\n",
    "    print(f\"deleting local scratch directory: {local_scratch}\")\n",
    "    command = f\"rm -rf {local_scratch}\"\n",
    "    print(command)\n",
    "    call(command,shell=True)\n",
    "\n",
    "if distributed:\n",
    "    dist.barrier()\n",
    "    dist.destroy_process_group()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
